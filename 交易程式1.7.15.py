# é€™å€‹ç‰ˆæœ¬è¦æª¢æŸ¥ä¸‰å€‹å•é¡Œï¼š
# 1. è§¸ç™¼æ¼²åœé€²å ´å¾Œï¼Œæ²’æœ‰åœ¨æ¥ä¸‹ä¾†çš„ç­‰å¾…æœŸé–“åŠ å…¥ã€Œç­‰å¾…ç¬¬ X åˆ†é˜ã€çš„è¨Šæ¯ã€‚
# 2. æ‹‰é«˜é€²å ´å’Œæ¼²åœé€²å ´åŒä¸€æ™‚é–“è§¸ç™¼ï¼Œæ²’æœ‰ä»¥æ¼²åœé€²å ´ç‚ºå„ªå…ˆã€‚
# 3. é ˜æ¼²æ›¿æ›ä¹‹å¾Œæ²’æœ‰ç¹¼çºŒè§€å¯Ÿï¼Œå¥½åƒæ²’æœ‰å…¶ä»–å‹•ä½œã€‚
# é€™å€‹ç‰ˆæœ¬è¦æ–°å¢çš„åŠŸèƒ½ï¼š
# 1. å›æ¸¬å‡½æ•¸çš„ç›¸ä¼¼åº¦åˆ¤æ–·ï¼ˆå·²å®Œæˆï¼‰
# 2. äº¤æ˜“å‡½æ•¸çš„ç›¸ä¼¼åº¦åˆ¤æ–·ï¼ˆå·²å®Œæˆï¼‰

# -------------------- äº‹å‰æº–å‚™ --------------------
import json
import os
import math
import subprocess
import sys
import time as time_module
import warnings
import msvcrt
import traceback
import shioaji_logic
import importlib
import csv
import threading

from datetime import datetime, time, timedelta, date
from concurrent.futures import ThreadPoolExecutor, as_completed

REQUIRED = [
    ("fugle_marketdata", "fugle-marketdata"),
    ("pandas",           "pandas"),
    ("yaml",             "pyyaml"),
    ("numpy",            "numpy"),
    ("colorama",         "colorama"),
    ("tabulate",         "tabulate"),
    ("openpyxl",         "openpyxl"),
    ("dateutil",         "python-dateutil"),
    ("matplotlib",       "matplotlib")
]

def ensure_packages(pkgs):
    """æª¢æŸ¥â†’ç¼ºå°‘å°± pip installâ†’æœ€å¾Œå†å‹•æ…‹ import å›ä¾†"""
    missing = []
    for mod, pkg in pkgs:
        try:
            importlib.import_module(mod)
        except ImportError:
            missing.append(pkg)

    if missing:
        print("é¦–æ¬¡åŸ·è¡Œåµæ¸¬åˆ°ä»¥ä¸‹å¥—ä»¶å°šæœªå®‰è£ï¼š", ", ".join(missing))
        for pkg in missing:
            subprocess.check_call(
                [sys.executable, "-m", "pip", "install", pkg]
            )
        # å®‰è£å®Œå†æŠŠå®ƒå€‘ import é€²ä¾†ï¼Œç¨‹å¼ä¸ç”¨é‡é–‹
        for mod, pkg in pkgs:
            globals()[mod] = importlib.import_module(mod)
    else:
        print("ğŸ‘  æ‰€æœ‰å¿…è¦å¥—ä»¶éƒ½å·²å®‰è£")

ensure_packages(REQUIRED)

import fugle_marketdata as fg
import pandas as pd
import yaml
import numpy as np
import colorama
import shioaji as sj
import touchprice as tp
import requests, bs4
import orjson
import matplotlib.pyplot as plt
from tabulate import tabulate
from openpyxl.styles import PatternFill
from colorama import init, Fore, Style
from fugle_marketdata import RestClient
from bs4 import BeautifulSoup

plt.rcParams['axes.unicode_minus'] = False
colorama.init(autoreset=True)
warnings.filterwarnings("ignore", category=FutureWarning)

# å…¨åŸŸæ——æ¨™ï¼šæŒ‰ä¸‹ Q éµè§¸ç™¼å¹³å€‰é¸å–®
quit_flag = {"quit": False}

RED = Fore.RED
GREEN = Fore.GREEN
YELLOW = Fore.YELLOW
BLUE = Fore.BLUE
RESET = Style.RESET_ALL

pd.set_option('future.no_silent_downcasting', True)

def _crawl_tw_isin_table(mode: str):
    """
    mode = '2' â†’ ä¸Šå¸‚è‚¡ç¥¨
    mode = '4' â†’ ä¸Šæ«ƒè‚¡ç¥¨
    å›å‚³ [(ä»£è™Ÿ, ä¸­æ–‡å), ...]
    """

    url = f"https://isin.twse.com.tw/isin/C_public.jsp?strMode={mode}"
    r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
    r.encoding = "big5"                    # å®˜æ–¹ç¶²é ä»¥ Big5 ç·¨ç¢¼
    soup = bs4.BeautifulSoup(r.text, "lxml")
    rows = soup.select("table tr")[1:]     # ç¬¬ 0 åˆ—æ˜¯è¡¨é ­

    pairs = []
    for tr in rows:
        tds = tr.find_all("td")
        if not tds:
            continue
        raw = tds[0].text.strip()
        if raw[:4].isdigit():              # åªè¦å‰ 4 ç¢¼æ˜¯ç´”æ•¸å­—çš„è‚¡ç¥¨
            code = raw[:4]
            name = raw.split("\u3000", 1)[1] if "\u3000" in raw else raw[4:]
            pairs.append((code, name))
    return pairs

def fetch_twse_stock_codes(save_json=None, save_csv=None):
    """
    å–å¾—å°ç£ä¸Šå¸‚è‚¡ç¥¨ä»£è™Ÿèˆ‡ä¸­æ–‡åç¨±æ¸…å–®
    --------------------------------------------------
    Parameters
    ----------
    save_json : str | None
        è‹¥çµ¦æª”åï¼Œå°‡çµæœå­˜æˆ JSONï¼Œä¾‹å¦‚ "twse_stocks.json"
    save_csv  : str | None
        è‹¥çµ¦æª”åï¼Œå°‡çµæœå­˜æˆ CSVï¼Œä¾‹å¦‚ "twse_stocks.csv"

    Returns
    -------
    List[Tuple[str,str]]
        [('1101', 'å°æ³¥'), ('1102', 'äºæ³¥'), ...]
    """
    url     = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    headers = {"User-Agent": "Mozilla/5.0"}

    res = requests.get(url, headers=headers, timeout=10)
    # ç¶²é æ¡ Bigâ€‘5ï¼Œæ‰‹å‹•æŒ‡å®šç·¨ç¢¼é¿å…äº‚ç¢¼
    res.encoding = "big5"

    soup = BeautifulSoup(res.text, "lxml")
    rows = soup.select("table tr")[1:]          # è·³éè¡¨é ­

    stocks = []
    for r in rows:
        cols = [c.text.strip() for c in r.find_all("td")]
        if not cols:
            continue
        code_name = cols[0]                     # ä¾‹ï¼šã€Œ1101ã€€å°æ³¥ã€
        if len(code_name) >= 4 and code_name[:4].isdigit():
            code = code_name[:4]
            # ä»¥ã€Œå…¨å½¢ç©ºæ ¼ã€åŠƒåˆ†å–ä¸­æ–‡åç¨±ï¼›è‹¥åˆ‡ä¸åˆ°å°±ç›´æ¥å–å‰©é¤˜å­—ä¸²
            name = code_name.split("\u3000", 1)[1] if "\u3000" in code_name else code_name[4:]
            stocks.append((code, name))

    # ----------- (é¸ç”¨) å­˜æª” -----------
    if save_json:
        with open(save_json, "w", encoding="utf-8") as f:
            json.dump(stocks, f, ensure_ascii=False, indent=2)
    if save_csv:
        with open(save_csv, "w", encoding="utf-8-sig", newline="") as f:
            w = csv.writer(f)
            w.writerow(["Code", "Name"])
            w.writerows(stocks)

    return stocks

STOCK_NAME_MAP = {}      # å…¨åŸŸå­—å…¸ { "1101": "å°æ³¥", ... }

def load_twse_name_map(json_path="twse_stocks_by_market.json"):
    global STOCK_NAME_MAP
    if STOCK_NAME_MAP:
        return

    try:
        if os.path.exists(json_path):
            with open(json_path, "r", encoding="utf-8") as f:
                STOCK_NAME_MAP = json.load(f)
            return

        # åˆ†åˆ¥æŠ“ä¸Šå¸‚èˆ‡ä¸Šæ«ƒ
        listed_pairs = _crawl_tw_isin_table("2")  # ä¸Šå¸‚
        otc_pairs = _crawl_tw_isin_table("4")     # ä¸Šæ«ƒ

        tse_map = {c: n for c, n in listed_pairs}
        otc_map = {c: n for c, n in otc_pairs}

        STOCK_NAME_MAP = {
            "TSE": tse_map,
            "OTC": otc_map
        }

        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(STOCK_NAME_MAP, f, ensure_ascii=False, indent=2)

    except Exception as e:
        print(f"è¼‰å…¥è‚¡ç¥¨ä¸­æ–‡åç¨±å¤±æ•—ï¼š{e}")
        STOCK_NAME_MAP = {}

def get_stock_name(code):
    """çµ¦å®š 4 ç¢¼è‚¡ç¥¨ä»£è™Ÿï¼Œå›å‚³ä¸­æ–‡åç¨±ï¼›æ‰¾ä¸åˆ°å°±å›ç©ºå­—ä¸²"""
    for market in ["TSE", "OTC"]:
        if code in STOCK_NAME_MAP.get(market, {}):
            return STOCK_NAME_MAP[market][code]
    return ""

load_twse_name_map()
'''
# æ¸¬è©¦è‚¡ç¥¨ä»£è™Ÿæ˜¯å¦èƒ½é€£çµåˆ°ä¸­æ–‡åç¨±
print(get_stock_name("2330"))   # å°ç©é›»  (ä¸Šå¸‚)
print(get_stock_name("5483"))   # ä¸­ç¾æ™¶  (ä¸Šæ«ƒ)
'''

def init_fugle_client():
    try:
        config = load_config("config.yaml")
        client = RestClient(api_key=config['api_key'])
        print("=" * 50)
        print("å¾ config.yaml è¼‰å…¥ API é‡‘é‘°")
        print("=" * 50)
        return client, config['api_key']
    except FileNotFoundError:
        print("éŒ¯èª¤ï¼šconfig.yaml æ–‡ä»¶ä¸å­˜åœ¨ã€‚")
        sys.exit(1)
    except KeyError:
        print("éŒ¯èª¤ï¼šconfig.yaml ä¸­ç¼ºå°‘ 'api_key'ã€‚")
        sys.exit(1)
    except Exception as e:
        print(f"åˆå§‹åŒ–å¯ŒæœAPIå®¢æˆ¶ç«¯æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        sys.exit(1)

def load_config(config_file):
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šç„¡æ³•æ‰¾åˆ° {config_file} æ–‡ä»¶ã€‚")
        sys.exit(1)
    except yaml.YAMLError as e:
        print(f"éŒ¯èª¤ï¼šè®€å– {config_file} æ–‡ä»¶æ™‚ç™¼ç”Ÿ YAML éŒ¯èª¤ï¼š{e}")
        sys.exit(1)

capital_per_stock = 0
transaction_fee = 0
transaction_discount = 0
trading_tax = 0
below_50 = 0
price_gap_50_to_100 = 0
price_gap_100_to_500 = 0
price_gap_500_to_1000 = 0
price_gap_above_1000 = 0
allow_reentry_after_stop_loss = False

# -------------------- é€²å…¥é¸å–® --------------------
def main_menu():
    global capital_per_stock
    load_settings()
    print('\n' + '=' * 50)
    print(f"\nç›®å‰è‚¡ç¥¨çš„å–®ç­†æŠ•å…¥è³‡æœ¬é¡ç‚º{capital_per_stock}è¬å…ƒ")
    while True:
        print("è«‹é¸æ“‡åŠŸèƒ½ï¼š")
        print("1. å›æ¸¬ç¨‹å¼")
        print("2. ä¸‹å–®ç¨‹å¼")
        print("3. ç®¡ç†æ—ç¾¤")
        print("4. è¨­å®šé¸å–®")
        print("5. æ›´æ–°Kç·šæ•¸æ“š")
        print("6. æŸ¥è©¢è™•ç½®è‚¡")
        print("0. é€€å‡ºç¨‹å¼")
        print('\n' + '=' * 50)
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if choice == '1':
            backtesting_menu_list()
        elif choice == '2':
            trading_menu_list()
        elif choice == '3':
            manage_groups()
        elif choice == '4':
            settings_menu()
        elif choice == '5':
            update_kline_data_menu()
        elif choice == '6':
            display_disposition_stocks()
        elif choice == '0':
            print("é€€å‡ºç¨‹å¼...å†è¦‹")
            break
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

# -------------------- å›æ¸¬ç¨‹å¼ --------------------
def backtesting_menu_list():
    print('\n' + '=' * 50)
    print("\nè«‹é¸æ“‡åŠŸèƒ½ï¼š")
    print("1. è¨ˆç®—å¹³å‡éé«˜ã€2. è‡ªé¸é€²å ´æ¨¡å¼ã€3. æ¥µå¤§åŒ–åˆ©æ½¤æ¨¡å¼ã€0. è¿”å›ä¸»é¸å–®")
    print('\n' + '=' * 50)
    back_choice = input("è«‹é¸æ“‡åŠŸèƒ½ï¼š")
    if back_choice == '1':
        calculate_average_over_high_list()
    elif back_choice == '2':
        simulate_trading_menu()
    elif back_choice == '3':
        maximize_profit_analysis()
    elif back_choice == '0':
        main_menu()
    else:
        print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

# ------------------ å›æ¸¬ç¨‹å¼ï¼šè¨ˆç®—å¹³å‡éé«˜ ------------------
def calculate_average_over_high_list():
    while True:
        print('\n' + '=' * 50)
        print("é¸æ“‡è¨ˆç®—å¹³å‡éé«˜çš„æ¨¡å¼ï¼š")
        print("1. å–®ä¸€æ—ç¾¤åˆ†æ")
        print("2. å…¨éƒ¨æ—ç¾¤åˆ†æ")
        print("0. è¿”å›ä¸»é¸å–®")
        
        sub_choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if sub_choice == '1':
            calculate_average_over_high()
        elif sub_choice == '2':
            matrix_dict_analysis = load_matrix_dict_analysis()
            all_group_names = list(matrix_dict_analysis.keys())
            if not all_group_names:
                print("æ²’æœ‰ä»»ä½•æ—ç¾¤è³‡æ–™å¯ä¾›åˆ†æã€‚")
                continue
            print("é–‹å§‹åˆ†ææ‰€æœ‰æ—ç¾¤ä¸­çš„è‚¡ç¥¨...")
            all_group_over_high_averages = []

            for i, group in enumerate(all_group_names):
                print(f"\n=== åˆ†ææ—ç¾¤ï¼š{group} ===")
                group_average = calculate_average_over_high(group_name=group)
                if group_average is not None:
                    all_group_over_high_averages.append(group_average)
                    
            if all_group_over_high_averages:
                overall_group_average = sum(all_group_over_high_averages) / len(all_group_over_high_averages)
                print(f"\nå…¨éƒ¨æ—ç¾¤çš„å¹³å‡éé«˜é–“éš”ï¼š{overall_group_average:.2f} åˆ†é˜")
            else:
                print("\næ²’æœ‰ä»»ä½•æ—ç¾¤ç™¼ç”Ÿéé«˜é–“éš”çš„æƒ…å½¢ã€‚")
        elif sub_choice == '0':
            main_menu()
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

# ---------------- å›æ¸¬ç¨‹å¼ï¼šå–®ä¸€æ—ç¾¤åˆ†æ ----------------
def calculate_average_over_high(group_name=None):
    daily_kline_data, intraday_kline_data = load_kline_data()

    matrix_dict_analysis = load_matrix_dict_analysis()
    
    if group_name is None:
        group_name = input("è«‹è¼¸å…¥è¦åˆ†æçš„æ—ç¾¤åç¨±ï¼š")
    
    if group_name not in matrix_dict_analysis:
        print("æ²’æœ‰æ­¤æ—ç¾¤è³‡æ–™")
        return None

    symbols_to_analyze = matrix_dict_analysis[group_name]
    disposition_stocks = load_disposition_stocks()
    symbols_to_analyze = [symbol for symbol in symbols_to_analyze if symbol not in disposition_stocks]

    if not symbols_to_analyze:
        print(f"{group_name} ä¸­æ²’æœ‰å¯ä¾›åˆ†æçš„è‚¡ç¥¨ã€‚")
        return None

    print(f"é–‹å§‹åˆ†ææ—ç¾¤ {group_name} ä¸­çš„è‚¡ç¥¨...")
    any_condition_one_triggered = False 
    group_over_high_averages = []

    for symbol in symbols_to_analyze:
        print(f"\næ­£åœ¨åˆ†æè‚¡ç¥¨ï¼š{symbol}")
        
        if symbol not in daily_kline_data or symbol not in intraday_kline_data:
            print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥ K ç·šæˆ–ä¸€åˆ† K ç·šæ•¸æ“šï¼Œè·³éã€‚")
            continue
        
        daily_kline_df = pd.DataFrame(daily_kline_data[symbol])
        intraday_data = pd.DataFrame(intraday_kline_data[symbol])

        condition_one_triggered = False
        condition_two_triggered = False
        previous_high = None
        condition_two_time = None
        over_high_intervals = []

        for idx, row in intraday_data.iterrows():
            current_time = pd.to_datetime(row['time']).time()
            if previous_high is None:
                previous_high = row['high']
                continue

            if not condition_one_triggered:
                if row['2min_pct_increase'] >= 2:
                    condition_one_triggered = True
                    condition_two_triggered = False
                    any_condition_one_triggered = True

                    print(f"{symbol} è§¸ç™¼æ¢ä»¶ä¸€ï¼Œé–‹å§‹ç›£æ¸¬å…©åˆ†é˜æ¼²å¹…ï¼Œå…©åˆ†é˜æ¼²å¹…: {row['2min_pct_increase']:.2f}%")

            if condition_one_triggered and not condition_two_triggered:
                if row['high'] <= previous_high:
                    current_time_str = current_time.strftime('%H:%M:%S')
                    print(f"{symbol} è§¸ç™¼æ¢ä»¶äºŒï¼æ™‚é–“ï¼š{current_time_str}")

                    condition_two_time = current_time
                    condition_two_triggered = True

            elif condition_two_triggered:
                if row['highest'] > previous_high:
                    condition_three_time_str = current_time.strftime('%H:%M:%S')
                    print(f"{symbol} è§¸ç™¼æ¢ä»¶ä¸‰ï¼æ™‚é–“ï¼š{condition_three_time_str}")
                    if condition_two_time:
                        today = datetime.today().date()
                        condition_two_datetime = datetime.combine(today, condition_two_time)
                        condition_three_datetime = datetime.combine(today, current_time)
                        interval = (condition_three_datetime - condition_two_datetime).total_seconds() / 60
                        print(f"{symbol} éé«˜é–“éš”ï¼š{interval:.2f} åˆ†é˜")
                        over_high_intervals.append(interval)

                    condition_one_triggered = False
                    condition_two_triggered = False
                    condition_two_time = None

            previous_high = row['high']

        if over_high_intervals:
            q1 = np.percentile(over_high_intervals, 25)
            q3 = np.percentile(over_high_intervals, 75)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            filtered_intervals = [interval for interval in over_high_intervals if lower_bound <= interval <= upper_bound]
            if filtered_intervals:
                average_interval = sum(filtered_intervals) / len(filtered_intervals)
                print(f"{symbol} å¹³å‡éé«˜é–“éš”ï¼š{average_interval:.2f} åˆ†é˜")
                group_over_high_averages.append(average_interval)
            else:
                print(f"{symbol} æ²’æœ‰æœ‰æ•ˆçš„éé«˜é–“éš”æ•¸æ“š")
        else:
            print(f"{symbol} æ²’æœ‰è§¸ç™¼éé«˜é–“éš”çš„æƒ…å½¢")

    if group_over_high_averages:
        group_average_over_high = sum(group_over_high_averages) / len(group_over_high_averages)
        print(f"{group_name} å¹³å‡éé«˜é–“éš”ï¼š{group_average_over_high:.2f} åˆ†é˜")
        return group_average_over_high
    else:
        print(f"{group_name} æ²’æœ‰æœ‰æ•ˆçš„éé«˜é–“éš”æ•¸æ“š")
        return None

# ------------------ å›æ¸¬ç¨‹å¼ï¼šè‡ªé¸é€²å ´æ¨¡å¼ ------------------
def simulate_trading_menu():
    matrix_dict_analysis = load_matrix_dict_analysis()
    if not matrix_dict_analysis:
        print("æ²’æœ‰æ—ç¾¤è³‡æ–™ï¼Œè«‹å…ˆç®¡ç†æ—ç¾¤ã€‚")
        return

    while True:
        print("è«‹é¸æ“‡æ“ä½œï¼š")
        print("1. åˆ†æå–®ä¸€æ—ç¾¤")
        print("2. åˆ†æå…¨éƒ¨æ—ç¾¤")
        print("0. è¿”å›ä¸»é¸å–®")
        choice = input("è«‹è¼¸å…¥é¸é …ç·¨è™Ÿï¼š")

        if choice == '1':
            group_name = input("è«‹è¼¸å…¥è¦åˆ†æçš„æ—ç¾¤åç¨±ï¼š")
            if group_name not in matrix_dict_analysis:
                print("æ²’æœ‰æ­¤æ—ç¾¤è³‡æ–™")
                continue

            try:
                wait_minutes = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“ï¼ˆåˆ†é˜ï¼‰ï¼š"))
            except ValueError:
                print("ç­‰å¾…æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸ã€‚")
                continue

            hold_minutes_input = input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥ 'F' ä»£è¡¨æŒæœ‰åˆ°13:30å¼·åˆ¶å‡ºå ´ï¼‰ï¼š")
            if hold_minutes_input.upper() == 'F':
                hold_minutes = None
            else:
                try:
                    hold_minutes = int(hold_minutes_input)
                except ValueError:
                    print("æŒæœ‰æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸æˆ– 'F'ã€‚")
                    continue

            disposition_stocks = load_disposition_stocks()
            symbols_to_analyze = matrix_dict_analysis[group_name]
            symbols_to_analyze = [symbol for symbol in symbols_to_analyze if symbol not in disposition_stocks]
            if len(symbols_to_analyze) == 0:
                print(f"{group_name} ä¸­æ²’æœ‰å¯ä¾›åˆ†æçš„è‚¡ç¥¨ã€‚")
                continue

            daily_kline_data, intraday_kline_data = load_kline_data()

            stock_data_collection = initialize_stock_data(symbols_to_analyze, daily_kline_data, intraday_kline_data)
            if not stock_data_collection:
                print("ç„¡æ³•ç²å–æœ‰æ•ˆçš„ä¸€åˆ† K è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œåˆ†æ")
                continue

            total_profit, avg_profit_rate = process_group_data(stock_data_collection, wait_minutes, hold_minutes, matrix_dict_analysis, verbose=True)

            print(f"\næ¨¡æ“¬äº¤æ˜“å®Œæˆï¼Œç¸½åˆ©æ½¤ï¼š{int(total_profit) if total_profit is not None else 0} å…ƒï¼Œå¹³å‡å ±é…¬ç‡ï¼š{avg_profit_rate if avg_profit_rate is not None else 0:.2f}%\n")

        elif choice == '2':
            try:
                wait_minutes = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“ï¼ˆåˆ†é˜ï¼‰ï¼š"))
            except ValueError:
                print("ç­‰å¾…æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸ã€‚")
                continue

            hold_minutes_input = input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥ 'F' ä»£è¡¨æŒæœ‰åˆ°13:30å¼·åˆ¶å‡ºå ´ï¼‰ï¼š")
            if hold_minutes_input.upper() == 'F':
                hold_minutes = None
            else:
                try:
                    hold_minutes = int(hold_minutes_input)
                except ValueError:
                    print("æŒæœ‰æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸æˆ– 'F'ã€‚")
                    continue

            day_total_profit = 0
            day_avg_profit_rates = []

            for group_name in matrix_dict_analysis.keys():
                print(f"\næ­£åœ¨åˆ†ææ—ç¾¤ï¼š{group_name}")

                disposition_stocks = load_disposition_stocks()
                symbols_to_analyze = matrix_dict_analysis[group_name]
                symbols_to_analyze = [symbol for symbol in symbols_to_analyze if symbol not in disposition_stocks]
                if len(symbols_to_analyze) == 0:
                    print(f"{group_name} ä¸­æ²’æœ‰å¯ä¾›åˆ†æçš„è‚¡ç¥¨ã€‚")
                    continue

                daily_kline_data, intraday_kline_data = load_kline_data()

                stock_data_collection = initialize_stock_data(symbols_to_analyze, daily_kline_data, intraday_kline_data)
                if not stock_data_collection:
                    print(f"ç„¡æ³•ç²å– {group_name} çš„æœ‰æ•ˆä¸€åˆ† K è³‡æ–™ï¼Œè·³éã€‚")
                    continue

                total_profit, avg_profit_rate = process_group_data(stock_data_collection, wait_minutes, hold_minutes, matrix_dict_analysis, verbose=True)

                if total_profit is not None and avg_profit_rate is not None:
                    day_total_profit += total_profit
                    day_avg_profit_rates.append(avg_profit_rate)
                else:
                    pass

            if day_avg_profit_rates:
                day_avg_profit_rate = sum(day_avg_profit_rates) / len(day_avg_profit_rates)
            else:
                day_avg_profit_rate = 0.0

            if day_total_profit > 0:
                print(f"{RED}=" * 50)
                print(f"{RED}\nç•¶æ—¥ç¸½åˆ©æ½¤ï¼š{int(day_total_profit)} å…ƒ{RESET}")
                print(f"{RED}ç•¶æ—¥å ±é…¬ç‡ï¼š{day_avg_profit_rate:.2f}%\n{RESET}")
                print(f"{RED}=" * 50)
            elif day_total_profit < 0:
                print(f"{GREEN}=" * 50)
                print(f"{GREEN}\nç•¶æ—¥ç¸½åˆ©æ½¤ï¼š{int(day_total_profit)} å…ƒ{RESET}")
                print(f"{GREEN}ç•¶æ—¥å ±é…¬ç‡ï¼š{day_avg_profit_rate:.2f}%\n{RESET}")
                print(f"{GREEN}=" * 50)
            else:
                print("=" * 50)
                print(f"\nç•¶æ—¥ç¸½åˆ©æ½¤ï¼š{int(day_total_profit)} å…ƒ")
                print(f"ç•¶æ—¥å ±é…¬ç‡ï¼š{day_avg_profit_rate:.2f}%\n")
                print("=" * 50)

        elif choice == '0':
            break
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")

# --------------- å›æ¸¬ç¨‹å¼ï¼šæ¥µå¤§åŒ–åˆ©æ½¤æ¨¡å¼ ---------------
def maximize_profit_analysis():
    print("é€²å…¥æ¥µå¤§åŒ–åˆ©æ½¤æ¨¡å¼...")
    
    matrix_dict_analysis = load_matrix_dict_analysis()
    if not matrix_dict_analysis:
        print("æ²’æœ‰æ—ç¾¤è³‡æ–™ï¼Œè«‹å…ˆç®¡ç†æ—ç¾¤ã€‚")
        return

    group_name = input("è«‹è¼¸å…¥è¦åˆ†æçš„æ—ç¾¤åç¨±ï¼š")
    
    if group_name not in matrix_dict_analysis:
        print("æ²’æœ‰æ­¤æ—ç¾¤è³‡æ–™")
        return
    wait_minutes_start = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“èµ·å§‹å€¼ï¼ˆåˆ†é˜ï¼‰ï¼š"))
    wait_minutes_end = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“çµæŸå€¼ï¼ˆåˆ†é˜ï¼‰ï¼š"))
    hold_minutes_start = int(input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“èµ·å§‹å€¼ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥0ä»£è¡¨Fï¼‰ï¼š"))
    hold_minutes_end = int(input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“çµæŸå€¼ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥0ä»£è¡¨Fï¼‰ï¼š"))

    wait_minutes_range = range(wait_minutes_start, wait_minutes_end + 1)
    hold_minutes_range = range(hold_minutes_start, hold_minutes_end + 1)

    disposition_stocks = load_disposition_stocks()
    symbols_to_analyze = matrix_dict_analysis[group_name]
    symbols_to_analyze = [symbol for symbol in symbols_to_analyze if symbol not in disposition_stocks]
    if len(symbols_to_analyze) == 0:
        print(f"{group_name} ä¸­æ²’æœ‰å¯ä¾›åˆ†æçš„è‚¡ç¥¨ã€‚")
        return

    daily_kline_data, intraday_kline_data = load_kline_data()

    stock_data_collection = initialize_stock_data(symbols_to_analyze, daily_kline_data, intraday_kline_data)
    if not stock_data_collection:
        print("ç„¡æ³•ç²å–æœ‰æ•ˆçš„ä¸€åˆ† K è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œåˆ†æ")
        return

    results_df = pd.DataFrame(columns=['ç­‰å¾…æ™‚é–“', 'æŒæœ‰æ™‚é–“', 'ç¸½åˆ©æ½¤', 'å¹³å‡å ±é…¬ç‡'])
    results_df = results_df.astype({
        'ç­‰å¾…æ™‚é–“': 'int',
        'æŒæœ‰æ™‚é–“': 'object',
        'ç¸½åˆ©æ½¤': 'float',
        'å¹³å‡å ±é…¬ç‡': 'float'
    })

    for wait_minutes in wait_minutes_range:
        for hold_minutes in hold_minutes_range:
            hold_minutes_value = None if hold_minutes == 0 else hold_minutes
            print(f"æ­£åœ¨åˆ†æï¼šç­‰å¾…æ™‚é–“ {wait_minutes} åˆ†é˜ã€æŒæœ‰æ™‚é–“ {'F' if hold_minutes_value is None else hold_minutes_value} åˆ†é˜")
            
            total_profit, avg_profit_rate = process_group_data(
                stock_data_collection, wait_minutes, hold_minutes_value, matrix_dict_analysis, verbose=False)
            
            if total_profit is None:
                total_profit = 0.0
            if avg_profit_rate is None:
                avg_profit_rate = 0.0
            
            new_row = pd.DataFrame([{
                'ç­‰å¾…æ™‚é–“': wait_minutes,
                'æŒæœ‰æ™‚é–“': 'F' if hold_minutes_value is None else hold_minutes_value,
                'ç¸½åˆ©æ½¤': float(total_profit),
                'å¹³å‡å ±é…¬ç‡': float(avg_profit_rate)
            }])
            results_df = pd.concat([results_df, new_row], ignore_index=True)

    if results_df.empty:
        print("æ¨¡æ“¬çµæœç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œå¾ŒçºŒåˆ†æã€‚")
        return

    max_profit = results_df['ç¸½åˆ©æ½¤'].max()
    min_profit = results_df['ç¸½åˆ©æ½¤'].min()
    best_combination = results_df.loc[results_df['ç¸½åˆ©æ½¤'].idxmax()]

    print("\nåˆ©æ½¤æœ€å¤§çš„çµ„åˆï¼š")
    print(f"ç­‰å¾…æ™‚é–“ï¼š{best_combination['ç­‰å¾…æ™‚é–“']} åˆ†é˜ï¼ŒæŒæœ‰æ™‚é–“ï¼š{best_combination['æŒæœ‰æ™‚é–“']} åˆ†é˜ï¼Œç¸½åˆ©æ½¤ï¼š{int(best_combination['ç¸½åˆ©æ½¤'])} å…ƒï¼Œå¹³å‡å ±é…¬ç‡ï¼š{best_combination['å¹³å‡å ±é…¬ç‡']:.2f}%\n")

    pivot_df = results_df.pivot(index='ç­‰å¾…æ™‚é–“', columns='æŒæœ‰æ™‚é–“', values='ç¸½åˆ©æ½¤')

    formatted_pivot_df = pivot_df.copy()
    for col in formatted_pivot_df.columns:
        if col != 'ç­‰å¾…æ™‚é–“':
            formatted_pivot_df[col] = formatted_pivot_df[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

    formatted_pivot_df_reset = formatted_pivot_df.reset_index()

    print("æ¨¡æ“¬çµæœï¼š")
    print(tabulate(formatted_pivot_df_reset, headers='keys', tablefmt='psql', showindex=False))

    try:
        with pd.ExcelWriter('æ¨¡æ“¬çµæœ.xlsx', engine='openpyxl') as writer:
            pivot_df.to_excel(writer, sheet_name='æ¨¡æ“¬çµæœ', index=True)
            workbook = writer.book
            worksheet = writer.sheets['æ¨¡æ“¬çµæœ']
            
            max_profit = pivot_df.max().max()
            min_profit = pivot_df.min().min()

            max_fill = PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')
            min_fill = PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid')

            for row in worksheet.iter_rows(min_row=2, min_col=2):
                for cell in row:
                    if cell.value == max_profit:
                        cell.fill = max_fill
                    elif cell.value == min_profit:
                        cell.fill = min_fill
        print("\næ¨¡æ“¬çµæœå·²æˆåŠŸå¯«å…¥ 'æ¨¡æ“¬çµæœ.xlsx'ã€‚")
    except Exception as e:
        print(f"\nå¯«å…¥ Excel æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")




# ------------------ äº¤æ˜“ç¨‹å¼ ------------------
def trading_menu_list():
    print('\n' + '=' * 50)
    print("\nè«‹é¸æ“‡åŠŸèƒ½ï¼š")
    print("1. é–‹å§‹äº¤æ˜“ã€2. ç™»å…¥å¸³æˆ¶ã€0. è¿”å›ä¸»é¸å–®")
    print('\n' + '=' * 50)
    back_choice = input("è«‹é¸æ“‡åŠŸèƒ½ï¼š")
    if back_choice == '1':
        start_trading()
    elif back_choice == '2':
        login()
    elif back_choice == '0':
        main_menu()
    else:
        print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

# ------------------ äº¤æ˜“ç¨‹å¼ï¼šé–‹å§‹äº¤æ˜“ ------------------
def start_trading(mode='full', wait_minutes=None, hold_minutes=None):
    """
    mode:
        'full' â€“ ç¬¬ä¸€æ¬¡åŸ·è¡Œï¼šæ­£å¸¸è©¢å•ç­‰å¾…/æŒæœ‰åˆ†é˜ã€‚
        'post' â€“ ç›¤å¾Œéè¿´å‘¼å«ï¼šæ²¿ç”¨ä¸Šä¸€è¼ª wait_minutes / hold_minutesï¼Œä¸å†è©¢å•ã€‚
    """
    client, api_key = init_fugle_client()

    # ===== è™•ç½®è‚¡éæ¿¾=====
    matrix_dict_analysis = load_matrix_dict_analysis()
    fetch_disposition_stocks(client, matrix_dict_analysis)   # â‘  å…ˆæ›´æ–° Disposition.json
    disposition_stocks = load_disposition_stocks()           # â‘¡ è®€æœ€æ–°è™•ç½®è‚¡
    purge_disposition_from_nb(disposition_stocks)           # â‘¢ åˆª nb_matrix_dict ä¸­çš„è™•ç½®è‚¡
    # ====================

    symbols_to_analyze = load_symbols_to_analyze()
    stop_trading = False
    max_symbols_to_fetch = 20

    group_symbols = load_group_symbols()
    if not group_symbols:
        print("æ²’æœ‰åŠ è¼‰åˆ°ä»»ä½•æ—ç¾¤è³‡æ–™ï¼Œè«‹ç¢ºèª nb_matrix_dict.json çš„å­˜åœ¨èˆ‡å…§å®¹ã€‚")
        return
    consolidated_symbols = group_symbols.get('consolidated_symbols', {})
    if not consolidated_symbols:
        print("æ²’æœ‰æ‰¾åˆ° 'consolidated_symbols'ï¼Œè«‹ç¢ºèªè³‡æ–™çµæ§‹ã€‚")
        return
    group_positions = {group: False for group in consolidated_symbols.keys()}

    # æ™‚é–“åˆ¤æ–·
    now = datetime.now()
    now_str = now.strftime('%Y-%m-%d %H:%M:%S')
    pre_market_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    market_start     = now.replace(hour=9, minute=1, second=0, microsecond=0)
    market_end       = now.replace(hour=13, minute=30, second=0, microsecond=0)
    post_switch      = now.replace(hour=13, minute=32, second=0, microsecond=0)
    market_exit      = now.replace(hour=13, minute=26, second=0, microsecond=0)

    # å…ˆåˆ†æ”¯ï¼šç›¤å‰ã€ç›¤ä¸­ã€è½‰ç›¤å¾Œéæ¸¡ã€ç›¤å¾Œ
    if pre_market_start <= now < market_start:
        print(f"ç›®å‰ç‚º {now_str}ï¼Œç›¤å‰æ™‚é–“ï¼Œåªæ›´æ–°æ—¥Kç·šè³‡æ–™ã€‚")
        
        # ---------- å–å¾— / æ¯”å°æ—¥ Kï¼ˆç›¤å‰ï¼‰ ----------
        existing_auto_daily_data = {}
        if os.path.exists('auto_daily.json'):
            with open('auto_daily.json', 'r', encoding='utf-8') as f:
                try:
                    existing_auto_daily_data = json.load(f)
                except json.JSONDecodeError:
                    existing_auto_daily_data = {}
        else:
            print("auto_daily.json ä¸å­˜åœ¨ï¼Œå°‡å»ºç«‹æ–°çš„ã€‚")

        print("é–‹å§‹å–å¾—æ—¥Kç·šæ•¸æ“šä¸¦èˆ‡ç¾æœ‰è³‡æ–™æ¯”å°...")
        auto_daily_data = {}
        data_is_same = True
        initial_api_count = 0
        symbols_fetched = 0

        for symbol in symbols_to_analyze[:max_symbols_to_fetch]:
            if initial_api_count >= 55:
                print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                time_module.sleep(60)
                initial_api_count = 0
            daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
            initial_api_count += 1
            if daily_kline_df.empty:
                print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                continue
            daily_kline_data = daily_kline_df.to_dict(orient='records')
            auto_daily_data[symbol] = daily_kline_data
            existing_data = existing_auto_daily_data.get(symbol)
            if existing_data != daily_kline_data:
                data_is_same = False
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                existing_auto_daily_data[symbol] = daily_kline_data
            else:
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")
            symbols_fetched += 1

        if not data_is_same:
            remaining_symbols = symbols_to_analyze[max_symbols_to_fetch:]
            print(f"ç™¼ç¾å‰ {max_symbols_to_fetch} æ”¯è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šæœ‰æ›´æ–°ï¼Œé–‹å§‹å–å¾—å‰©é¤˜è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šä¸¦æ›´æ–°ã€‚")
            for symbol in remaining_symbols:
                if initial_api_count >= 55:
                    print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                    time_module.sleep(60)
                    initial_api_count = 0
                daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
                initial_api_count += 1
                if daily_kline_df.empty:
                    print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                    continue
                daily_kline_data = daily_kline_df.to_dict(orient='records')
                auto_daily_data[symbol] = daily_kline_data
                existing_data = existing_auto_daily_data.get(symbol)
                if existing_data != daily_kline_data:
                    print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                    existing_auto_daily_data[symbol] = daily_kline_data
                else:
                    print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")

        if symbols_fetched < max_symbols_to_fetch:
            print(f"æ³¨æ„ï¼šåƒ…å–å¾—äº† {symbols_fetched} æ”¯è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šã€‚")

        with open('auto_daily.json', 'w', encoding='utf-8') as f:
            json.dump(existing_auto_daily_data, f, ensure_ascii=False, indent=4)

        print(f"{YELLOW}å·²æ›´æ–° auto_daily.jsonã€‚{RESET}")
        print(f"{YELLOW}ç›¤å‰æ›´æ–°å®Œæˆã€‚{RESET}")

        # âœ… é€™é‚Šæ–°å¢ï¼šç­‰å¾…åˆ° 09:00 è‡ªå‹•åˆ‡å…¥ç›¤ä¸­äº¤æ˜“æ¨¡å¼
        now = datetime.now()
        wait_seconds = (market_start - now).total_seconds()
        if wait_seconds > 0:
            print(f"ç­‰å¾… {wait_seconds/60:.1f} åˆ†é˜ç›´åˆ°é–‹ç›¤é–‹å§‹ç›¤ä¸­äº¤æ˜“...")
            time_module.sleep(wait_seconds)

        # âœ… ç­‰å¾…å®Œå¾Œè‡ªå‹•æ›´æ–°ç¾åœ¨æ™‚é–“ï¼Œé€²å…¥ç›¤ä¸­æµç¨‹
        now = datetime.now()


    elif market_start <= now <= market_end:
        print(f"ç›®å‰ç‚º {now_str}ï¼Œç›¤ä¸­äº¤æ˜“æ™‚é–“ã€‚")
        # ---------- 1. ç¬¬ä¸€æ¬¡åŸ·è¡Œè©¢å•ä½¿ç”¨è€… ----------
        if mode == 'full':
            try:
                wait_minutes = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“ï¼ˆåˆ†é˜ï¼‰ï¼š"))
            except ValueError:
                print("ç­‰å¾…æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸ã€‚")
                return
            hold_minutes_input = input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥ 'F' ä»£è¡¨æŒæœ‰åˆ°13:30å¼·åˆ¶å‡ºå ´ï¼‰ï¼š")
            if hold_minutes_input.upper() == 'F':
                hold_minutes = None
            else:
                try:
                    hold_minutes = int(hold_minutes_input)
                except ValueError:
                    print("æŒæœ‰æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸æˆ– 'F'ã€‚")
                    return
        else:
            assert wait_minutes is not None

        # ---------- 2. å–å¾— / æ¯”å°æ—¥ Kï¼ˆç›¤ä¸­ä¹Ÿéœ€è¦æ—¥Kï¼‰ ----------
        existing_auto_daily_data = {}
        if os.path.exists('auto_daily.json'):
            with open('auto_daily.json', 'r', encoding='utf-8') as f:
                try:
                    existing_auto_daily_data = json.load(f)
                except json.JSONDecodeError:
                    existing_auto_daily_data = {}
        print("é–‹å§‹å–å¾—æ—¥Kç·šæ•¸æ“šä¸¦èˆ‡ç¾æœ‰è³‡æ–™æ¯”å°...")
        auto_daily_data = {}
        data_is_same = True
        initial_api_count = 0
        symbols_fetched = 0
        for symbol in symbols_to_analyze[:max_symbols_to_fetch]:
            if initial_api_count >= 55:
                print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                time_module.sleep(60)
                initial_api_count = 0
            daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
            initial_api_count += 1
            if daily_kline_df.empty:
                print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                continue
            daily_kline_data = daily_kline_df.to_dict(orient='records')
            auto_daily_data[symbol] = daily_kline_data
            existing_data = existing_auto_daily_data.get(symbol)
            if existing_data != daily_kline_data:
                data_is_same = False
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                existing_auto_daily_data[symbol] = daily_kline_data
            else:
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")
            symbols_fetched += 1
        if not data_is_same:
            remaining_symbols = symbols_to_analyze[max_symbols_to_fetch:]
            print(f"ç™¼ç¾å‰ {max_symbols_to_fetch} æ”¯è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šæœ‰æ›´æ–°ï¼Œé–‹å§‹å–å¾—å‰©é¤˜è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šä¸¦æ›´æ–°ã€‚")
            for symbol in remaining_symbols:
                if initial_api_count >= 55:
                    print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                    time_module.sleep(60)
                    initial_api_count = 0
                daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
                initial_api_count += 1
                if daily_kline_df.empty:
                    print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                    continue
                daily_kline_data = daily_kline_df.to_dict(orient='records')
                auto_daily_data[symbol] = daily_kline_data
                existing_data = existing_auto_daily_data.get(symbol)
                if existing_data != daily_kline_data:
                    print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                    existing_auto_daily_data[symbol] = daily_kline_data
                else:
                    print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")
        if symbols_fetched < max_symbols_to_fetch:
            print(f"æ³¨æ„ï¼šåƒ…å–å¾—äº† {symbols_fetched} æ”¯è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šã€‚")
        with open('auto_daily.json', 'w', encoding='utf-8') as f:
            json.dump(existing_auto_daily_data, f, ensure_ascii=False, indent=4)
        print("å·²æ›´æ–° auto_daily.jsonã€‚")

        # ---------- 3. è£œé½Šä¸€åˆ†Kï¼ˆç›¤ä¸­æ¯æ¬¡éƒ½è¦å°ç•¶æ—¥åšåˆæ¬¡è£œé½Šï¼‰ ----------
        fetch_time = datetime.now() - timedelta(minutes=1)
        trading_day = fetch_time.strftime('%Y-%m-%d')
        '''
        print(f"æ—¥æœŸæ¨£æœ¬ï¼š{trading_day}")
        '''
        
        yesterday_close_prices = {}
        # ï¼ˆæ­¤è™•ä¿æŒã€Œè®€æ˜¨æ”¶ã€é‚è¼¯ä¸è®Šï¼‰
        for symbol in symbols_to_analyze:
            daily_data = existing_auto_daily_data.get(symbol, [])
            if not daily_data:
                daily_kline_df = fetch_daily_kline_data(client, symbol, days=5)
                if not daily_kline_df.empty:
                    daily_kline_data = daily_kline_df.to_dict(orient='records')
                    existing_auto_daily_data[symbol] = daily_kline_data
                    with open('auto_daily.json', 'w', encoding='utf-8') as f:
                        json.dump(existing_auto_daily_data, f, ensure_ascii=False, indent=4)
                if len(existing_auto_daily_data[symbol]) > 1:
                    now2 = datetime.now()
                    weekday = now2.weekday()
                    if 0 <= weekday <= 4 and 8 <= now2.hour < 15:
                        yesterday_close = existing_auto_daily_data[symbol][0].get('close', 0)
                    else:
                        yesterday_close = existing_auto_daily_data[symbol][1].get('close', 0)
                else:
                    yesterday_close = 0
                yesterday_close_prices[symbol] = yesterday_close
            else:
                sorted_daily_data = sorted(daily_data, key=lambda x: x['date'], reverse=True)
                if len(sorted_daily_data) > 1:
                    now2 = datetime.now()
                    weekday = now2.weekday()
                    if 0 <= weekday <= 4 and 8 <= now2.hour < 15:
                        yesterday_close = sorted_daily_data[0].get('close', 0)
                    else:
                        yesterday_close = sorted_daily_data[1].get('close', 0)
                else:
                    yesterday_close = sorted_daily_data[0].get('close', 0)
                yesterday_close_prices[symbol] = yesterday_close

        # ä¸€åˆ†Kåˆæ¬¡è£œé½Š

        # æ¸¬è©¦è¨Šæ¯
        t_fetch_hist = time_module.perf_counter()
        print("ğŸ” [æ­·å²] é–‹å§‹è£œé½Šä¸€åˆ†Kè³‡æ–™...")
        
        market_real_end       = now.replace(hour=13, minute=30, second=0, microsecond=0)

        if now < market_real_end :
            full_intraday_end = (now - timedelta(minutes=1)).strftime('%H:%M')
        else:
            full_intraday_end = "13:30"


        print(f"{YELLOW}é–‹å§‹è£œé½Šä»Šæ—¥ 09:00 åˆ° {full_intraday_end} çš„ä¸€åˆ†Kæ•¸æ“š...{RESET}")

        auto_intraday_data = {}
        initial_api_count = 0
        with ThreadPoolExecutor(max_workers=200) as executor:
            future_to_symbol = {}
            for symbol in symbols_to_analyze:
                if initial_api_count >= 200:
                    time_module.sleep(60)
                    initial_api_count = 0
                yc = yesterday_close_prices.get(symbol, 0)
                if yc == 0:
                    continue
                future = executor.submit(
                    fetch_intraday_data,
                    client=client,
                    symbol=symbol,
                    trading_day=trading_day,
                    yesterday_close_price=yc,
                    start_time="09:00",
                    end_time=full_intraday_end
                )
                future_to_symbol[future] = symbol
                initial_api_count += 1
            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                df = future.result()
                if df.empty:
                    continue
                updated_records = []
                records = df.to_dict(orient='records')
                for i, candle in enumerate(records):
                    past_candles = records[:i]
                    updated_candle = calculate_2min_pct_increase_and_highest(candle, past_candles)
                    updated_records.append(updated_candle)
                df = pd.DataFrame(updated_records)
                auto_intraday_data[symbol] = df.to_dict(orient='records')

        # æ¸¬è©¦è¨Šæ¯
        print(f"âœ… [æ­·å²] è£œé½Šå®Œæˆï¼Œè€—æ™‚ï¼š{time_module.perf_counter() - t_fetch_hist:.2f} ç§’")
        t_save_json = time_module.perf_counter()

        save_auto_intraday_data(auto_intraday_data)

        initialize_triggered_limit_up(auto_intraday_data)

        # æ¸¬è©¦è¨Šæ¯
        print(f"ğŸ“ [å¯«æª”] å¯«å…¥ auto_intraday.json å®Œæˆï¼Œè€—æ™‚ï¼š{time_module.perf_counter() - t_save_json:.2f} ç§’")
        '''
        print("å·²æ›´æ–° auto_intraday.jsonã€‚")
        '''
        # ---------- 4. ç›¤ä¸­ä¸»è¿´åœˆ ----------
        print("é–‹å§‹ç›¤ä¸­äº¤æ˜“ç›£æ§ï¼Œè¼¸å…¥ 'Q' è¿”å›ä¸»é¸å–®ï¼š ", end='', flush=True)

        # å•Ÿå‹•éé˜»å¡ Q éµç›£è½èˆ‡é¸å–®è§¸ç™¼
        threading.Thread(target=monitor_quit_key, daemon=True).start()
        threading.Thread(target=check_quit_flag_loop, daemon=True).start()

        # åˆå§‹åŒ–ç›¤ä¸­ç‹€æ…‹
        has_exited = False
        current_position = None
        hold_time = 0
        message_log = []
        already_entered_stocks = []
        stop_loss_triggered = False
        final_check_active = False
        final_check_count = 0
        in_waiting_period = False
        waiting_time = 0
        leader = None
        tracking_stocks = set()
        previous_rise_values = {}
        leader_peak_rise = None
        leader_rise_before_decline = None
        first_condition_one_time = None
        can_trade = True

        exit_live_done = False
        restart_to_post = False

        while not stop_trading:
            now_loop = datetime.now()

            if now_loop >= market_exit and not exit_live_done:
                print(f"ğŸ” 13:26 è§¸ç™¼ï¼šæª¢æŸ¥è§¸åƒ¹å§”è¨—å–®ï¼Œç›®å‰å°šæœ‰ {len(to.conditions)} æª”è‚¡ç¥¨åœ¨è§¸åƒ¹å§”è¨—ä¸­ã€‚")
                exit_trade_live()
                exit_live_done = True

            if market_end < now_loop < post_switch:
                print(f"\nç›®å‰ç‚º {now_loop.strftime('%Y-%m-%d %H:%M:%S')}ï¼Œç›¤å¾Œéæ¸¡æœŸï¼Œç­‰å¾…åˆ‡ç›¤å¾Œæµç¨‹â€¦")
                time_module.sleep((post_switch - now_loop).total_seconds())
                continue

            if now_loop >= post_switch:
                print("\næ”¶ç›¤å¾Œ +1 åˆ†é˜ï¼Œåˆ‡æ›åˆ°ç›¤å¾Œæµç¨‹â€¦")
                restart_to_post = True
                break

            if market_start <= now_loop <= market_end:
                now_sec = datetime.now().second
                time_module.sleep(60 - now_sec)

                fetch_time = datetime.now() - timedelta(minutes=1)
                trading_day = fetch_time.strftime('%Y-%m-%d')
                fetch_time_str = fetch_time.strftime('%H:%M')
                if fetch_time.time() > market_end.time():
                    fetch_time_str = "13:30"
                
                # æ¸¬è©¦è¨Šæ¯
                t_fetch_realtime = time_module.perf_counter()
                print(f"{YELLOW}â± [å³æ™‚] é–‹å§‹å–å¾— {fetch_time_str} çš„ä¸€åˆ†Kè³‡æ–™...{RESET}")

                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                print("\n" + "=" * 50)
                print(f"\n{timestamp} å¸‚å ´é–‹ç›¤ä¸­ï¼Œå–å¾— {fetch_time_str} åˆ†çš„å³æ™‚ä¸€åˆ†Kæ•¸æ“šã€‚")
                print(f"æ­£åœ¨å–å¾—ä¸€åˆ†Kæ•¸æ“šå¾ {fetch_time_str} åˆ° {fetch_time_str}...")

                updated_intraday_data = {}
                with ThreadPoolExecutor(max_workers=200) as executor:
                    future_to_symbol = {}
                    for symbol in symbols_to_analyze:
                        yc = yesterday_close_prices.get(symbol, 0)
                        if yc == 0:
                            continue
                        fut = executor.submit(
                            fetch_realtime_intraday_data,
                            client=client,
                            symbol=symbol,
                            trading_day=trading_day,
                            yesterday_close_price=yc,
                            start_time=fetch_time_str,
                            end_time=fetch_time_str
                        )
                        future_to_symbol[fut] = symbol
                    for fut in as_completed(future_to_symbol):
                        sym = future_to_symbol[fut]
                        df = fut.result()
                        if df.empty:
                            continue
                        candle = df.to_dict(orient='records')[0]
                        candle = calculate_2min_pct_increase_and_highest(candle, auto_intraday_data.get(sym, []))
                        if 'æ¼²åœåƒ¹' in candle:
                            candle['æ¼²åœåƒ¹'] = truncate_to_two_decimals(candle['æ¼²åœåƒ¹'])
                        updated_intraday_data.setdefault(sym, []).append(candle)

                for sym, lst in updated_intraday_data.items():
                    auto_intraday_data.setdefault(sym, []).extend(lst)
                    auto_intraday_data[sym] = auto_intraday_data[sym][-1000:]

                # æ¸¬è©¦è¨Šæ¯
                print(f"âœ… [å³æ™‚] ä¸€åˆ†Kå–å¾—å®Œæˆï¼Œè€—æ™‚ï¼š{time_module.perf_counter() - t_fetch_realtime:.2f} ç§’")
                t_save_json = time_module.perf_counter()

                save_auto_intraday_data(auto_intraday_data)

                # æ¸¬è©¦è¨Šæ¯
                print(f"ğŸ“ [å¯«æª”] å¯«å…¥ auto_intraday.json å®Œæˆï¼Œè€—æ™‚ï¼š{time_module.perf_counter() - t_save_json:.2f} ç§’")
                print("=" * 50)

                process_live_trading_logic(
                    symbols_to_analyze,
                    fetch_time_str,
                    wait_minutes,
                    hold_minutes,
                    message_log,
                    False,
                    has_exited,
                    current_position,
                    hold_time,
                    already_entered_stocks,
                    stop_loss_triggered,
                    final_check_active,
                    final_check_count,
                    in_waiting_period,
                    waiting_time,
                    leader,
                    tracking_stocks,
                    previous_rise_values,
                    leader_peak_rise,
                    leader_rise_before_decline,
                    first_condition_one_time,
                    can_trade,
                    group_positions
                )

        # è‹¥æœ‰åˆ‡æ›åˆ°ç›¤å¾Œ
        if restart_to_post:
            start_trading(mode='post', wait_minutes=wait_minutes, hold_minutes=hold_minutes)
            return

        print("å·²åœæ­¢äº¤æ˜“ï¼Œè¿”å›ä¸»é¸å–®")

    else:  # now >= post_switch
        print(f"ç›®å‰ç‚º {now_str}ï¼Œç›¤å¾Œæ™‚é–“ï¼Œä¸éœ€è¦æ›´æ–°ä»»ä½•æ•¸æ“šï¼Œè¿”å›ä¸»é¸å–®ã€‚")
        return

# ------------------ äº¤æ˜“ç¨‹å¼ï¼šç™»å…¥å¸³æˆ¶ ------------------
def login():
    file_path = "shioaji_logic.py"  # è¦æ›´æ–°çš„æª”æ¡ˆè·¯å¾‘

    print('\n' + '=' * 50 + '\n')
    print("ç•¶å‰ api key ç‚ºï¼š" + shioaji_logic.TEST_API_KEY)
    print("ç•¶å‰æ†‘è­‰è·¯å¾‘ç‚ºï¼š" + shioaji_logic.CA_CERT_PATH)
    print("ç•¶å‰æ†‘è­‰å¯†ç¢¼ç‚ºï¼š" + shioaji_logic.CA_PASSWORD)
    print('\n' + '=' * 50)
    print("1. ä¿®æ”¹ api keyã€2. ä¿®æ”¹ api secretã€3. ä¿®æ”¹æ†‘è­‰è·¯å¾‘ã€4. ä¿®æ”¹æ†‘è­‰å¯†ç¢¼")
    api_setting = input("è«‹é¸æ“‡åŠŸèƒ½ï¼š")
    if api_setting == "1":
        new_api_key = input("è«‹è¼¸å…¥æ–°çš„ api keyï¼š")
        update_variable(file_path, "TEST_API_KEY", new_api_key)
    elif api_setting == "2":
        new_api_secret = input("è«‹è¼¸å…¥æ–°çš„ api secretï¼š")
        update_variable(file_path, "TEST_API_SECRET", new_api_secret)
    elif api_setting == "3":
        new_ca_path = input("è«‹è¼¸å…¥æ–°çš„æ†‘è­‰è·¯å¾‘ï¼š")
        update_variable(file_path, "CA_CERT_PATH", new_ca_path, is_raw=True)
    elif api_setting == "4":
        new_ca_password = input("è«‹è¼¸å…¥æ–°çš„æ†‘è­‰å¯†ç¢¼ï¼š")
        update_variable(file_path, "CA_PASSWORD", new_ca_password)
    else:
        print("è«‹è¼¸å…¥åˆæ³•å­—å…ƒ...")
        login()

def update_variable(file_path, var_name, new_value, is_raw=False):
    """
    æ›´æ–°æŒ‡å®šæª”æ¡ˆä¸­ä»¥ var_name é–‹é ­çš„è®Šæ•¸çš„å€¼ã€‚
    è‹¥ is_raw ç‚º Trueï¼Œå‰‡æœƒä»¥ raw å­—ä¸²æ ¼å¼å„²å­˜ï¼ˆä¾‹å¦‚ CA_CERT_PATHï¼‰
    """
    lines = []
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            # å¦‚æœè©²è¡Œä»¥è®Šæ•¸åç¨±é–‹é ­ï¼Œå‰‡æ›¿æ›è©²è¡Œ
            if line.lstrip().startswith(var_name + " ="):
                if is_raw:
                    new_line = f'{var_name} = r"{new_value}"\n'
                else:
                    new_line = f'{var_name} = "{new_value}"\n'
                lines.append(new_line)
            else:
                lines.append(line)
    with open(file_path, "w", encoding="utf-8") as f:
        f.writelines(lines)
    print(f"{var_name} å·²æ›´æ–°ç‚º: {new_value}")
    importlib.reload(shioaji_logic)

#ç™»å…¥
api = sj.Shioaji(simulation=True)
accounts = api.login(api_key = shioaji_logic.TEST_API_KEY, secret_key = shioaji_logic.TEST_API_SECRET)
api.activate_ca(
    ca_path=shioaji_logic.CA_CERT_PATH,
    ca_passwd=shioaji_logic.CA_PASSWORD
)
'''
print("ca_path:", shioaji_logic.CA_CERT_PATH)
print("ca_password:", shioaji_logic.CA_PASSWORD)
'''




# ------------------ ç®¡ç†æ—ç¾¤ ------------------
def manage_groups():
    current_page = 0
    page_size = 5
    groups = load_matrix_dict_analysis()
    total_pages = (len(groups) + page_size - 1) // page_size
    total_page = 1

    def display_page(page):
        load_twse_name_map()                     # â† ç¢ºä¿å·²è¼‰å…¥å°ç…§è¡¨
        start = page * page_size
        end   = start + page_size
        if total_pages == 0:
            print("=" * 50)
            print(f"æ—ç¾¤åŠå€‹è‚¡åˆ—è¡¨ - ç¬¬ {page + 1} é  / å…± {total_page} é ")
            print("=" * 50)
        else:
            print("=" * 50)
            print(f"æ—ç¾¤åŠå€‹è‚¡åˆ—è¡¨ - ç¬¬ {page + 1} é  / å…± {total_pages} é ")
            print("=" * 50)
        for idx, (group, stocks) in enumerate(list(groups.items())[start:end], start=1):
            print(f"æ—ç¾¤: {group}")
            if stocks:
                for s_idx, code in enumerate(stocks, start=1):
                    cname = get_stock_name(code)
                    print(f"  {str(s_idx).rjust(2)}. {code:<6} {cname}")
            else:
                print("  (æ­¤æ—ç¾¤ç›®å‰æ²’æœ‰å€‹è‚¡)")
            print("-" * 50)
        print("=" * 50)
        if current_page == total_pages - 1:
            print("å·²é¡¯ç¤ºæ‰€æœ‰æ—ç¾¤åŠå€‹è‚¡ã€‚")
        print("=" * 50)

    while True:
        display_page(current_page)
        print("\nPï¼šä¸Šä¸€é ã€Qï¼šä¸‹ä¸€é ã€1ï¼šæ–°å¢æ—ç¾¤/å€‹è‚¡ï¼›ã€2ï¼šåˆªé™¤æ—ç¾¤/å€‹è‚¡ã€0ï¼šè¿”å›ä¸»é¸å–®")
        choice = input("è«‹é¸æ“‡æ“ä½œ: ").strip()

        if choice == "1":
            add_group_or_stock(groups)
        elif choice == "2":
            delete_group_or_stock(groups)
        elif choice.upper() == "P":
            if current_page > 0:
                current_page -= 1
            else:
                print("å·²ç¶“æ˜¯ç¬¬ä¸€é ï¼")
        elif choice.upper() == "Q":
            if current_page < total_pages - 1:
                current_page += 1
            else:
                print("å·²ç¶“æ˜¯æœ€å¾Œä¸€é ï¼")
        elif choice == "0":
            save_matrix_dict(groups)
            break
        else:
            print("ç„¡æ•ˆé¸é …ï¼Œè«‹é‡æ–°é¸æ“‡ã€‚")

#------------------ ç®¡ç†æ—ç¾¤ï¼šæ–°å¢æ—ç¾¤/å€‹è‚¡ ------------------
def add_group_or_stock(groups):
    print("\n==============================")
    print("1ï¼šæ–°å¢æ—ç¾¤ã€2ï¼šæ–°å¢æ—ç¾¤ä¸­çš„å€‹è‚¡ã€0ï¼šè¿”å›é¸å–®")
    print("\n==============================")
    choice = input("è«‹é¸æ“‡æ“ä½œ: ").strip()

    if choice == "1":
        new_group = input("è¼¸å…¥æ–°æ—ç¾¤åç¨±: ").strip()
        if not new_group:
            print("æ—ç¾¤åç¨±ä¸èƒ½ç‚ºç©ºã€‚")
            add_group_or_stock(groups)
        if new_group in groups:
            print(f"æ—ç¾¤ '{new_group}' å·²å­˜åœ¨ã€‚")
        else:
            groups[new_group] = []
            print(f"æ—ç¾¤ '{new_group}' æ–°å¢æˆåŠŸã€‚")
    
    elif choice == "2":
        group_name = input("è¼¸å…¥è¦æ–°å¢å€‹è‚¡çš„æ—ç¾¤åç¨±: ").strip()
        if not group_name:
            print("æ—ç¾¤åç¨±ä¸èƒ½ç‚ºç©ºã€‚")
            add_group_or_stock(groups)
        if group_name in groups:
            current_stocks = groups[group_name]
            print(f"\n==============================")
            print(f"æ—ç¾¤ '{group_name}' ä¸­ç›®å‰çš„å€‹è‚¡:")
            if current_stocks:
                for idx, stock in enumerate(current_stocks, start=1):
                    print(f"  {str(idx).rjust(2)}. {stock}")
            else:
                print("  ç„¡")
            print("==============================\n")
            
            print(f"é–‹å§‹æ–°å¢å€‹è‚¡åˆ°æ—ç¾¤ '{group_name}'ã€‚")
            print("è«‹è¼¸å…¥å€‹è‚¡ä»£è™Ÿï¼Œè¼¸å…¥ 'Q' ä»¥é€€å‡ºæ–°å¢æ¨¡å¼ã€‚")
            
            while True:
                new_stock = input("è¼¸å…¥å€‹è‚¡ä»£è™Ÿ (æˆ– 'Q' é€€å‡º): ").strip()
                if new_stock.upper() == "Q":
                    print("é€€å‡ºæ–°å¢å€‹è‚¡æ¨¡å¼ã€‚")
                    break
                elif not new_stock:
                    print("è¼¸å…¥ç„¡æ•ˆï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")
                    continue
                elif new_stock in groups[group_name]:
                    print(f"å€‹è‚¡ '{new_stock} {get_stock_name(new_stock)}' å·²å­˜åœ¨æ–¼æ—ç¾¤ '{group_name}' ä¸­ã€‚")
                else:
                    groups[group_name].append(new_stock)
                    print(f"å€‹è‚¡ '{new_stock} {get_stock_name(new_stock)}' å·²æ–°å¢è‡³æ—ç¾¤ '{group_name}'ã€‚")
        else:
            print(f"æ—ç¾¤ '{group_name}' ä¸å­˜åœ¨ã€‚")
    
    elif choice == "0":
        print("è¿”å›ä¸»é¸å–®ã€‚")
        manage_groups()

    else:
        print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°é¸æ“‡ã€‚")

#------------------ ç®¡ç†æ—ç¾¤ï¼šåˆªé™¤æ—ç¾¤/å€‹è‚¡ ------------------
def delete_group_or_stock(groups):
    print("\n==============================")
    print("1ï¼šåˆªé™¤æ—ç¾¤ã€2ï¼šåˆªé™¤æ—ç¾¤ä¸­çš„å€‹è‚¡ã€0ï¼šè¿”å›é¸å–®")
    print("\n==============================")
    choice = input("è«‹é¸æ“‡æ“ä½œ: ").strip()

    if choice == "1":
        group_name = input("è¼¸å…¥è¦åˆªé™¤çš„æ—ç¾¤åç¨±: ").strip()
        if not group_name:
            print("æ—ç¾¤åç¨±ä¸èƒ½ç‚ºç©ºã€‚")
            delete_group_or_stock(groups)
        if group_name in groups:
            confirm = input(f"ç¢ºå®šè¦åˆªé™¤æ—ç¾¤ '{group_name}' å—ï¼Ÿ (Y/N): ").strip().upper()
            if confirm == "Y":
                del groups[group_name]
                print(f"æ—ç¾¤ '{group_name}' å·²åˆªé™¤ã€‚")
            else:
                print("å–æ¶ˆåˆªé™¤ã€‚")
        else:
            print(f"æ—ç¾¤ '{group_name}' ä¸å­˜åœ¨ã€‚")

    elif choice == "2":
        group_name = input("è¼¸å…¥è¦åˆªé™¤å€‹è‚¡çš„æ—ç¾¤åç¨±: ").strip()
        if not group_name:
            print("æ—ç¾¤åç¨±ä¸èƒ½ç‚ºç©ºã€‚")
            delete_group_or_stock(groups)
        if group_name in groups:
            current_stocks = groups[group_name]
            print(f"\n==============================")
            print(f"æ—ç¾¤ '{group_name}' ä¸­ç›®å‰çš„å€‹è‚¡:")
            if current_stocks:
                for idx, stock in enumerate(current_stocks, start=1):
                    print(f"  {str(idx).rjust(2)}. {stock}")
            else:
                print("  ç„¡")
            print("==============================\n")

            if not current_stocks:
                print(f"æ—ç¾¤ '{group_name}' ä¸­ç›®å‰æ²’æœ‰ä»»ä½•å€‹è‚¡ã€‚")
                delete_group_or_stock(groups)

            print(f"é–‹å§‹åˆªé™¤å€‹è‚¡å¾æ—ç¾¤ '{group_name}'ã€‚")
            print("è«‹è¼¸å…¥è¦åˆªé™¤çš„å€‹è‚¡ä»£è™Ÿï¼Œè¼¸å…¥ 'Q' ä»¥é€€å‡ºåˆªé™¤æ¨¡å¼ã€‚")

            while True:
                stock_name = input("è¼¸å…¥å€‹è‚¡ä»£è™Ÿ (æˆ– 'Q' é€€å‡º): ").strip()
                if stock_name.upper() == "Q":
                    print("é€€å‡ºåˆªé™¤å€‹è‚¡æ¨¡å¼ã€‚")
                    break
                elif not stock_name:
                    print("è¼¸å…¥ç„¡æ•ˆï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")
                    continue
                elif stock_name not in groups[group_name]:
                    print(f"å€‹è‚¡ '{stock_name}' ä¸å­˜åœ¨æ–¼æ—ç¾¤ '{group_name}' ä¸­ã€‚")
                else:
                    confirm = input(f"ç¢ºå®šè¦åˆªé™¤å€‹è‚¡ '{stock_name} {get_stock_name(stock_name)} 'å—ï¼Ÿ (Y/N): ").strip().upper()
                    if confirm == "Y":
                        groups[group_name].remove(stock_name)
                        print(f"å€‹è‚¡ '{stock_name}' å·²å¾æ—ç¾¤ '{group_name}' ä¸­åˆªé™¤ã€‚")
                        if not groups[group_name]:
                            print(f"æ—ç¾¤ '{group_name}' ç¾åœ¨å·²ç¶“æ²’æœ‰ä»»ä½•å€‹è‚¡ã€‚")
                    else:
                        print("å–æ¶ˆåˆªé™¤ã€‚")
        else:
            print(f"æ—ç¾¤ '{group_name}' ä¸å­˜åœ¨ã€‚")

    elif choice == "0":
        print("è¿”å›ä¸»é¸å–®ã€‚")
        manage_groups()

    else:
        print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°é¸æ“‡ã€‚")




# ------------------ è¨­å®šé¸å–® ------------------
def settings_menu():
    global capital_per_stock, transaction_fee, transaction_discount, trading_tax
    global below_50, price_gap_50_to_100, price_gap_100_to_500, price_gap_500_to_1000, price_gap_above_1000
    global allow_reentry_after_stop_loss
    while True:
        print("\nè¨­å®šé¸å–®ï¼š")
        print(f"1. è¨­å®šæ¯æª”è‚¡ç¥¨æŠ•å…¥è³‡æœ¬é¡ï¼ˆç›®å‰ç‚º {capital_per_stock} è¬å…ƒï¼‰")
        print(f"2. æ‰‹çºŒè²»è¨­å®šï¼Œç›®å‰ç‚º {transaction_fee}%")
        print(f"3. æ‰‹çºŒè²»æŠ˜æ•¸è¨­å®šï¼Œç›®å‰ç‚º {transaction_discount}%")
        print(f"4. è­‰äº¤ç¨…è¨­å®šï¼Œç›®å‰ç‚º {trading_tax}%")
        print("5. åƒ¹å·®åœæè¨­å®š")
        print("6. åœæå†é€²å ´è¨­å®š")
        print("0. è¿”å›ä¸»é¸å–®")
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if choice == "1":
            set_capital_per_stock()
        elif choice == "2":
            transaction_fee = float(input("è«‹è¼¸å…¥æ‰‹çºŒè²»ï¼ˆ%ï¼‰ï¼š"))
            save_settings()
        elif choice == "3":
            transaction_discount = float(input("è«‹è¼¸å…¥æ‰‹çºŒè²»æŠ˜æ•¸ï¼ˆ%ï¼‰ï¼š"))
            save_settings()
        elif choice == "4":
            trading_tax = float(input("è«‹è¼¸å…¥è­‰äº¤ç¨…ï¼ˆ%ï¼‰ï¼š"))
            save_settings()
        elif choice == "5":
            price_gap_stop_loss_menu()
        elif choice == "6":
            stop_loss_reentry_menu()
        elif choice == "0":
            main_menu()
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

# ------------------ è¨­å®šé¸å–®ï¼šè¨­å®šæ¯æª”è³‡æœ¬é¡ ------------------
def set_capital_per_stock():
    global capital_per_stock
    capital_per_stock = int(input("è«‹è¼¸å…¥æ¯æª”æŠ•å…¥è³‡æœ¬é¡ï¼ˆè¬å…ƒï¼‰ï¼š"))
    print(f"æ¯æª”æŠ•å…¥è³‡æœ¬é¡å·²è¨­å®šç‚ºï¼š{capital_per_stock} è¬å…ƒ")
    save_settings()

# ------------------ è¨­å®šé¸å–®ï¼šåƒ¹å·®åœæè¨­å®š ------------------
def price_gap_stop_loss_menu():
    global below_50, price_gap_50_to_100, price_gap_100_to_500, price_gap_500_to_1000, price_gap_above_1000
    while True:
        print(f"1. 50å…ƒä»¥ä¸‹è‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {below_50} å…ƒ")
        print(f"2. 50~100å…ƒè‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {price_gap_50_to_100} å…ƒ")
        print(f"3. 100~500å…ƒè‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {price_gap_100_to_500} å…ƒ")
        print(f"4. 500~1000å…ƒè‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {price_gap_500_to_1000} å…ƒ")
        print(f"5. 1000å…ƒä»¥ä¸Šè‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {price_gap_above_1000} å…ƒ")
        print("6. è¿”å›ä¸Šä¸€é ")
        choice = input("è«‹é¸æ“‡è¦è¨­å®šçš„é …ç›®ï¼š")
        if choice == "1":
            below_50 = float(input("è«‹è¼¸å…¥50å…ƒä»¥ä¸‹è‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "2":
            price_gap_50_to_100 = float(input("è«‹è¼¸å…¥50~100å…ƒè‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "3":
            price_gap_100_to_500 = float(input("è«‹è¼¸å…¥100~500å…ƒè‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "4":
            price_gap_500_to_1000 = float(input("è«‹è¼¸å…¥500~1000å…ƒè‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "5":
            price_gap_above_1000 = float(input("è«‹è¼¸å…¥1000å…ƒä»¥ä¸Šè‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "6":
            break
        else:
            print("ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡è©¦ã€‚")
        save_settings()

# ------------------ è¨­å®šé¸å–®ï¼šåœæå†é€²å ´è¨­å®š ------------------
def stop_loss_reentry_menu():
    global allow_reentry_after_stop_loss
    while True:
        status = "é–‹å•Ÿ" if allow_reentry_after_stop_loss else "é—œé–‰"
        print(f"\nç›®å‰ç‚º({status}åœæå¾Œé€²å ´)")
        print("1.é–‹å•Ÿåœæå¾Œé€²å ´")
        print("2.é—œé–‰åœæå¾Œé€²å ´")
        print("3.è¿”å›ä¸Šä¸€é ")
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if choice == '1':
            allow_reentry_after_stop_loss = True
            print("å·²é–‹å•Ÿåœæå¾Œé€²å ´åŠŸèƒ½")
            save_settings()
        elif choice == '2':
            allow_reentry_after_stop_loss = False
            print("å·²é—œé–‰åœæå¾Œé€²å ´åŠŸèƒ½")
            save_settings()
        elif choice == '3':
            settings_menu()
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")




# ------------------ æ›´æ–°Kç·šæ•¸æ“š ------------------
def update_kline_data_menu():
    while True:
        print("\næ›´æ–°Kç·šæ•¸æ“šé¸å–®ï¼š")
        print("1. æ›´æ–°æ•¸æ“š")
        print("2. æŸ¥çœ‹æ•¸æ“š")
        print("0. è¿”å›ä¸»é¸å–®")
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if choice == '1':
            update_kline_data()
        elif choice == '2':
            symbol_to_group = load_symbol_to_group('./matrix_dict_analysis.json')
            view_kline_data('./intraday_kline_data.json', symbol_to_group)
        elif choice == '0':
            main_menu()
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

# ------------------ æ›´æ–°Kç·šæ•¸æ“šï¼šæ›´æ–°æ•¸æ“š ------------------
def update_kline_data():
    client, api_key = init_fugle_client()
    matrix_dict_analysis = load_matrix_dict_analysis()
    if not matrix_dict_analysis:
        print("æ²’æœ‰ä»»ä½•æ—ç¾¤è³‡æ–™ï¼Œè«‹å…ˆç®¡ç†æ—ç¾¤ã€‚")
        return

    print("æ­£åœ¨æ›´æ–°è™•ç½®è‚¡æ¸…å–®...")
    fetch_disposition_stocks(client, matrix_dict_analysis)
    print("è™•ç½®è‚¡æ¸…å–®å·²æ›´æ–°ã€‚")

    disposition_stocks = load_disposition_stocks()
    symbols_to_analyze = [sym for group in matrix_dict_analysis.values() for sym in group if sym not in disposition_stocks]

    # ===== â‘  æ›´æ–°æ—¥ K ç·šè³‡æ–™ =====
    print("âœ… é–‹å§‹æ›´æ–°æ—¥Kç·šæ•¸æ“šè‡³ daily_kline_data.json...")

    existing_daily_kline_data = {}
    if os.path.exists('daily_kline_data.json'):
        with open('daily_kline_data.json', 'r', encoding='utf-8') as f:
            try:
                existing_daily_kline_data = json.load(f)
            except json.JSONDecodeError:
                existing_daily_kline_data = {}
    else:
        print("âš ï¸ daily_kline_data.json ä¸å­˜åœ¨ï¼Œå°‡å»ºç«‹æ–°æª”æ¡ˆã€‚")

    data_is_same = True
    max_symbols_to_fetch = 20
    symbols_fetched = 0
    initial_api_count = 0

    for symbol in symbols_to_analyze[:max_symbols_to_fetch]:
        if initial_api_count >= 55:
            print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
            time_module.sleep(60)
            initial_api_count = 0

        daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
        initial_api_count += 1

        if daily_kline_df.empty:
            print(f"âŒ ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
            continue

        daily_kline_data = daily_kline_df.to_dict(orient='records')
        existing_data = existing_daily_kline_data.get(symbol)
        if existing_data != daily_kline_data:
            data_is_same = False
            print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
            existing_daily_kline_data[symbol] = daily_kline_data
        else:
            print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")
        symbols_fetched += 1

    if not data_is_same:
        print("ğŸ”„ ç™¼ç¾è³‡æ–™æœ‰ç•°å‹•ï¼Œé–‹å§‹æ›´æ–°å‰©é¤˜è‚¡ç¥¨...")
        remaining_symbols = symbols_to_analyze[max_symbols_to_fetch:]
        for symbol in remaining_symbols:
            if initial_api_count >= 55:
                print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                time_module.sleep(60)
                initial_api_count = 0

            daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
            initial_api_count += 1

            if daily_kline_df.empty:
                print(f"âŒ ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                continue

            daily_kline_data = daily_kline_df.to_dict(orient='records')
            existing_data = existing_daily_kline_data.get(symbol)
            if existing_data != daily_kline_data:
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                existing_daily_kline_data[symbol] = daily_kline_data
            else:
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")

    with open('daily_kline_data.json', 'w', encoding='utf-8') as f:
        json.dump(existing_daily_kline_data, f, indent=4, ensure_ascii=False)

    print("âœ… æ—¥Kç·šæ•¸æ“šå·²å¯«å…¥ daily_kline_data.jsonã€‚")

    # ===== â‘¡ æ›´æ–°ä¸€åˆ† K ç·šè³‡æ–™ =====
    print("âœ… é–‹å§‹æ›´æ–°ä¸€åˆ†Kç·šè³‡æ–™è‡³ intraday_kline_data.json...")

    def get_recent_trading_day():
        today = datetime.now().date()
        now_time = datetime.now().time()
        market_open = datetime.strptime("09:00", "%H:%M").time()
        market_close = datetime.strptime("13:30", "%H:%M").time()

        def last_friday(date):
            while date.weekday() != 4:
                date -= timedelta(days=1)
            return date

        weekday = today.weekday()

        if weekday == 5:  # Saturday
            return last_friday(today)
        elif weekday == 6:  # Sunday
            return last_friday(today)
        elif weekday == 0:  # Monday
            if now_time < market_open:
                return last_friday(today)
            elif market_open <= now_time <= market_close:
                return last_friday(today)
            else:
                return today
        else:  # Tuesday to Friday
            if now_time < market_open:
                return today - timedelta(days=1)
            elif market_open <= now_time <= market_close:
                return today - timedelta(days=1)
            else:
                return today

    intraday_kline_data = {}
    count = 0

    trading_day = get_recent_trading_day().strftime('%Y-%m-%d')
    print(f"ğŸ“… æœ¬æ¬¡ä¸€åˆ†Kæ›´æ–°ä½¿ç”¨äº¤æ˜“æ—¥: {trading_day}")

    for symbol in symbols_to_analyze:
        if count >= 55:
            print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
            time_module.sleep(60)
            count = 0

        daily_data = existing_daily_kline_data.get(symbol, [])
        if len(daily_data) < 2:
            print(f"{symbol} æ—¥Kè³‡æ–™ä¸è¶³ï¼Œç„¡æ³•åˆ¤æ–·æ˜¨æ”¶ï¼Œè·³éã€‚")
            continue
        yesterday_close_price = daily_data[1].get('close', 0)
        intraday_df = fetch_intraday_data(
            client=client,
            symbol=symbol,
            trading_day=trading_day,
            yesterday_close_price=yesterday_close_price,
            start_time="09:00",
            end_time="13:30"
        )
        count += 1

        if intraday_df.empty:
            print(f"ç„¡æ³•å–å¾— {symbol} çš„ä¸€åˆ†Kæ•¸æ“šï¼Œè·³éã€‚")
            continue
        
        updated_records = []
        records = intraday_df.to_dict(orient='records')
        for i, candle in enumerate(records): 
            updated_candle = calculate_2min_pct_increase_and_highest(candle, records[:i])
            updated_records.append(updated_candle)
        intraday_df = pd.DataFrame(updated_records)
        intraday_kline_data[symbol] = intraday_df.to_dict(orient='records')
        print(f"{symbol} çš„ä¸€åˆ†Kè³‡æ–™å·²åŠ å…¥ã€‚")

    intraday_kline_data_str = convert_datetime_to_str(intraday_kline_data)
    with open('intraday_kline_data.json', 'w', encoding='utf-8') as f:
        json.dump(intraday_kline_data_str, f, indent=4, ensure_ascii=False, default=str)
    print("âœ… ä¸€åˆ†Kç·šè³‡æ–™å·²å¯«å…¥ intraday_kline_data.jsonã€‚")

    consolidate_and_save_stock_symbols()
    print("âœ… è‚¡ç¥¨ä»£è™Ÿå·²çµ±æ•´ä¸¦å„²å­˜è‡³ nb_matrix_dict.jsonã€‚")


# ------------------ æ›´æ–°Kç·šæ•¸æ“šï¼šæŸ¥çœ‹æ•¸æ“š ------------------
def load_symbol_to_group(matrix_path):
    """
    å¾ matrix_dict_analysis.json è®€å–æ—ç¾¤è³‡æ–™ï¼Œä¸¦è½‰æ›æˆ symbol -> group å­—å…¸
    """
    with open(matrix_path, 'r', encoding='utf-8') as f:
        matrix_dict = json.load(f)
    
    symbol_to_group = {}
    for group, symbols in matrix_dict.items():
        for symbol in symbols:
            symbol_to_group[symbol] = group
    
    return symbol_to_group

# â¡ï¸ åŠ ï¼šè¨­å®šä¸­æ–‡é¡¯ç¤º
plt.rcParams['font.family'] = 'Microsoft JhengHei'

def view_kline_data(json_path, symbol_to_group):
    """
    æŸ¥çœ‹ç›¤ä¸­Kç·šæ•¸æ“šï¼Œä¾æ—ç¾¤åˆ†é¡ä¸¦ç¹ªè£½æ¨™æº–åŒ–closeèµ°å‹¢åœ–
    - ä½¿ç”¨Z-scoreæ¨™æº–åŒ–
    - è‡ªå‹•è™•ç†ä¸­æ–‡é¡¯ç¤º
    - æŒ‡å®šæ™‚é–“æ ¼å¼é¿å…è­¦å‘Š
    """
    # è®€å–JSON
    if not os.path.exists(json_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{json_path}")
        
    with open(json_path, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
    
    # æ•´ç†æˆ symbol -> DataFrame
    stock_data = {}
    for symbol, records in raw_data.items():
        df = pd.DataFrame(records)
        if 'time' in df.columns and 'close' in df.columns and 'date' in df.columns:
            # å…ˆåˆä½µæ—¥æœŸå’Œæ™‚é–“
            df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'], format="%Y-%m-%d %H:%M:%S")
            df = df.sort_values(by='datetime')
            stock_data[symbol] = df
        else:
            print(f"è‚¡ç¥¨ {symbol} ç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œç•¥éã€‚")
    
    # æŒ‰æ—ç¾¤åˆ†çµ„
    group_to_stocks = {}
    for symbol, group in symbol_to_group.items():
        if symbol in stock_data:
            group_to_stocks.setdefault(group, []).append(symbol)
    
    all_figures = []
    
    # ç‚ºæ¯å€‹æ—ç¾¤ç¹ªåœ–
    for group, symbols in group_to_stocks.items():
        fig, ax = plt.subplots(figsize=(12, 6))
        
        for symbol in symbols:
            df = stock_data[symbol]
            close = df['close']
            close_z = (close - close.mean()) / close.std() if close.std() != 0 else close - close.mean()
            ax.plot(df['datetime'], close_z, label=symbol)
        
        ax.set_title(f"{group} æ—ç¾¤æ¨™æº–åŒ–æ”¶ç›¤åƒ¹èµ°å‹¢")
        ax.set_xlabel("æ™‚é–“")
        ax.set_ylabel("æ¨™æº–åŒ–æ”¶ç›¤åƒ¹ (Z-score)")
        ax.legend()
        ax.grid(True)
        all_figures.append(fig)  # å­˜èµ·ä¾†

    # ğŸ”¥ ç•«å®Œæ‰€æœ‰æ—ç¾¤åœ–ä¹‹å¾Œï¼Œå†ä¸€æ¬¡é¡¯ç¤ºæ‰€æœ‰åœ–
    plt.show()




# ------------------ æŸ¥è©¢è™•ç½®è‚¡ ------------------
def display_disposition_stocks():
    disposition_file = 'Disposition.json'
    try:
        with open(disposition_file, 'r', encoding='utf-8') as f:
            disposition_data = json.load(f)
            if isinstance(disposition_data, list):
                stock_codes = disposition_data
            elif isinstance(disposition_data, dict):
                stock_codes = disposition_data.get("stock_codes", [])
            else:
                print(f"éŒ¯èª¤ï¼š{disposition_file} æ–‡ä»¶æ ¼å¼ä¸æ­£ç¢ºã€‚")
                return
    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šç„¡æ³•æ‰¾åˆ° {disposition_file} æ–‡ä»¶ã€‚")
        return
    except json.JSONDecodeError:
        print(f"éŒ¯èª¤ï¼š{disposition_file} æ–‡ä»¶æ ¼å¼ä¸æ­£ç¢ºã€‚")
        return

    if not stock_codes:
        print(f"{disposition_file} ä¸­æ²’æœ‰ä»»ä½•è‚¡ç¥¨ä»£è™Ÿã€‚")
        return

    items_per_page = 10
    total_items = len(stock_codes)
    total_pages = (total_items + items_per_page - 1) // items_per_page
    current_page = 1

    while True:
        start_idx = (current_page - 1) * items_per_page
        end_idx = start_idx + items_per_page
        page_items = stock_codes[start_idx:end_idx]

        print("\n" + "=" * 50)
        print(f"{disposition_file} è‚¡ç¥¨ä»£è™Ÿåˆ—è¡¨ - ç¬¬ {current_page} é  / å…± {total_pages} é ")
        print("=" * 50)
        for idx, code in enumerate(page_items, start=1 + start_idx):
            print(f"{idx}. {code}")
        print("=" * 50)
        if total_pages == 1:
            print("å·²é¡¯ç¤ºæ‰€æœ‰è‚¡ç¥¨ä»£è™Ÿã€‚")
            break

        print("å°èˆªé¸é …ï¼š")
        if current_page > 1:
            print("P - ä¸Šä¸€é ")
        if current_page < total_pages:
            print("N - ä¸‹ä¸€é ")
        print("0 - è¿”å›ä¸»é¸å–®")

        choice = input("è«‹è¼¸å…¥é¸é …ï¼ˆN/P/0ï¼‰ï¼š").strip().upper()

        if choice == 'N' and current_page < total_pages:
            current_page += 1
        elif choice == 'P' and current_page > 1:
            current_page -= 1
        elif choice == '0':
            break
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")




# ------------------ å·¥å…·ç¨‹å¼ ------------------

# è¨ˆç®—ä¸‰åˆ†é˜æ¼²å¹…èˆ‡ç•¶æ—¥æœ€é«˜åƒ¹
def calculate_2min_pct_increase_and_highest(new_candle, existing_candles):
    new_candle['2min_pct_increase'] = 0.0
    new_candle['highest'] = new_candle.get('high', 0)

    if not existing_candles:
        return new_candle

    all_candles = existing_candles + [new_candle]
    num_existing_candles = len(existing_candles)

    # --- è¨ˆç®— 2åˆ†é˜æ¼²å¹… ---
    if num_existing_candles < 2:
        relevant_candles = all_candles
    else:
        relevant_candles = existing_candles[-1:] + [new_candle]  # æœ€è¿‘å…©æ ¹

    rise_values = [float(c.get('rise', 0.0)) for c in relevant_candles if c.get('rise') is not None]

    if len(rise_values) >= 2:
        first = rise_values[0]
        last = rise_values[-1]
        r_max = max(rise_values)
        r_min = min(rise_values)

        if last >= first:
            pct_increase = r_max - r_min
        else:
            pct_increase = r_min - r_max

        new_candle['2min_pct_increase'] = round(pct_increase, 2)

    # --- è¨ˆç®— highest ---
    prev_highest = max([c.get('highest', 0) for c in existing_candles])
    new_candle['highest'] = max(prev_highest, new_candle.get('high', 0))

    return new_candle

# è¨ˆç®—å…©åˆ†é˜æ¼²å¹…
def calculate_2min_pct_increase(new_candle, existing_candles):
    new_candle['2min_pct_increase'] = 0.0
    all_candles = existing_candles + [new_candle]
    num_existing_candles = len(existing_candles)

    if num_existing_candles == 0:
        return new_candle

    if num_existing_candles >=1:
        relevant_candles = all_candles
    else:
        relevant_candles = existing_candles[-1:] + [new_candle]  # æœ€è¿‘ 2 æ ¹

    # æ”¹ç‚ºä½¿ç”¨ rise æ¬„ä½
    rise_values = [float(c.get('rise', 0.0)) for c in relevant_candles if c.get('rise') is not None]

    if len(rise_values) < 2:
        new_candle['2min_pct_increase'] = 0.0
    else:
        first = rise_values[0]
        last = rise_values[-1]
        r_max = max(rise_values)
        r_min = min(rise_values)

        if last >= first:
            pct_increase = r_max - r_min
        else:
            pct_increase = r_min - r_max

        new_candle['2min_pct_increase'] = round(pct_increase, 2)

    return new_candle

# è¨ˆç®—ä¸€åˆ†Kç·šæ•¸æ“šï¼ˆå›æ¸¬ã€æ­·å²è¡Œæƒ…ç”¨ï¼‰
def fetch_intraday_data(client, symbol, trading_day, yesterday_close_price, start_time=None, end_time=None):
    try:
        symbol = str(symbol).strip()
        if not symbol:
            print(f"âŒ ç„¡æ•ˆçš„ symbol: {symbol}")
            return pd.DataFrame()

        if isinstance(trading_day, str):
            trading_day_date = datetime.strptime(trading_day, '%Y-%m-%d').date()
        elif isinstance(trading_day, datetime):
            trading_day_date = trading_day.date()
        elif isinstance(trading_day, date):
            trading_day_date = trading_day
        else:
            print(f"âŒ ç„¡æ•ˆ trading_day é¡å‹ï¼š{type(trading_day)}ï¼Œå€¼ï¼š{trading_day}")
            return pd.DataFrame()

        today = datetime.now().date()
        if trading_day_date < today:
            end_time_str = "13:30"
        else:
            now = datetime.now()
            market_end = now.replace(hour=13, minute=30, second=0, microsecond=0)
            end_time_str = "13:30" if now > market_end else (now - timedelta(minutes=1)).replace(second=0, microsecond=0).strftime('%H:%M')

        _from = datetime.strptime(f"{trading_day} {start_time or '09:00'}", "%Y-%m-%d %H:%M")
        to = datetime.strptime(f"{trading_day} {end_time or end_time_str}", "%Y-%m-%d %H:%M")

        candles_rsp = client.stock.intraday.candles(
            symbol=symbol, timeframe='1',
            _from=_from.isoformat(), to=to.isoformat()
        )

        if not candles_rsp or not candles_rsp.get('data'):
            print(f"âš ï¸ API ç„¡å›å‚³è³‡æ–™ï¼š{candles_rsp}")
            return pd.DataFrame()

        candles_df = pd.DataFrame(candles_rsp['data'])
        if 'volume' not in candles_df.columns:
            print(f"âš ï¸ volume æ¬„ä½ä¸å­˜åœ¨ï¼å¯¦éš›æ¬„ä½ï¼š{candles_df.columns.tolist()}")
            return pd.DataFrame()

        candles_df['volume'] = pd.to_numeric(candles_df['volume'], errors='coerce')
        candles_df['datetime'] = pd.to_datetime(candles_df['date'], errors='coerce').dt.tz_localize(None).dt.floor('min')
        candles_df.set_index('datetime', inplace=True)

        original_df = candles_df.reset_index()[['datetime', 'volume']].rename(columns={'volume': 'orig_volume'})

        full_idx = pd.date_range(start=_from, end=to, freq='1min')
        candles_df = candles_df.reindex(full_idx)

        candles_df.reset_index(inplace=True)
        candles_df.rename(columns={'index': 'datetime'}, inplace=True)
        candles_df['date'] = candles_df['datetime'].dt.strftime('%Y-%m-%d')
        candles_df['time'] = candles_df['datetime'].dt.strftime('%H:%M:%S')

        candles_df = pd.merge(candles_df, original_df, how='left', on='datetime')
        candles_df['was_filled'] = candles_df['orig_volume'].isna()

        # âœ… è‹¥æ‰¾ä¸åˆ°å‰ä¸€æ ¹Kæ£’ï¼Œè£œä¸Šæ˜¨æ—¥æ”¶ç›¤åƒ¹
        for col in ['open', 'high', 'low', 'close']:
            values = candles_df[col].to_numpy()
            last_valid_close = yesterday_close_price

            for i in range(len(values)):
                vol = candles_df.at[i, 'volume']
                close_val = candles_df.at[i, 'close']

                if vol > 0 and not pd.isna(close_val):
                    last_valid_close = close_val

                if pd.isna(values[i]) or vol == 0:
                    values[i] = last_valid_close

            candles_df[col] = values

        candles_df['volume'] = candles_df['orig_volume'].fillna(0)
        candles_df['symbol'] = symbol
        candles_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹'] = yesterday_close_price
        candles_df['æ¼²åœåƒ¹'] = truncate_to_two_decimals(calculate_limit_up_price(yesterday_close_price))
        candles_df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']] = candles_df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']].ffill().bfill()
        candles_df['rise'] = (candles_df['close'] - candles_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹']) / candles_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹'] * 100

        # âœ… ä¿®æ­£ highest = None å•é¡Œï¼šè£œå®Œ high å†è¨ˆç®— cummax
        candles_df['highest'] = candles_df['high'].cummax()
        candles_df['highest'] = candles_df['highest'].fillna(yesterday_close_price)

        return candles_df[['symbol', 'date', 'time', 'open', 'high', 'low',
                           'close', 'volume', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹', 'rise', 'highest']]

    except Exception as e:
        print(f"âŒ ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤ï¼š{e}")
        traceback.print_exc()
        return pd.DataFrame()
    
def fetch_realtime_intraday_data(client, symbol, trading_day, yesterday_close_price, start_time=None, end_time=None):
    try:
        symbol = str(symbol).strip()
        if not symbol:
            print(f"âŒ ç„¡æ•ˆçš„ symbol: {symbol}")
            return pd.DataFrame()

        # è™•ç† trading_day åƒæ•¸
        if isinstance(trading_day, str):
            trading_day_date = datetime.strptime(trading_day, '%Y-%m-%d').date()
        elif isinstance(trading_day, datetime):
            trading_day_date = trading_day.date()
        elif isinstance(trading_day, date):
            trading_day_date = trading_day
        else:
            print(f"âŒ ç„¡æ•ˆ trading_day é¡å‹ï¼š{type(trading_day)}ï¼Œå€¼ï¼š{trading_day}")
            return pd.DataFrame()

        # è¨ˆç®—çµæŸæ™‚é–“
        today = datetime.now().date()
        if trading_day_date < today:
            end_time_str = "13:30"
        else:
            now = datetime.now()
            market_end = now.replace(hour=13, minute=30, second=0, microsecond=0)
            end_time_str = "13:30" if now > market_end else (now - timedelta(minutes=1)).replace(second=0, microsecond=0).strftime('%H:%M')

        _from = datetime.strptime(f"{trading_day} {start_time or '09:00'}", "%Y-%m-%d %H:%M")
        to = datetime.strptime(f"{trading_day} {end_time or end_time_str}", "%Y-%m-%d %H:%M")

        candles_rsp = client.stock.intraday.candles(
            symbol=symbol, timeframe='1',
            _from=_from.isoformat(), to=to.isoformat()
        )

        if not candles_rsp or not candles_rsp.get('data'):
            print(f"âš ï¸ API ç„¡å›å‚³è³‡æ–™ï¼š{candles_rsp}")
            return pd.DataFrame()

        candles_df = pd.DataFrame(candles_rsp['data'])
        if 'volume' not in candles_df.columns:
            print(f"âš ï¸ volume æ¬„ä½ä¸å­˜åœ¨ï¼å¯¦éš›æ¬„ä½ï¼š{candles_df.columns.tolist()}")
            return pd.DataFrame()

        candles_df['volume'] = pd.to_numeric(candles_df['volume'], errors='coerce')
        candles_df['datetime'] = pd.to_datetime(candles_df['date'], errors='coerce').dt.tz_localize(None).dt.floor('min')
        candles_df.set_index('datetime', inplace=True)

        original_df = candles_df.reset_index()[['datetime', 'volume']].rename(columns={'volume': 'orig_volume'})

        full_idx = pd.date_range(start=_from, end=to, freq='1min')
        candles_df = candles_df.reindex(full_idx)

        candles_df.reset_index(inplace=True)
        candles_df.rename(columns={'index': 'datetime'}, inplace=True)
        candles_df['date'] = candles_df['datetime'].dt.strftime('%Y-%m-%d')
        candles_df['time'] = candles_df['datetime'].dt.strftime('%H:%M:%S')

        candles_df = pd.merge(candles_df, original_df, how='left', on='datetime')
        candles_df['was_filled'] = candles_df['orig_volume'].isna()

        # âœ… ä½¿ç”¨å‘é‡åŒ–è£œå€¼å–ä»£ iterrowsï¼Œæ•ˆç‡æå‡
        filled = candles_df['was_filled'].to_numpy()
        close = candles_df['close'].to_numpy()

        last_valid = yesterday_close_price
        for i in range(len(close)):
            if candles_df.at[i, 'volume'] > 0:
                if not pd.isna(close[i]):
                    last_valid = close[i]
            if filled[i]:
                close[i] = last_valid

        for col in ['open', 'high', 'low', 'close']:
            values = candles_df[col].to_numpy()
            last_valid_close = None
            for i in range(len(values)):
                vol = candles_df.at[i, 'volume']
                if vol > 0 and not pd.isna(candles_df.at[i, 'close']):
                    last_valid_close = candles_df.at[i, 'close']
                if pd.isna(values[i]) or vol == 0:
                    if last_valid_close is not None:
                        values[i] = last_valid_close
            candles_df[col] = values

        # volume æœ¬èº«è£œé›¶
        candles_df['volume'] = candles_df['orig_volume'].fillna(0)

        # âœ… å°ˆå±¬å³æ™‚è£œå€¼ï¼švolume==0 æ™‚è®€å– auto_intraday.json æœ€å¾Œä¸€ç­† close
        try:
            with open("auto_intraday.json", "r", encoding="utf-8") as f:
                auto_data = json.load(f)
            last_close = None
            if symbol in auto_data and isinstance(auto_data[symbol], list) and auto_data[symbol]:
                last_record = auto_data[symbol][-1]
                last_close = last_record.get("close")

            for i in range(len(candles_df)):
                if candles_df.at[i, "volume"] == 0:
                    if last_close is not None:
                        for col in ["open", "high", "low", "close"]:
                            candles_df.at[i, col] = last_close
                        '''
                        print(f"ğŸ“Œ [è£œå€¼] {symbol} {candles_df.at[i, 'time']} volume=0ï¼Œä½¿ç”¨ auto_intraday.json æœ€å¾Œä¸€ç­† close={last_close}")
                        '''
                    else:
                        print(f"âš ï¸ [è£œå€¼å¤±æ•—] {symbol} {candles_df.at[i, 'time']} volume=0ï¼Œä½†ç„¡æ³•å¾ auto_intraday.json å–å¾— close å€¼")
        except Exception as e:
            print(f"âŒ è®€å– auto_intraday.json æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

        candles_df['symbol'] = symbol
        candles_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹'] = yesterday_close_price
        candles_df['æ¼²åœåƒ¹'] = truncate_to_two_decimals(calculate_limit_up_price(yesterday_close_price))
        candles_df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']] = candles_df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']].ffill().bfill()
        candles_df['rise'] = (candles_df['close'] - candles_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹']) / candles_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹'] * 100
        candles_df['highest'] = candles_df['high'].cummax()

        return candles_df[[ 'symbol', 'date', 'time', 'open', 'high', 'low',
                            'close', 'volume', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹', 'rise', 'highest']]

    except Exception as e:
        print(f"âŒ ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤ï¼š{e}")
        traceback.print_exc()
        return pd.DataFrame()


# è¨ˆç®—æ—¥Kç·šæ•¸æ“š
def fetch_daily_kline_data(client, symbol, days=2):
    end_date = get_recent_trading_day()
    start_date = end_date - timedelta(days=days)
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')

    print(f"æ­£åœ¨å–å¾— {symbol} å¾ {start_date_str} åˆ° {end_date_str} çš„æ—¥Kæ•¸æ“š...")

    try:
        data = client.stock.historical.candles(symbol=symbol, from_=start_date_str, to=end_date_str)
        if 'data' in data and data['data']:
            daily_kline_df = pd.DataFrame(data['data'])
            return daily_kline_df
        else:
            print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼šAPI å›æ‡‰ä¸­ä¸åŒ…å« 'data' æ¬„ä½æˆ– 'data' ç‚ºç©º")
            return pd.DataFrame()
    except Exception as e:
        print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼š{e}")
        return pd.DataFrame()

# è¨ˆç®—æœ€è¿‘äº¤æ˜“æ—¥
def get_recent_trading_day():
    today = datetime.now().date()
    now_time = datetime.now().time()
    market_open = datetime.strptime("09:00", "%H:%M").time()
    market_close = datetime.strptime("13:30", "%H:%M").time()

    def last_friday(date):
        """å¾€å›æ‰¾åˆ°æœ€è¿‘çš„æ˜ŸæœŸäº”"""
        while date.weekday() != 4:
            date -= timedelta(days=1)
        return date

    weekday = today.weekday()  # 0=Monday, 6=Sunday

    if weekday == 5:  # Saturday
        return last_friday(today)
    elif weekday == 6:  # Sunday
        return last_friday(today)
    elif weekday == 0:  # Monday
        if now_time < market_open:
            return last_friday(today)  # é€±ä¸€æ—©ä¸Š9é»å‰ï¼Œé‚„æ˜¯æ‹¿ä¸Šé€±äº”
        elif market_open <= now_time <= market_close:
            return last_friday(today)  # ç›¤ä¸­ä¹Ÿæ‹¿ä¸Šé€±äº”
        else:
            return today  # ç›¤å¾Œæ‹¿ä»Šå¤©
    else:  # Tuesday to Friday
        if now_time < market_open:
            return today - timedelta(days=1)
        elif market_open <= now_time <= market_close:
            return today - timedelta(days=1)
        else:
            return today

# è¨­å®šé¸å–®å·¥å…·
def save_settings():
    with open('settings.json', 'w', encoding='utf-8') as f:
        json.dump({
            'capital_per_stock': capital_per_stock,
            'transaction_fee': transaction_fee,
            'transaction_discount': transaction_discount,
            'trading_tax': trading_tax,
            'below_50': below_50,
            'price_gap_50_to_100': price_gap_50_to_100,
            'price_gap_100_to_500': price_gap_100_to_500,
            'price_gap_500_to_1000': price_gap_500_to_1000,
            'price_gap_above_1000': price_gap_above_1000,
            'allow_reentry_after_stop_loss': allow_reentry_after_stop_loss
        }, f, indent=4)

def load_settings():
    global capital_per_stock, transaction_fee, transaction_discount, trading_tax
    global below_50, price_gap_50_to_100, price_gap_100_to_500, price_gap_500_to_1000, price_gap_above_1000
    global allow_reentry_after_stop_loss
    if os.path.exists('settings.json'):
        with open('settings.json', 'r', encoding='utf-8') as f:
            settings = json.load(f)
            capital_per_stock = settings.get('capital_per_stock', 0)
            transaction_fee = settings.get('transaction_fee', 0)
            transaction_discount = settings.get('transaction_discount', 0)
            trading_tax = settings.get('trading_tax', 0)
            below_50 = settings.get('below_50', 0)
            price_gap_50_to_100 = settings.get('price_gap_50_to_100', 0)
            price_gap_100_to_500 = settings.get('price_gap_100_to_500', 0)
            price_gap_500_to_1000 = settings.get('price_gap_500_to_1000', 0)
            price_gap_above_1000 = settings.get('price_gap_above_1000', 0)
            allow_reentry_after_stop_loss = settings.get('allow_reentry_after_stop_loss', False)
    else:
        capital_per_stock = 1000
        transaction_fee = 0.1425
        transaction_discount = 20.0
        trading_tax = 0.15
        below_50 = 500
        price_gap_50_to_100 = 1000
        price_gap_100_to_500 = 2000
        price_gap_500_to_1000 = 3000
        price_gap_above_1000 = 5000
        allow_reentry_after_stop_loss = False

def consolidate_and_save_stock_symbols():
    # åªè®€ matrix_dict_analysis.jsonï¼Œç›´æ¥ç•¶ä½œæœ€çµ‚æ¸…å–®
    matrix_dict_analysis = load_matrix_dict_analysis()
    if not matrix_dict_analysis:
        print("matrix_dict_analysis.json æª”æ¡ˆä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œçµ±æ•´")
        return

    # ç›´æ¥ä»¥åŸå§‹ç¾¤çµ„å®šç¾©å»ºç«‹ consolidated_symbols
    nb_matrix_dict = {
        "consolidated_symbols": matrix_dict_analysis
    }

    save_nb_matrix_dict(nb_matrix_dict)


# ------------------ è¨ˆç®—å›æ¸¬å‡½æ•¸ç›¸ä¼¼åº¦ ------------------
def calculate_group_kline_data(
    leader: str,
    candidates: list[str],
    intraday_file: str,
    group_symbols: list[str],
    wait_end_time: datetime,
    similarity_threshold: float = 0.4,
    close_weight: float = 2.0
) -> list[str]:
    """
    è¨ˆç®—ã€Œleaderã€èˆ‡ group_symbolsï¼ˆé™¤ leader å¤–ï¼‰åœ¨ 09:00ï½(wait_end_time - 1min) ä¹‹é–“
    çš„ K ç·šç›¸ä¼¼åº¦ï¼Œä¸¦æŠŠéç¨‹ dump åˆ° debug JSONã€‚
    """

    # 1. è®€ intraday_kline_data.json
    with open(intraday_file, 'r', encoding='utf-8') as f:
        intraday_data = json.load(f)

    # 2. å®šç¾©æ™‚é–“ç¯„åœ
    start_time = time(9, 0)
    end_dt     = wait_end_time - timedelta(minutes=1)
    end_time   = end_dt.time()
    print(f"[SIM DEBUG] å–ç”¨ K ç·šæ™‚é–“ç¯„åœï¼š{start_time} ï½ {end_time}")

    # 3. å–å‡º leader & group_symbols çš„ DataFrame
    def df_of(sym):
        recs = intraday_data.get(sym, [])
        df = pd.DataFrame(recs)
        if df.empty:
            return df
        # è½‰æˆ time ç‰©ä»¶
        df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.time
        mask = (df['time'] >= start_time) & (df['time'] <= end_time)
        return df.loc[mask].sort_values('time').reset_index(drop=True)

    df_lead = df_of(leader)

    # æŠŠ time è½‰å›å­—ä¸²ï¼Œæ‰ä¸æœƒ dump æ™‚å¤±æ•—
    df_lead_str = df_lead.copy()
    if not df_lead_str.empty:
        df_lead_str['time'] = df_lead_str['time'].astype(str)
    leader_klines = df_lead_str.to_dict('records')

    # 4. è¨ˆç®—æ‰€æœ‰ group_symbolsï¼ˆå‰”é™¤ leaderï¼‰ vs leader çš„ç›¸ä¼¼åº¦
    sim_results      = []
    candidate_klines = {}
    for sym in group_symbols:
        if sym == leader:
            continue
        df_cand = df_of(sym)
        # candidate ä¹ŸåŒæ¨£è½‰å›å­—ä¸²
        df_cand_str = df_cand.copy()
        if not df_cand_str.empty:
            df_cand_str['time'] = df_cand_str['time'].astype(str)
        candidate_klines[sym] = df_cand_str.to_dict('records')

        if df_lead.empty or df_cand.empty:
            sim = None
        else:
            merged = pd.merge(df_lead, df_cand, on='time', suffixes=('_L','_C'))
            if merged.empty:
                sim = None
            else:
                # Z-score æ¨™æº–åŒ–
                for col in ['open','high','low','close','volume']:
                    merged[f'{col}_L_z'] = (
                        merged[f'{col}_L'] - merged[f'{col}_L'].mean()
                    ) / merged[f'{col}_L'].std(ddof=0)
                    merged[f'{col}_C_z'] = (
                        merged[f'{col}_C'] - merged[f'{col}_C'].mean()
                    ) / merged[f'{col}_C'].std(ddof=0)

                dist = np.sqrt(
                    (merged['open_L_z']   - merged['open_C_z'])**2 +
                    (merged['high_L_z']   - merged['high_C_z'])**2 +
                    (merged['low_L_z']    - merged['low_C_z'])**2 +
                    close_weight*(merged['close_L_z'] - merged['close_C_z'])**2 +
                    (merged['volume_L_z'] - merged['volume_C_z'])**2
                ).mean()
                sim = 1 / (1 + dist)

        sim_results.append({'symbol': sym, 'similarity': sim})

    # 5. ç”¢å‡ºç¬¦åˆé–€æª»çš„è‚¡ç¥¨æ¸…å–®
    sim_ok = [
        r['symbol']
        for r in sim_results
        if r['similarity'] is not None and r['similarity'] >= similarity_threshold
    ]

    # 6. Debugï¼šæŠŠæ‰€æœ‰ç›¸ä¼¼åº¦çµæœèˆ‡ K ç·šè³‡æ–™å­˜åˆ° JSON
    debug_info = {
        'leader':               leader,
        'group_symbols':        group_symbols,
        'time_range':           f"{start_time} ~ {end_time}",
        'similarity_threshold': similarity_threshold,
        'leader_klines':        leader_klines,
        'candidate_klines':     candidate_klines,
        'sim_results':          sim_results,
        'sim_ok':               sim_ok
    }
    with open('similarity_debug_full.json', 'w', encoding='utf-8') as f:
        json.dump(debug_info, f, ensure_ascii=False, indent=2)

    return sim_ok

# ------------------ è¨ˆç®—äº¤æ˜“å‡½æ•¸ç›¸ä¼¼åº¦ ------------------
def calculate_realtime_kline_data(
    leader: str,
    candidates: list[str],
    intraday_file: str,
    wait_end_time: datetime,
    similarity_threshold: float = 0.4,
    close_weight: float = 2.0
) -> list[str]:
    """
    è·Ÿ calculate_group_kline_data å¹¾ä¹ä¸€æ¨£ï¼Œ
    åªæ˜¯è³‡æ–™ä¾†æºæ”¹æˆ auto_intraday.jsonã€è¼¸å‡ºæª”åæ”¹ç‚º similarity_realtime_debug_full.json
    """
    import json
    from datetime import timedelta, time

    # 1. è®€ auto_intraday.json
    with open(intraday_file, 'r', encoding='utf-8') as f:
        intraday_data = json.load(f)

    # 2. æ™‚é–“ç¯„åœï¼š09:00 ï½ wait_end_time - 1 åˆ†é˜
    start_time = time(9, 0)
    end_dt     = wait_end_time - timedelta(minutes=1)
    end_time   = end_dt.time()
    print(f"[RT-SIM DEBUG] å–ç”¨ K ç·šæ™‚é–“ç¯„åœï¼š{start_time} ï½ {end_time}")

    # 3. å– DataFrameï¼Œåˆ‡åˆ°æ™‚é–“å€é–“
    def df_of(sym):
        recs = intraday_data.get(sym, [])
        df = pd.DataFrame(recs)
        if df.empty:
            return df
        df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.time
        return (
            df[(df['time'] >= start_time) & (df['time'] <= end_time)]
            .sort_values('time')
            .reset_index(drop=True)
        )

    df_lead = df_of(leader)
    leader_klines = df_lead.to_dict('records')

    sim_results = []
    candidate_klines = {}
    for sym in candidates:
        df_cand = df_of(sym)
        candidate_klines[sym] = df_cand.to_dict('records')

        merged = pd.merge(df_lead, df_cand, on='time', suffixes=('_L','_C'))
        if merged.empty:
            sim = None
        else:
            for col in ['open','high','low','close','volume']:
                merged[f'{col}_L_z'] = (
                    merged[f'{col}_L'] - merged[f'{col}_L'].mean()
                ) / merged[f'{col}_L'].std(ddof=0)
                merged[f'{col}_C_z'] = (
                    merged[f'{col}_C'] - merged[f'{col}_C'].mean()
                ) / merged[f'{col}_C'].std(ddof=0)
            dist = np.sqrt(
                (merged['open_L_z']   - merged['open_C_z'])**2 +
                (merged['high_L_z']   - merged['high_C_z'])**2 +
                (merged['low_L_z']    - merged['low_C_z'])**2 +
                close_weight*(merged['close_L_z'] - merged['close_C_z'])**2 +
                (merged['volume_L_z'] - merged['volume_C_z'])**2
            ).mean()
            sim = 1 / (1 + dist)
        sim_results.append({'symbol': sym, 'similarity': sim})

    sim_ok = [
        r['symbol']
        for r in sim_results
        if r['similarity'] is not None and r['similarity'] >= similarity_threshold
    ]

    # 6. å°‡æ‰€æœ‰ debug è³‡æ–™å¯«å‡º
    debug_info = {
        'leader':              leader,
        'time_range':          f"{start_time} ~ {end_time}",
        'similarity_threshold': similarity_threshold,
        'leader_klines':       leader_klines,
        'candidate_klines':    candidate_klines,
        'sim_results':         sim_results,
        'sim_ok':              sim_ok
    }
    with open('similarity_realtime_debug_full.json', 'w', encoding='utf-8') as f:
        json.dump(debug_info, f, ensure_ascii=False, indent=2)

    return sim_ok


def calculate_kline_similarity(stock_data_list, close_weight=2):
    """
    è¨ˆç®—è‚¡ç¥¨ä¹‹é–“çš„Kç·šç›¸ä¼¼åº¦ï¼ˆå«æˆäº¤é‡ï¼Œå¼·åŒ–closeé‡è¦æ€§ï¼‰
    
    åƒæ•¸ï¼š
    - stock_data_list: æ¯æ”¯è‚¡ç¥¨çš„DataFrameåˆ—è¡¨ï¼ˆæ¯å€‹DataFrameåŒ…å«è‡³å°‘open/high/low/close/volumeæ¬„ä½ï¼‰
    - close_weight: closeæ¬„ä½åœ¨è¨ˆç®—è·é›¢æ™‚çš„æ¬Šé‡ï¼ˆé è¨­ç‚º2å€ï¼‰
    
    è¿”å›ï¼š
    - ç›¸ä¼¼åº¦DataFrameï¼ˆåŒ…å«stock1ã€stock2ã€similarity_scoreï¼‰
    """
    similarity_results = []
    num_stocks = len(stock_data_list)
    
    for i in range(num_stocks):
        stock1 = stock_data_list[i]
        if 'symbol' not in stock1.columns:
            raise KeyError("DataFrame does not contain 'symbol' column.")
        symbol1 = stock1['symbol'].iloc[0]
        
        for j in range(i + 1, num_stocks):
            stock2 = stock_data_list[j]
            if 'symbol' not in stock2.columns:
                raise KeyError("DataFrame does not contain 'symbol' column.")
            symbol2 = stock2['symbol'].iloc[0]
            
            if symbol1 != symbol2:
                merged_df = pd.merge(stock1, stock2, on='time', suffixes=('_1', '_2'))
                merged_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹_2'] = merged_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹_2'].ffill().bfill()
                
                # ç¢ºèªéœ€è¦çš„æ¬„ä½å­˜åœ¨
                required_cols = ['open', 'high', 'low', 'close', 'volume']
                if not all(f'{col}_1' in merged_df.columns and f'{col}_2' in merged_df.columns for col in required_cols):
                    print(f"è‚¡ç¥¨ {symbol1} æˆ– {symbol2} ç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œè·³éç›¸ä¼¼åº¦è¨ˆç®—ã€‚")
                    continue

                # Z-score æ¨™æº–åŒ–
                for col in required_cols:
                    merged_df[f'{col}_1_z'] = (merged_df[f'{col}_1'] - merged_df[f'{col}_1'].mean()) / merged_df[f'{col}_1'].std()
                    merged_df[f'{col}_2_z'] = (merged_df[f'{col}_2'] - merged_df[f'{col}_2'].mean()) / merged_df[f'{col}_2'].std()

                # è¨ˆç®—æ­å¼è·é›¢ï¼Œcloseæ¬„ä½æœ‰åŠ æ¬Š
                distance = np.sqrt(
                    (merged_df['open_1_z'] - merged_df['open_2_z']) ** 2 +
                    (merged_df['high_1_z'] - merged_df['high_2_z']) ** 2 +
                    (merged_df['low_1_z'] - merged_df['low_2_z']) ** 2 +
                    close_weight * (merged_df['close_1_z'] - merged_df['close_2_z']) ** 2 +
                    (merged_df['volume_1_z'] - merged_df['volume_2_z']) ** 2
                ).mean()

                similarity_score = 1 / (1 + distance)
                
                if similarity_score >= 0.4:
                    result = {
                        'stock1': symbol1,
                        'stock2': symbol2,
                        'similarity_score': similarity_score
                    }
                    similarity_results.append(result)

    if not similarity_results:
        print("æ²’æœ‰æ‰¾åˆ°ç›¸ä¼¼åº¦å¤§æ–¼ç­‰æ–¼ 0.4 çš„çµæœ")
        return pd.DataFrame(columns=['stock1', 'stock2', 'similarity_score'])
    
    similarity_df = pd.DataFrame(similarity_results)
    similarity_df = similarity_df.sort_values(by='similarity_score', ascending=False).reset_index(drop=True)
    return similarity_df

def calculate_limit_up_price(close_price):
    limit_up = close_price * 1.10
    if limit_up < 10:
        price_unit = 0.01
    elif limit_up < 50:
        price_unit = 0.05
    elif limit_up < 100:
        price_unit = 0.1
    elif limit_up < 500:
        price_unit = 0.5
    elif limit_up < 1000:
        price_unit = 1
    else:
        price_unit = 5
    limit_up_price = (limit_up // price_unit) * price_unit
    return limit_up_price

def load_nb_matrix_dict():
    if os.path.exists('nb_matrix_dict.json'):
        with open('nb_matrix_dict.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        return {}
    
def ensure_continuous_time_series(df):
    df['date'] = pd.to_datetime(df['date'])
    df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.time

    full_time_index = pd.date_range(start='09:00', end='13:30', freq='1min').time
    full_index = pd.MultiIndex.from_product([df['date'].unique(), full_time_index], names=['date', 'time'])

    df.set_index(['date', 'time'], inplace=True)
    df = df.reindex(full_index)
    df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']] = df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']].ffill().bfill()

    if 'high' not in df.columns:
        df['high'] = df['close']
    if 'low' not in df.columns:
        df['low'] = df['close']

    df['close'] = df['close'].ffill()
    df['close'] = df['close'].fillna(df['æ˜¨æ—¥æ”¶ç›¤åƒ¹'])
    df['open'] = df['open'].ffill()
    df['open'] = df['open'].fillna(df['close'])
    df['high'] = df['high'].ffill()
    df['high'] = df['high'].fillna(df['close'])
    df['low'] = df['low'].ffill()
    df['low'] = df['low'].fillna(df['close'])
    df['volume'] = df['volume'].fillna(0)

    if '2min_pct_increase' not in df.columns:
        df['2min_pct_increase'] = 0.0
    else:
        df['2min_pct_increase'] = df['2min_pct_increase'].fillna(0.0)

    df.reset_index(inplace=True)
    return df
        
def load_disposition_stocks():
    disposition_file = 'Disposition.json'
    try:
        with open(disposition_file, 'r', encoding='utf-8') as f:
            disposition_data = json.load(f)
            return disposition_data
    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šç„¡æ³•æ‰¾åˆ° {disposition_file} æ–‡ä»¶ã€‚")
        return []
    except json.JSONDecodeError:
        print(f"éŒ¯èª¤ï¼š{disposition_file} æ–‡ä»¶æ ¼å¼ä¸æ­£ç¢ºã€‚")
        return []
    
def fetch_disposition_stocks(client, matrix_dict_analysis):
    disposition_stocks = []
    for group, stock_list in matrix_dict_analysis.items():
        for symbol in stock_list:
            try:
                ticker_data = client.stock.intraday.ticker(symbol=symbol)
                if ticker_data.get('isDisposition', False):
                    disposition_stocks.append(symbol)
            except Exception as e:
                print(f"ç²å– {symbol} çš„è™•ç½®è‚¡ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    with open('Disposition.json', 'w', encoding='utf-8') as f:
        json.dump(disposition_stocks, f, indent=4, ensure_ascii=False)

def load_kline_data():
    daily_kline_data = {}
    intraday_kline_data = {}

    if os.path.exists('daily_kline_data.json'):
        with open('daily_kline_data.json', 'r', encoding='utf-8') as f:
            try:
                daily_kline_data = json.load(f)
                if not daily_kline_data:
                    print("æ—¥Kç·šæ•¸æ“šæª”æ¡ˆç‚ºç©ºï¼Œè«‹å…ˆæ›´æ–°æ•¸æ“šã€‚")
            except json.JSONDecodeError:
                print("æ—¥Kç·šæ•¸æ“šæª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼Œè«‹å…ˆæ›´æ–°æ•¸æ“šã€‚")

    if os.path.exists('intraday_kline_data.json'):
        with open('intraday_kline_data.json', 'r', encoding='utf-8') as f:
            try:
                intraday_kline_data = json.load(f)
                if not intraday_kline_data:
                    print("ä¸€åˆ†Kç·šæ•¸æ“šæª”æ¡ˆç‚ºç©ºï¼Œè«‹å…ˆæ›´æ–°æ•¸æ“šã€‚")
            except json.JSONDecodeError:
                print("ä¸€åˆ†Kç·šæ•¸æ“šæª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼Œè«‹å…ˆæ›´æ–°æ•¸æ“šã€‚")

    return daily_kline_data, intraday_kline_data

def load_symbols_to_analyze():
    nb_matrix_dict = load_nb_matrix_dict()
    consolidated_symbols = nb_matrix_dict.get("consolidated_symbols", {})
    symbols = []
    for group_symbols in consolidated_symbols.values():
        symbols.extend(group_symbols)
    disposition_stocks = load_disposition_stocks()
    symbols = [symbol for symbol in symbols if symbol not in disposition_stocks]
    return symbols

def load_group_symbols():
    if not os.path.exists('nb_matrix_dict.json'):
        print("nb_matrix_dict.json æ–‡ä»¶ä¸å­˜åœ¨ã€‚")
        return {}
    with open('nb_matrix_dict.json', 'r', encoding='utf-8') as f:
        group_symbols = json.load(f)
    return group_symbols

# æŠŠè™•ç½®è‚¡å¾ nb_matrix_dict.json å‰”é™¤
def purge_disposition_from_nb(disposition_list, nb_path='nb_matrix_dict.json'):
    """
    disposition_list : List[str]  # è™•ç½®è‚¡ä»£è™Ÿæ¸…å–®
    nb_path          : str        # nb_matrix_dict æª”æ¡ˆè·¯å¾‘
    --------------
    è®€å– nb_matrix_dict.json â†’ consolidated_symbols
    è‹¥è©²è‚¡ç¥¨ä»£è™Ÿå‡ºç¾åœ¨ disposition_listï¼Œä¾¿å°‡å…¶å¾å°æ‡‰æ—ç¾¤ç§»é™¤ã€‚
    æœ‰ç•°å‹•æ‰è¦†å¯«æª”æ¡ˆã€‚
    """
    if not os.path.exists(nb_path):
        print(f"æ‰¾ä¸åˆ° {nb_path}ï¼Œè·³éè™•ç½®è‚¡éæ¿¾ã€‚")
        return

    try:
        with open(nb_path, 'r', encoding='utf-8') as f:
            nb_dict = json.load(f)
    except json.JSONDecodeError:
        print(f"{nb_path} æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è§£æï¼Œè·³ééæ¿¾ã€‚")
        return

    if 'consolidated_symbols' not in nb_dict or not isinstance(nb_dict['consolidated_symbols'], dict):
        print(f"{nb_path} ç¼ºå°‘ consolidated_symbolsï¼Œè·³ééæ¿¾ã€‚")
        return

    changed = False
    for grp, syms in nb_dict['consolidated_symbols'].items():
        # åŸæœ¬å¯èƒ½æœ‰é‡è¤‡ï¼Œå…ˆå»é‡å†éæ¿¾
        filtered = [s for s in dict.fromkeys(syms) if s not in disposition_list]
        if len(filtered) != len(syms):
            nb_dict['consolidated_symbols'][grp] = filtered
            changed = True

    # è‹¥æœ‰ç•°å‹•ï¼Œå¯«å›æª”æ¡ˆ
    if changed:
        with open(nb_path, 'w', encoding='utf-8') as f:
            json.dump(nb_dict, f, ensure_ascii=False, indent=4)
        print(f"å·²å¾ {nb_path} ç§»é™¤è™•ç½®è‚¡ï¼š{', '.join(disposition_list)}")
    else:
        print("nb_matrix_dict.json ç„¡éœ€èª¿æ•´ï¼ŒæœªåŒ…å«ä»»ä½•è™•ç½®è‚¡ã€‚")

# æª¢æŸ¥ç›¤ä¸­é€€å‡º
def check_quit_flag_loop():
    while True:
        time_module.sleep(5)  # æ¯ 5 ç§’æª¢æŸ¥ä¸€æ¬¡
        if quit_flag["quit"]:
            threading.Thread(target=show_exit_menu, daemon=True).start()
            quit_flag["quit"] = False

# å…¨åŸŸè®Šæ•¸ï¼Œç”¨ä¾†è¨˜éŒ„ä¸Šä¸€æ¬¡å­˜åœ¨æ–¼åœæå§”è¨—å–®ä¸­çš„è‚¡ç¥¨ä»£è™Ÿ
previous_stop_loss_codes = set()
open_positions: dict[str, dict] = {} # â€‘ åªè¦æœ‰é€²å ´å°±å¯«å…¥ï¼›å¹³å€‰å°±åˆªé™¤ï¼ˆç›¤ä¸­æŒå€‰è¡¨ï¼‰ã€‚
triggered_limit_up_stocks: set[str] = set()

def monitor_stop_loss_orders():
    """
    æ¯æ¬¡å‘¼å«æ™‚æª¢æŸ¥ to.conditions çš„å…§å®¹ï¼Œå¦‚æœç™¼ç¾åŸæœ¬å­˜åœ¨çš„åœæå§”è¨—å–®è‚¡ç¥¨ä»£è™Ÿå·²ä¸è¦‹ï¼Œ
    å‰‡æª¢æŸ¥ allow_reentry_after_stop_loss æ˜¯å¦ç‚º Trueï¼Œ
    è‹¥æ˜¯ï¼Œå‰‡å°‡è©²è‚¡ç¥¨æ‰€å±¬æ—ç¾¤çš„ in_position è¨­ç‚º Falseï¼ˆå…è¨±é‡å…¥ï¼‰ã€‚
    """
    global to, group_positions, previous_stop_loss_codes, allow_reentry_after_stop_loss

    # å–å¾—ç›®å‰åœæå§”è¨—å–®çš„è‚¡ç¥¨ä»£è™Ÿé›†åˆ
    if isinstance(to.conditions, dict):
        current_codes = set(to.conditions.keys())
    else:
        # å¦‚æœ to.conditions ä¸æ˜¯å­—å…¸ï¼Œå°±å˜—è©¦å¾æ¯å€‹åœæå–®ç‰©ä»¶ä¸­æå–è‚¡ç¥¨ä»£è™Ÿï¼ˆä¾å¯¦éš›æ ¼å¼èª¿æ•´ï¼‰
        current_codes = set()
        for cond in to.conditions:
            try:
                current_codes.add(cond.order_contract.code)
            except Exception as e:
                print(f"æå–åœæå–®ä»£è™Ÿæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    # èˆ‡ä¸Šä¸€è¼ªè¨˜éŒ„æ¯”è¼ƒï¼Œæ‰¾å‡ºå·²ç§»é™¤çš„è‚¡ç¥¨ä»£è™Ÿ
    removed_codes = previous_stop_loss_codes - current_codes

    if removed_codes:
        if allow_reentry_after_stop_loss:
            nb_matrix_dict = load_nb_matrix_dict()  # å‡è¨­æ­¤å‡½æ•¸èƒ½æ­£ç¢ºè¼‰å…¥ nb_matrix_dict.json
            if "consolidated_symbols" in nb_matrix_dict:
                consolidated_symbols = nb_matrix_dict["consolidated_symbols"]
                for code in removed_codes:
                    # å°‹æ‰¾è©²è‚¡ç¥¨æ‰€åœ¨çš„æ—ç¾¤
                    for group, symbols in consolidated_symbols.items():
                        # å‡è¨­è‚¡ç¥¨ä»£è™Ÿæ ¼å¼ä¸€è‡´
                        if code in symbols:
                            if group in group_positions and group_positions[group] == "å·²é€²å ´":
                                group_positions[group] = False
                                print(f"åœæè§¸ç™¼ï¼šè‚¡ç¥¨ {code} çš„åœæå§”è¨—å–®æ¶ˆå¤±ï¼Œå°‡æ—ç¾¤ {group} çš„ in_position è¨­ç‚º False")
            else:
                print("nb_matrix_dict ä¸­ç¼ºå°‘ 'consolidated_symbols' éµï¼Œç„¡æ³•æ›´æ–°æ—ç¾¤ç‹€æ…‹")
        else:
            print("åœæå§”è¨—å–®æ¶ˆå¤±ï¼Œä½†åœæå†é€²å ´å·²é—œé–‰")
    else:
        print("ç›£æ§ä¸­ï¼šç›®å‰æœªç™¼ç¾ç•°å¸¸...")
        print("=" * 50)

    previous_stop_loss_codes = current_codes.copy()

def monitor_quit_key():
    """èƒŒæ™¯åŸ·è¡Œçš„ Q éµåµæ¸¬å™¨ï¼ŒæŒ‰ä¸‹ Q å°‡ quit_flag['quit'] è¨­ç‚º True"""
    while True:
        if msvcrt.kbhit():
            key = msvcrt.getch().decode("utf-8").upper()
            if key == 'Q':
                quit_flag['quit'] = True

def show_exit_menu():
    """éé˜»å¡åœ°é¡¯ç¤ºé€€å‡ºå¹³å€‰é¸å–®ï¼ˆå¯¦éš›å¹³å€‰é‚è¼¯å¯¦ä½œï¼‰"""
    def _menu():
        print("\n================ æ‰‹å‹•é€€å‡ºé¸å–® ================")
        print("1. ç›´æ¥é€€å‡ºï¼Œä¸å¹³å€‰")
        print("2. å¹³å€‰")
        print("0. è¿”å›ç¨‹å¼")
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š").strip()
        if choice == "1":
            confirm = input("âš ï¸  ç¢ºå®šä¸å¹³å€‰ç›´æ¥é€€å‡ºï¼Ÿ(Y/N)ï¼š").strip().upper()
            if confirm == "Y":
                os._exit(0)
                main_menu()

        elif choice == "2":
            while True:
                list_open_positions()
                print("\nå¹³å€‰é¸é …ï¼š1. å…¨éƒ¨å¹³å€‰  2. é¸æ“‡è‚¡ç¥¨  0. è¿”å›ç¨‹å¼")
                sub = input("è«‹è¼¸å…¥ï¼š").strip()
                if sub == "1":
                    exit_trade_live()
                    os._exit(0)
                    main_menu()
                elif sub == "2":
                    if not open_positions:
                        continue
                    code = input("è¼¸å…¥è¦å¹³å€‰çš„è‚¡ç¥¨ä»£è™Ÿï¼š").strip()
                    if code in open_positions:
                        close_one_stock(code)
                    else:
                        print("ä»£è™Ÿä¸å­˜åœ¨æ–¼æŒå€‰")
                    cont = input("å·²è™•ç†ï¼Œç¹¼çºŒåŸ·è¡Œç¨‹å¼ï¼Ÿ(Y=ç¹¼çºŒ/N=é€€å‡º)ï¼š").strip().upper()
                    if cont == "N":
                        os._exit(0)
                        main_menu()
                elif sub == "0":
                    break
        else:
            print("âŒ ç„¡æ•ˆé¸é …ï¼Œç¹¼çºŒåŸ·è¡Œç¨‹å¼ã€‚")

    threading.Thread(target=_menu, daemon=True).start()
def save_matrix_dict(matrix_dict):
    with open('matrix_dict_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(matrix_dict, f, indent=4, ensure_ascii=False)

def load_matrix_dict_analysis():
    if os.path.exists('matrix_dict_analysis.json'):
        with open('matrix_dict_analysis.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        print("matrix_dict_analysis.json æ–‡ä»¶ä¸å­˜åœ¨ã€‚")
        return {}

def save_nb_matrix_dict(nb_matrix_dict):
    with open('nb_matrix_dict.json', 'w', encoding='utf-8') as f:
        json.dump(nb_matrix_dict, f, indent=4, ensure_ascii=False, default=str)

def initialize_stock_data(symbols_to_analyze, daily_kline_data, intraday_kline_data):
    stock_data_collection = {}
    for symbol in symbols_to_analyze:
        if symbol not in daily_kline_data or symbol not in intraday_kline_data:
            print(f"è‚¡ç¥¨ä»£è™Ÿ {symbol} çš„æ—¥ K ç·šæˆ–ä¸€åˆ† K ç·šè³‡æ–™ç¼ºå¤±ï¼Œè·³éã€‚")
            continue
        daily_kline_df = pd.DataFrame(daily_kline_data[symbol])
        intraday_data = pd.DataFrame(intraday_kline_data[symbol])
        if intraday_data.empty:
            print(f"è‚¡ç¥¨ä»£è™Ÿ {symbol} çš„æ—¥å…§æ•¸æ“šç‚ºç©ºï¼Œè·³éã€‚")
            continue
        complete_df = ensure_continuous_time_series(intraday_data)
        complete_df = complete_df.drop(columns=['average'], errors='ignore')
        stock_data_collection[symbol] = complete_df
    return stock_data_collection

    
def truncate_to_two_decimals(value):
    if isinstance(value, float):
        return math.floor(value * 100) / 100
    return value

def save_auto_intraday_data(auto_intraday_data):
    try:
        with open('auto_intraday.json', 'wb') as f:
            f.write(orjson.dumps(auto_intraday_data, option=orjson.OPT_NON_STR_KEYS))
        print(f"{YELLOW}âœ… å·²å„²å­˜ auto_intraday.json{RESET}")
    except Exception as e:
        print(f"{YELLOW}âŒ å„²å­˜ auto_intraday.json æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}{RESET}")

def initialize_triggered_limit_up(auto_intraday_data: dict):
    """
    æƒæ auto_intraday.json è£¡çš„æ­·å² 1 åˆ† Kï¼š
    åªè¦æ›¾å‡ºç¾ã€ç•¶æ ¹ high == æ¼²åœåƒ¹ ä¸” å‰ä¸€æ ¹ high < æ¼²åœåƒ¹ã€
    å°±æŠŠè©²è‚¡ç¥¨åŠ å…¥ triggered_limit_up_stocksï¼Œç•¶å¤©ä¹‹å¾Œä¸å†è§¸ç™¼ã€‚
    """
    now_txt = datetime.now().strftime("%H:%M")
    for sym, kbars in auto_intraday_data.items():
        for i in range(1, len(kbars)):
            prev, curr = kbars[i-1], kbars[i]
            if curr["high"] == curr["æ¼²åœåƒ¹"] and prev["high"] < curr["æ¼²åœåƒ¹"]:
                triggered_limit_up_stocks.add(sym)
                print(f"[{now_txt}] è‚¡ç¥¨ {sym} æ›¾ç¶“æ¼²åœè§¸ç™¼ â†’ åŠ å…¥å·²è§¸ç™¼æ¸…å–®")
                break  # åªè¦è¨˜ä¸€æ¬¡å°±å¥½

def convert_datetime_to_str(obj):
    if isinstance(obj, dict):
        return {k: convert_datetime_to_str(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_datetime_to_str(element) for element in obj]
    elif isinstance(obj, (datetime, pd.Timestamp, time)):
        return obj.isoformat()
    else:
        return obj

# ------------------ å›æ¸¬ç¨‹å¼ä¸»ç¨‹å¼ ------------------
def process_group_data(stock_data_collection, wait_minutes, hold_minutes,
                       matrix_dict_analysis, verbose=True):
    """
    === å›æ¸¬å‡½æ•¸ (Back-test)  ===
    - åŒæ­¥ process_live_trading_logic çš„å››å¤§é‚è¼¯ï¼š
      1. æ‹‰é«˜è§¸ç™¼ï¼š5-min æ¼²å¹… â‰¥ 2% ä¸”æˆäº¤é‡ > 1.5Ã—(09:00-09:02 å¹³å‡é‡)
      2. è¿½è¹¤æ¸…å–®åŠ å…¥é–€æª»ï¼š5-min æ¼²å¹… â‰¥ 1.5%
      3. æ¼²åœè§¸ç™¼ï¼šhigh == æ¼²åœåƒ¹ ä¸” (å‰ä¸€æ ¹ high < æ¼²åœåƒ¹ï¼Œ09:00 ä¾‹å¤–)
      4. ç­‰å¾…æœŸæ»¿å¾Œçš„ eligible ç¯©é¸èˆ‡é€²å ´ã€åœæé‚è¼¯
    """

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0-A. æœ¬åœ°æ——æ¨™åˆå§‹åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    in_position         = False
    has_exited          = False
    current_position    = None
    stop_loss_triggered = False
    final_check_active  = False        # å›æ¸¬ç‰ˆä»ä¿ç•™ä½†ç›®å‰æœªç”¨
    final_check_count   = 0            # ã€ƒ
    hold_time           = 0

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0-B. éœ€è¦çš„å…¨åŸŸè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    global capital_per_stock, transaction_fee, transaction_discount, trading_tax
    global price_gap_below_50, price_gap_50_to_100, price_gap_100_to_500
    global price_gap_500_to_1000, price_gap_above_1000
    global allow_reentry_after_stop_loss
    # --------------------------------------------------------------

    # ---------- 0-C. é–‹ç›¤å‰ä¸‰åˆ†é˜å¹³å‡é‡ ---------- #
    FIRST3_AVG_VOL: dict[str, float] = {}
    for sym, df in stock_data_collection.items():
        first3 = df[df['time'].astype(str).isin(['09:00:00', '09:01:00', '09:02:00'])]
        FIRST3_AVG_VOL[sym] = first3['volume'].mean() if not first3.empty else 0

    # ---------- 0-D. å…¶ä»–ç‹€æ…‹è®Šæ•¸ ---------- #
    message_log: list[tuple[str, str]] = []
    tracking_stocks: set[str] = set()
    leader                      = None
    leader_peak_rise            = None
    leader_rise_before_decline  = None
    in_waiting_period           = False
    waiting_time                = 0
    pull_up_entry               = False
    limit_up_entry              = False
    first_condition_one_time    = None

    # ---------- 0-E. çµ„ merge DataFrame ---------- #
    merged_df = None
    req_cols = ['time', 'rise', 'high', 'æ¼²åœåƒ¹',
                'close', '2min_pct_increase', 'volume']
    for sym, df in stock_data_collection.items():
        if not all(c in df.columns for c in req_cols):
            continue
        tmp = df[req_cols].copy()
        tmp = tmp.rename(columns={
            'rise':               f'rise_{sym}',
            'high':               f'high_{sym}',
            'æ¼²åœåƒ¹':             f'limit_up_price_{sym}',
            'close':              f'close_{sym}',
            '2min_pct_increase':  f'2min_pct_increase_{sym}',
            'volume':             f'volume_{sym}'
        })
        merged_df = tmp if merged_df is None else pd.merge(
            merged_df, tmp, on='time', how='outer')

    if merged_df is None or merged_df.empty:
        print("ç„¡æœ‰æ•ˆè³‡æ–™å¯å›æ¸¬")
        return None, None
    merged_df.sort_values('time', inplace=True, ignore_index=True)

    # â•â•â•â•â•â•â•â•â•â•â• 1. é€åˆ†é˜ä¸»è¿´åœˆ â•â•â•â•â•â•â•â•â•â•â• #
    total_profit = total_profit_rate = total_trades = 0

    for _, row in merged_df.iterrows():
        current_time     = row['time']
        current_time_str = current_time.strftime('%H:%M:%S')

        # â”€â”€ 1-1. æŒå€‰æœŸé–“ï¼šå¼·åˆ¶ / æ™‚é–“å¹³å€‰ / æ¢ä»¶åœæ â”€â”€ #
        if in_position and not has_exited:
            hold_time += 1

            # a) 13:30 å¼·åˆ¶
            if current_time_str == '13:30:00':
                profit, rate = exit_trade(
                    stock_data_collection[current_position['symbol']],
                    current_position['shares'],
                    current_position['entry_price'],
                    current_position['sell_cost'],
                    current_position['entry_fee'],
                    current_position['tax'],
                    message_log,
                    current_time, hold_time,
                    current_position['entry_time'],
                    use_f_exit=True
                )
                if profit is not None:
                    total_trades += 1
                    total_profit += profit
                    total_profit_rate += rate
                in_position = False
                has_exited  = True
                current_position = None
                continue

            # b) æŒæœ‰åˆ†é˜åˆ°æœŸ
            if hold_minutes is not None and hold_time >= hold_minutes:
                profit, rate = exit_trade(
                    stock_data_collection[current_position['symbol']],
                    current_position['shares'],
                    current_position['entry_price'],
                    current_position['sell_cost'],
                    current_position['entry_fee'],
                    current_position['tax'],
                    message_log,
                    current_time, hold_time,
                    current_position['entry_time']
                )
                if profit is not None:
                    total_trades += 1
                    total_profit += profit
                    total_profit_rate += rate
                in_position = False
                has_exited  = True
                continue

            # c) åœææ¢ä»¶ä¸‰
            sel_df  = stock_data_collection[current_position['symbol']]
            now_row = sel_df[sel_df['time'] == current_time]
            if not now_row.empty:
                h_now = truncate_to_two_decimals(now_row.iloc[0]['high'])
                thresh = truncate_to_two_decimals(
                    current_position['stop_loss_threshold'])
                if h_now >= thresh:
                    exit_price = thresh
                    exit_cost  = current_position['shares'] * exit_price * 1000
                    exit_fee   = int(exit_cost * (transaction_fee*0.01) *
                                     (transaction_discount*0.01))
                    profit = (current_position['sell_cost'] - exit_cost
                              - current_position['entry_fee'] - exit_fee
                              - current_position['tax'])
                    rate = (profit * 100) / (current_position['sell_cost']
                                              - current_position['entry_fee']
                                              - exit_fee)
                    message_log.append(
                        (current_time_str,
                         f"{Fore.RED}åœæè§¸ç™¼ï¼Œåˆ©æ½¤ {int(profit)} å…ƒ "
                         f"({rate:.2f}%){Style.RESET_ALL}")
                    )
                    total_trades += 1
                    total_profit += profit
                    total_profit_rate += rate
                    in_position = False
                    has_exited  = True
                    current_position = None
                    stop_loss_triggered = True
                    if not allow_reentry_after_stop_loss:
                        break
            continue  # æŒå€‰æ™‚ä¸å†æª¢æŸ¥æ–°è§¸ç™¼

        # â”€â”€ 1-2. æª¢æŸ¥è§¸ç™¼ (æ‹‰é«˜/æ¼²åœ) â”€â”€ #
        trigger_list = []
        for sym in stock_data_collection.keys():
            pct  = row.get(f'2min_pct_increase_{sym}')
            vol  = row.get(f'volume_{sym}')
            high = row.get(f'high_{sym}')
            lup  = row.get(f'limit_up_price_{sym}')
            avgv = FIRST3_AVG_VOL.get(sym, 0)

            # æ¼²åœ
            hit_limit = False
            if high is not None and lup is not None and high == lup:
                if current_time_str == '09:00:00':
                    hit_limit = True
                else:
                    prev_time = (datetime.combine(date.today(), current_time)
                                 - timedelta(minutes=1)).time()
                    prev_high = stock_data_collection[sym].loc[
                        stock_data_collection[sym]['time'] == prev_time,
                        'high']
                    if prev_high.empty or prev_high.iloc[0] < lup:
                        hit_limit = True
            if hit_limit:
                trigger_list.append({'symbol': sym, 'condition': 'limit_up'})
                continue

            # æ‹‰é«˜
            if (pct is not None and pct >= 2
               and vol is not None and avgv and vol > 1.3*avgv):
                trigger_list.append({'symbol': sym, 'condition': 'pull_up'})

        # â”€â”€ 1-3. è™•ç†è§¸ç™¼çµæœ â†’ æ›´æ–° tracking / leader / waiting â”€â”€ #
        for item in trigger_list:
            sym  = item['symbol']
            cond = item['condition']
            if cond == 'limit_up':
                tracking_stocks.clear()
                tracking_stocks.add(sym)
                leader = sym
                in_waiting_period = True
                waiting_time = 0
                pull_up_entry  = False
                limit_up_entry = True
                first_condition_one_time = datetime.combine(date.today(), current_time)
                if verbose:
                    message_log.append(
                        (current_time_str,
                         f"{Fore.CYAN}{sym} æ¼²åœè§¸ç™¼ï¼Œé–‹å§‹ç­‰å¾…{Style.RESET_ALL}"))
            else:  # pull_up
                if not pull_up_entry:
                    pull_up_entry = True
                    limit_up_entry = False
                    tracking_stocks.clear()
                    first_condition_one_time = datetime.combine(date.today(), current_time)
                tracking_stocks.add(sym)
                if verbose:
                    message_log.append(
                        (current_time_str,
                         f"{sym} æ‹‰é«˜è§¸ç™¼ï¼ŒåŠ å…¥è¿½è¹¤"))

        # è¿½è¹¤æ¸…å–®æ“´å……é–€æª» 1.5%
        if pull_up_entry:
            for sym in stock_data_collection.keys():
                if sym in tracking_stocks:
                    continue
                pct = row.get(f'2min_pct_increase_{sym}')
                if pct is not None and pct >= 1.5:
                    tracking_stocks.add(sym)

        # â”€â”€ 1-4. é ˜æ¼²é¸æ“‡èˆ‡åè½‰åµæ¸¬ â”€â”€ #
        if pull_up_entry and tracking_stocks:
            # é¸æ“‡ rise æœ€å¤§è€…
            max_sym, max_rise = None, None
            for sym in tracking_stocks:
                r = row.get(f'rise_{sym}')
                if r is not None and (max_rise is None or r > max_rise):
                    max_rise, max_sym = r, sym
            if leader != max_sym:
                if leader and verbose:
                    message_log.append(
                        (current_time_str,
                        f"{Fore.CYAN}é ˜æ¼²æ›¿æ›ï¼š{leader} â†’ {max_sym}{Style.RESET_ALL}"))

                leader = max_sym
                leader_peak_rise = max_rise
                leader_rise_before_decline = max_rise

                # âœ… é ˜æ¼²æ›¿æ›åªæ›´æ–°ï¼Œä¸é€²å…¥ç­‰å¾…
                in_waiting_period = False
                waiting_time = 0
                if verbose:
                    message_log.append(
                        (current_time_str,
                        f"{Fore.MAGENTA}ğŸš€ é ˜æ¼²æ›¿æ›è§¸ç™¼ï¼Œé‡æ–°ç›£æ§é ˜æ¼²{Style.RESET_ALL}"))
            # åè½‰ â†’ é€²å…¥ç­‰å¾…
            if leader:
                h_now = row.get(f'high_{leader}')
                prev_time = (datetime.combine(date.today(), current_time)
                             - timedelta(minutes=1)).time()
                prev_row = stock_data_collection[leader][
                    stock_data_collection[leader]['time'] == prev_time]
                if not prev_row.empty:
                    h_prev = prev_row.iloc[0]['high']
                    if h_now <= h_prev and not in_waiting_period:
                        in_waiting_period = True
                        waiting_time = 0
                        leader_rise_before_decline = max_rise
                        if verbose:
                            message_log.append(
                                (current_time_str,
                                 f"é ˜æ¼² {leader} åè½‰ï¼Œé–‹å§‹ç­‰å¾…"))

        # â”€â”€ 1-5. ç­‰å¾…æ™‚é–“è¨ˆæ•¸ & å®Œæˆå¾Œç¯©é¸ eligible â”€â”€ #
        if in_waiting_period:
            if waiting_time >= wait_minutes:
                # ç­‰å¾…å®Œæˆï¼Œé‡ç½® flag
                in_waiting_period = False
                waiting_time      = 0

                # â”€â”€â”€ å…ˆæ‰¾å‡ºé€™è¼ªç­‰å¾…çš„ leader å±¬æ–¼å“ªå€‹ç¾¤çµ„ â”€â”€â”€
                current_group = next(
                    (g for g, syms in matrix_dict_analysis.items() if leader in syms),
                    None
                )
                if current_group is None:
                    # ç„¡æ³•è­˜åˆ¥ç¾¤çµ„ï¼Œè·³éç›¸ä¼¼åº¦éæ¿¾
                    filtered_stocks = set(tracking_stocks)
                else:
                    # ä»¥ç›¸ä¼¼åº¦å…ˆç¯©é¸è·Ÿ leader ç›¸è¿‘çš„è‚¡ç¥¨
                    sim_ok = calculate_group_kline_data(
                        leader=leader,
                        candidates=list(tracking_stocks),
                        intraday_file="intraday_kline_data.json",
                        group_symbols=matrix_dict_analysis[current_group],
                        wait_end_time=datetime.combine(date.today(), current_time),
                        similarity_threshold=0.4,
                        close_weight=2.0
                    )
                    if verbose:
                        message_log.append(
                            (current_time_str,
                            f"[SIM] ç›¸ä¼¼åº¦åˆæ ¼ï¼š{sim_ok}")
                        )
                    
                    # **æ–°å¢ debugï¼šç¢ºèª tracking_stocks èˆ‡ sim_ok**
                    message_log.append((current_time_str, f"[DEBUG] tracking_stocks = {tracking_stocks}"))
                    

                    filtered_stocks = set(sim_ok)

                    
                    # **ç«‹åˆ»å°å‡º filtered_stocksï¼Œç¢ºèªçœŸæ­£å¸¶é€²é‡èƒ½éæ¿¾çš„æ˜¯å“ªäº›è‚¡ç¥¨**  
                    if verbose:
                        message_log.append((current_time_str, f"[DEBUG] filtered_stocks = {filtered_stocks}"))
                    


                # â”€â”€ æ¥è‘—æ‰é€²å…¥åŸæœ¬çš„ eligible ç¯©é¸æµç¨‹ â”€â”€
                def _vol_break(sym, join_time):
                    df   = stock_data_collection[sym]
                    avgv = FIRST3_AVG_VOL.get(sym, 0)
                    later = df[df['time'] >= join_time.time()]
                    return (later['volume'] >= 1.5*avgv).any()

                def _rise_peak_flat(sym: str, join_time: datetime) -> bool:
                    """
                    æª¢æŸ¥å¾ join_time é–‹å§‹ç®—ï¼Œsym é€™æ”¯è‚¡ç¥¨çš„ rise æ˜¯å¦ã€Œå…ˆè¦‹é«˜é»å¾Œä¸å†å‰µé«˜ã€ã€‚
                    åŒæ™‚å°å‡º debug è¨Šæ¯ï¼šrise åºåˆ—ã€æœ€é«˜é»ã€å¾ŒçºŒæœ€å¤§å€¼ï¼Œä»¥åŠæ˜¯å¦é€šéã€‚
                    """
                    df = stock_data_collection[sym]
                    # å–å‡ºå¾ join_time ä¹‹å¾Œçš„æ‰€æœ‰ K æ£’
                    sub = df[df['time'] >= join_time.time()]
                    if sub.empty:
                        if verbose:
                            message_log.append((current_time_str,
                                f"[DEBUG-PEAK] {sym} ç„¡ä»»ä½• join_time ä¹‹å¾Œçš„è³‡æ–™ â†’ ä¸é€šé"))
                        return False

                    # æ‰¾å‡ºæœ€é«˜é»
                    pkidx = sub['rise'].idxmax()
                    pkval = sub.loc[pkidx, 'rise']

                    # å¾ŒçºŒæ‰€æœ‰é»
                    later = sub.loc[pkidx+1:]
                    later_max = later['rise'].max() if not later.empty else None

                    # åˆ¤æ–·æ˜¯å¦å†å‰µé«˜
                    passed = (later_max is None) or (later_max <= pkval)

                    # åµéŒ¯è¼¸å‡º
                    if verbose:
                        message_log.append((current_time_str,
                            f"[DEBUG-PEAK] {sym} rises={sub['rise'].tolist()}"))
                        message_log.append((current_time_str,
                            f"[DEBUG-PEAK] {sym} peak={pkval:.2f} at idx={pkidx}, "
                            f"later_max={later_max if later_max is not None else 'N/A'}, pass={passed}"))

                    return passed

                # 1. åˆ—å‡ºé‡èƒ½çªç ´é–€æª»çš„è‚¡ç¥¨
                passed_vol = [s for s in filtered_stocks if _vol_break(s, first_condition_one_time)]
                
                message_log.append((current_time_str, f"[DEBUG] æˆäº¤é‡é€šé: {passed_vol}"))
                
                
                # 2. åˆ—å‡ºåè½‰é€šéçš„è‚¡ç¥¨åŠå³°é ‚æ™‚é–“
                passed_reversal = []
                for s in passed_vol:
                    df    = stock_data_collection[s]
                    sub   = df[df['time'] >= first_condition_one_time.time()]
                    pkidx = sub['rise'].idxmax()
                    pk_time = sub.loc[pkidx, 'time'].strftime('%H:%M:%S')
                    # ç”¨ _rise_peak_flat åŒæ™‚è¨ˆç®— passed
                    if _rise_peak_flat(s, first_condition_one_time):
                        passed_reversal.append((s, pk_time))
                message_log.append((current_time_str, f"[DEBUG] åè½‰é€šé: {passed_reversal}"))

                # 3. å»ºç«‹ eligible ä¸¦æŠŠåè½‰æ™‚é–“å¸¶å…¥ debug
                eligible = []
                for s, pk_time in passed_reversal:
                    rise_now = row[f"rise_{s}"]
                    price_now= row[f"close_{s}"]
                    if rise_now is None or not (-2 <= rise_now <= 6): continue
                    if price_now is None or price_now > capital_per_stock*1.5: continue
                    row_sym = stock_data_collection[s][stock_data_collection[s]['time']==current_time].iloc[0]
                    eligible.append({'symbol': s, 'rise': rise_now, 'row': row_sym, 'reversal_time': pk_time})
                    message_log.append((current_time_str,
                        f"[ELIGIBLE] {s} å³°é ‚ {pk_time} æ¼²å¹… {rise_now:.2f}%"))
                    
                eligible = []
                for sym in filtered_stocks:
                    if sym == leader:
                        continue
                    # 2) æˆäº¤é‡çªç ´
                    if not _vol_break(sym, first_condition_one_time):
                        continue
                    # 3) rise å…ˆè¦‹é«˜é»å¾Œä¸å†å‰µé«˜
                    if not _rise_peak_flat(sym, first_condition_one_time):
                        continue
                    # 4) ç•¶ä¸‹çš„æ¼²å¹…ã€åƒ¹æ ¼æª¢æŸ¥
                    rise_now = row.get(f'rise_{sym}')
                    if rise_now is None or not (-2 <= rise_now <= 6):
                        continue
                    price_now = row.get(f'close_{sym}')
                    if price_now is None or price_now > capital_per_stock*1.5:
                        continue
                    row_sym = stock_data_collection[sym].loc[
                        stock_data_collection[sym]['time'] == current_time
                    ].iloc[0]
                    eligible.append({'symbol': sym, 'rise': rise_now, 'row': row_sym})

                if not eligible:
                    # æµç¨‹é‡ç½®
                    pull_up_entry = limit_up_entry = False
                    tracking_stocks.clear()
                    if verbose:
                        message_log.append(
                            (current_time_str,
                             "ç­‰å¾…çµæŸç„¡ç¬¦åˆè‚¡ç¥¨ï¼Œæµç¨‹é‡ç½®"))
                else:
                    eligible.sort(key=lambda x: x['rise'], reverse=True)
                    chosen = eligible[len(eligible)//2]

                    # é€²å ´èˆ‡åœæè¨ˆç®—èˆ‡ live ç‰ˆä¸€è‡´
                    rowch   = chosen['row']
                    entry_p = rowch['close']
                    shares  = round((capital_per_stock*10000)/(entry_p*1000))
                    sell_cost = shares * entry_p * 1000
                    entry_fee = int(sell_cost * (transaction_fee*0.01) *
                                    (transaction_discount*0.01))
                    tax   = int(sell_cost * (trading_tax*0.01))
                    if entry_p < 10:
                        gap, tick = price_gap_below_50, 0.01
                    elif entry_p < 50:
                        gap, tick = price_gap_50_to_100, 0.05
                    elif entry_p < 100:
                        gap, tick = price_gap_50_to_100, 0.1
                    elif entry_p < 500:
                        gap, tick = price_gap_100_to_500, 0.5
                    elif entry_p < 1000:
                        gap, tick = price_gap_500_to_1000, 1
                    else:
                        gap, tick = price_gap_above_1000, 5

                    highest_on_entry = rowch['highest'] or entry_p
                    if (highest_on_entry-entry_p)*1000 < gap:
                        stop_thr = entry_p + gap/1000
                    else:
                        stop_thr = highest_on_entry + tick

                    current_position = {
                        'symbol': chosen['symbol'], 'shares': shares,
                        'entry_price': entry_p, 'sell_cost': sell_cost,
                        'entry_fee': entry_fee, 'tax': tax,
                        'entry_time': current_time_str,
                        'current_price_gap': gap, 'tick_unit': tick,
                        'highest_on_entry': highest_on_entry,
                        'stop_loss_threshold': stop_thr
                    }
                    in_position = True
                    has_exited  = False
                    hold_time   = 0
                    pull_up_entry = limit_up_entry = False
                    tracking_stocks.clear()
                    if verbose:
                        message_log.append(
                            (current_time_str,
                             f"{Fore.GREEN}é€²å ´ï¼{chosen['symbol']} {shares}å¼µ "
                             f"åƒ¹ {entry_p:.2f} åœæ {stop_thr:.2f}"
                             f"{Style.RESET_ALL}"))
            else:
                # ğŸ” æ–°å¢ï¼šæª¢æŸ¥æ˜¯å¦å†å‰µæ–°é«˜
                if leader:
                    rise_now = row.get(f"rise_{leader}")
                    if leader_rise_before_decline is not None and rise_now is not None and rise_now > leader_rise_before_decline:
                        if verbose:
                            message_log.append(
                                (current_time_str,
                                f"{Fore.YELLOW}ğŸš€ é ˜æ¼²è‚¡ {leader} å†å‰µæ–°é«˜ {rise_now:.2f}% > {leader_rise_before_decline:.2f}%ï¼Œè§¸ç™¼è‡ªæˆ‘æ›¿æ›{Style.RESET_ALL}"))

                        leader_rise_before_decline = rise_now

                        # âœ… çµ‚æ­¢ç­‰å¾…ï¼ˆé‡é»ï¼‰
                        in_waiting_period = False
                        waiting_time = 0

                        if verbose:
                            message_log.append(
                                (current_time_str,
                                f"{Fore.MAGENTA}ğŸš€ è‡ªæˆ‘æ›¿æ›è§¸ç™¼ï¼Œçµ‚æ­¢ç­‰å¾…ï¼Œé‡æ–°è§€å¯Ÿé ˜æ¼²{Style.RESET_ALL}"))
                        continue  # âš¡ é‡é»ï¼ä¸è¦ç¹¼çºŒåŠ  waiting_time

                # å¦‚æœæ²’æœ‰è‡ªæˆ‘æ›¿æ›ï¼Œæ‰é€²è¡ŒåŸæœ¬ç­‰å¾…ç´¯åŠ 
                waiting_time += 1
                if verbose:
                    message_log.append(
                        (current_time_str,
                        f"ç­‰å¾…ä¸­ï¼Œç¬¬ {waiting_time} åˆ†é˜"))

    # â•â•â•â•â•â•â•â•â•â•â• 2. å›æ¸¬çµæœè¼¸å‡º â•â•â•â•â•â•â•â•â•â•â• #
    message_log.sort(key=lambda x: x[0])
    for t, msg in message_log:
        print(f"[{t}] {msg}")

    if total_trades:
        avg_rate = total_profit_rate / total_trades
        print(f"\næ¨¡æ“¬å®Œæˆï¼Œç¸½åˆ©æ½¤ï¼š{int(total_profit)} å…ƒï¼Œå¹³å‡å ±é…¬ç‡ï¼š{avg_rate:.2f}%\n")
        return total_profit, avg_rate
    else:
        print("ç„¡äº¤æ˜“ï¼Œç„¡æ³•è¨ˆç®—åˆ©æ½¤")
        return None, None
    
def exit_trade(
    selected_stock_df, shares, entry_price, sell_cost,
    entry_fee, tax,
    message_log, current_time, hold_time, entry_time, use_f_exit=False
):
    global transaction_fee, transaction_discount, trading_tax
    global in_position, has_exited, current_position
    current_time_str = current_time if isinstance(current_time, str) else current_time.strftime('%H:%M:%S')
    selected_stock_df['time'] = pd.to_datetime(selected_stock_df['time'], format='%H:%M:%S').dt.time

    if isinstance(entry_time, str):
        entry_time_obj = datetime.strptime(entry_time, '%H:%M:%S').time()
    else:
        entry_time_obj = entry_time

    if use_f_exit:
        end_time = datetime.strptime('13:30', '%H:%M').time()
        end_price_series = selected_stock_df[selected_stock_df['time'] == end_time]['close']
        if not end_price_series.empty:
            end_price = end_price_series.values[0]
        else:
            print("ç„¡æ³•å–å¾— 13:30 çš„æ•¸æ“šï¼Œå‡ºå ´æ™‚é–“é…å°éŒ¯èª¤")
            message_log.append((current_time_str, f"{RED}å‡ºå ´æ™‚é–“é…å°éŒ¯èª¤{RESET}"))
            return None, None
        entry_datetime = datetime.combine(date.today(), entry_time_obj)
        if isinstance(current_time, datetime):
            current_datetime = current_time
        else:
            current_datetime = datetime.combine(date.today(), current_time)
        hold_time_calculated = int((current_datetime - entry_datetime).total_seconds() / 60)
    else:
        entry_index_series = selected_stock_df[selected_stock_df['time'] == entry_time_obj].index
        if not entry_index_series.empty:
            entry_index = entry_index_series[0]
            exit_index = entry_index + hold_time
            if exit_index >= len(selected_stock_df):
                print("å‡ºå ´æ™‚é–“è¶…å‡ºç¯„åœï¼Œç„¡æ³•é€²è¡Œäº¤æ˜“")
                message_log.append((current_time_str, f"{RED}å‡ºå ´æ™‚é–“è¶…å‡ºç¯„åœ{RESET}"))
                return None, None
            end_price = selected_stock_df.iloc[exit_index]['close']
        else:
            print("é€²å ´æ™‚é–“é…å°éŒ¯èª¤ï¼Œç„¡æ³•æ‰¾åˆ°ç²¾ç¢ºçš„é€²å ´æ™‚é–“")
            message_log.append((current_time_str, f"{RED}é€²å ´æ™‚é–“é…å°éŒ¯èª¤{RESET}"))
            return None, None
        hold_time_calculated = hold_time

    buy_cost = shares * end_price * 1000
    exit_fee = int(buy_cost * (transaction_fee * 0.01) * (transaction_discount * 0.01))
    profit = sell_cost - buy_cost - entry_fee - exit_fee - tax
    return_rate = (profit * 100) / (buy_cost - exit_fee) if (buy_cost - exit_fee) != 0 else 0.0

    if use_f_exit:
        message_log.append(
            (current_time_str,
             f"{RED}è‚¡ç¥¨å‡ºå ´ï¼ŒæŒæœ‰æ™‚é–“ {hold_time_calculated} åˆ†é˜ï¼ˆå¼·åˆ¶å‡ºå ´ï¼‰{RESET}")
        )
    else:
        message_log.append(
            (current_time_str,
             f"{RED}è‚¡ç¥¨å‡ºå ´ï¼ŒæŒæœ‰æ™‚é–“ {hold_time_calculated} åˆ†é˜{RESET}")
        )
    message_log.append(
        (current_time_str,
         f"{RED}æŒæœ‰å¼µæ•¸ï¼š{shares} å¼µï¼Œå‡ºå ´åƒ¹æ ¼ï¼š{end_price} å…ƒï¼Œå‡ºå ´åƒ¹é‡‘ï¼š{int(buy_cost)} å…ƒï¼Œåˆ©æ½¤ï¼š{int(profit)} å…ƒï¼Œ"
         f"å ±é…¬ç‡ï¼š{return_rate:.2f}%ï¼Œæ‰‹çºŒè²»ï¼š{exit_fee} å…ƒ{RESET}")
    )

    in_position = False
    has_exited = True
    return profit, return_rate


# ------------------ äº¤æ˜“ç¨‹å¼ä¸»ç¨‹å¼ ------------------
#æ–°å¢ç®¡ç†å¥—ä»¶
to = tp.TouchOrderExecutor(api)

def process_live_trading_logic(
    symbols_to_analyze,
    current_time_str,
    wait_minutes,
    hold_minutes,
    message_log,
    in_position,
    has_exited,
    current_position,
    hold_time,
    already_entered_stocks,
    stop_loss_triggered,
    final_check_active,
    final_check_count,
    in_waiting_period,
    waiting_time,
    leader,
    tracking_stocks,
    previous_rise_values,
    leader_peak_rise,
    leader_rise_before_decline,
    first_condition_one_time,
    can_trade,
    group_positions,
    nb_matrix_path="nb_matrix_dict.json"
):
    """
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      ç›¤ä¸­é€²å ´é‚è¼¯ï¼ˆæ¼²åœé€²å ´ / æ‹‰é«˜é€²å ´ï¼‰
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. è§¸ç™¼æ¢ä»¶  
       â–¸ æ¼²åœé€²å ´ï¼šæœ€æ–° K æ£’ high == æ¼²åœåƒ¹ï¼Œä¸”å‰ä¸€ K æ£’ high < æ¼²åœåƒ¹  
       â–¸ æ‹‰é«˜é€²å ´ï¼š5Â min æ¼²å¹… â‰¥Â 2% ä¸” volume > 1.5Ã—(09:00~09:02 å¹³å‡é‡)

    2. è¿½è¹¤æ¸…å–®ï¼ˆæœ¬ç‰ˆè¦å‰‡ï¼‰  
       â”€ åŠ å…¥æ¢ä»¶ï¼š5Â min æ¼²å¹… â‰¥Â 1.5Â %  
       â”€ åŠ å…¥æ™‚è¨˜éŒ„ join_timeã€base_volã€base_rise

    3. ç­‰å¾…å®Œæˆå¾Œçš„é€²å ´ç¯©é¸  
       â¶ éé ˜æ¼²  
       â· è‡ªåŠ å…¥è¿½è¹¤å¾Œ volume â‰¥Â 1.5Ã—(09:00~09:02 å¹³å‡é‡) æ›¾å‡ºç¾  
       â¸ è‡ªåŠ å…¥è¿½è¹¤å¾Œ rise å…ˆè¦‹é«˜é»ä¸”ä¹‹å¾Œæœªå†å‰µé«˜  
       â¹ ç­‰å¾…æœŸæ»¿ç•¶ä¸‹ rise âˆˆÂ [-2Â %,Â 6Â %]

       â†’ ä¾ rise ç”±å¤§åˆ°å°æ’åºï¼Œå–ä¸­é–“åå¾Œè‚¡ç¥¨ä¸‹å–®  
         (å¸‚åƒ¹ IOC è³£å‡º *dayâ€‘trade short*ï¼ŒTouchPrice åŠ åœæè²·å›)

    4. å…¶ä»–æµç¨‹ï¼ˆé ˜æ¼²åµæ¸¬ / åè½‰ç­‰å¾… / æœ€å¾Œåæ¬¡æª¢æŸ¥ / åœæè¨ˆç®—ï¼‰  
       æ²¿ç”¨èˆŠç‰ˆï¼Œåƒ…å°‡æ¶‰åŠè¿½è¹¤æ¸…å–® & é€²å ´æŒ‘é¸éƒ¨åˆ†ä¾æ–°è¦å‰‡æ”¹å¯«ã€‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """
    # ------------------------------ 0. å‰ç½® ------------------------------- #
    monitor_stop_loss_orders()  # åµæ¸¬åœæè§¸åƒ¹å–®æ˜¯å¦æ¶ˆå¤±

    global capital_per_stock, transaction_fee, transaction_discount, trading_tax
    global price_gap_below_50, price_gap_50_to_100, price_gap_100_to_500
    global price_gap_500_to_1000, price_gap_above_1000, triggered_limit_up_stocks
    
    # Q é€€å‡ºé¸å–®æª¢æŸ¥
    if quit_flag['quit']:
        threading.Thread(target=show_exit_menu, daemon=True).start()
        quit_flag['quit'] = False

    # æ™‚é–“è§£æ
    try:
        current_dt = datetime.strptime(current_time_str, "%H:%M")
    except ValueError:
        print(f"æ™‚é–“æ ¼å¼éŒ¯èª¤ï¼š{current_time_str} (é ˆ HH:MM)")
        return

    trading_time = current_dt.time()
    trading_txt  = current_dt.strftime("%H:%M:%S")

    # ---------- è®€ consolidated_symbols ----------
    if not os.path.exists(nb_matrix_path):
        print(f"æ‰¾ä¸åˆ° {nb_matrix_path}")
        return
    with open(nb_matrix_path, "r", encoding="utf-8") as f:
        nb_dict = json.load(f)
    consolidated_symbols = nb_dict.get("consolidated_symbols", {})
    if not isinstance(consolidated_symbols, dict):
        print("consolidated_symbols æ ¼å¼éŒ¯èª¤")
        return

    # ---------- è®€ auto_intraday ----------
    auto_intraday_file = "auto_intraday.json"
    if not os.path.exists(auto_intraday_file):
        print("ç¼ºå°‘ auto_intraday.json")
        return
    with open(auto_intraday_file, "r", encoding="utf-8") as f:
        auto_intraday_data = json.load(f)

    # ---------- å»ºç«‹ DataFrame å¿«å– ----------
    stock_df = {}
    for sym in symbols_to_analyze:
        data = auto_intraday_data.get(sym, [])
        df = pd.DataFrame(data).copy()
        if not df.empty:
            df["time"] = pd.to_datetime(df["time"], format="%H:%M:%S").dt.time
            df.sort_values("time", inplace=True)
            df.reset_index(drop=True, inplace=True)
        stock_df[sym] = df

    # ---------- é–‹ç›¤å‰ä¸‰åˆ†é˜å‡é‡ ----------
    FIRST3_AVG_VOL: dict[str, float] = {}
    for sym, df in stock_df.items():
        first3 = df[df["time"].astype(str).isin(["09:00:00", "09:01:00", "09:02:00"])]
        FIRST3_AVG_VOL[sym] = first3["volume"].mean() if not first3.empty else 0

    # ------------------------- 1. è§¸ç™¼æª¢æŸ¥ ------------------------------- #
    trigger_list = []

    # 13:00ä»¥å¾Œï¼Œä¸å†è§¸ç™¼æ¼²åœæˆ–æ‹‰é«˜é€²å ´
    if trading_time >= time(13, 0):
        print(f"â° {trading_txt} å·²è¶…é13:00ï¼Œåœæ­¢è§¸ç™¼æ–°çš„æ¼²åœé€²å ´èˆ‡æ‹‰é«˜é€²å ´ã€‚")
    else:
        for grp, syms in consolidated_symbols.items():
            # å·²ç¶“ã€Œè§€å¯Ÿä¸­ã€æˆ–ã€Œå·²é€²å ´ã€çš„æ—ç¾¤ä¸å†æª¢æŸ¥
            if grp in group_positions and group_positions[grp]:
                continue

            for sym in syms:
                if sym not in symbols_to_analyze:
                    continue
                df = stock_df[sym]
                if df.empty:
                    continue

                row_now = df[df["time"] == trading_time]
                if row_now.empty:
                    continue
                row_now = row_now.iloc[0]

                # ---- æ¼²åœé€²å ´è§¸ç™¼ ----
                hit_limit = False
                if sym not in triggered_limit_up_stocks and row_now["high"] == row_now["æ¼²åœåƒ¹"]:
                    prev_t = (datetime.combine(date.today(), trading_time) - timedelta(minutes=1)).time()
                    prev = df[df["time"] == prev_t]
                    prev_high = prev.iloc[0]["high"] if not prev.empty else None
                    if prev.empty or (prev_high is not None and prev_high < row_now["æ¼²åœåƒ¹"]):
                        hit_limit = True
                        triggered_limit_up_stocks.add(sym)
                        print(f"[{trading_txt}] è‚¡ç¥¨ {sym} ç¬¬ä¸€æ¬¡æ¼²åœè§¸ç™¼ï¼ŒåŠ å…¥å·²è§¸ç™¼æ¸…å–®")
                        # å–æ¶ˆåŒç¾¤æ‹‰é«˜è§€å¯Ÿ
                        for g2, gstat in group_positions.items():
                            if isinstance(gstat, dict) and gstat.get("trigger") == "æ‹‰é«˜é€²å ´":
                                if sym in consolidated_symbols.get(g2, []):
                                    group_positions[g2] = False
                                    msg = f"ğŸš€ {sym} æ¼²åœè§¸ç™¼ï¼å–æ¶ˆæ‹‰é«˜è§€å¯Ÿï¼Œè½‰ç”±æ¼²åœé€²å ´è™•ç†"
                                    print(msg)
                                    message_log.append((trading_txt, msg))

                # ---- æ‹‰é«˜è§¸ç™¼ ----
                pull_up = False
                if row_now["2min_pct_increase"] >= 2:
                    avgv = FIRST3_AVG_VOL[sym]
                    if avgv and row_now["volume"] > 1.3 * avgv:
                        pull_up = True

                if hit_limit or pull_up:
                    trigger_list.append({
                        "symbol": sym,
                        "group": grp,
                        "condition": "limit_up" if hit_limit else "pull_up"
                    })

    trigger_list.sort(key=lambda x: 0 if x["condition"] == "limit_up" else 1)

    # ---------- å¯«å…¥è§€å¯Ÿç‹€æ…‹ ----------
    for item in trigger_list:
        grp = item["group"]
        cond_txt = "æ¼²åœé€²å ´" if item["condition"] == "limit_up" else "æ‹‰é«˜é€²å ´"
        if grp not in group_positions or not group_positions[grp]:
            group_positions[grp] = {
                "status": "è§€å¯Ÿä¸­",
                "trigger": cond_txt,
                "start_time": datetime.combine(date.today(), trading_time),
                "tracking": {},
                "leader": None
            }
            msg = f"æ—ç¾¤ {grp} é€²å…¥è§€å¯Ÿä¸­ï¼ˆ{cond_txt}ï¼‰"
            print(msg)
            message_log.append((trading_txt, msg))

            if cond_txt == "æ¼²åœé€²å ´":
                gpos = group_positions[grp]
                gpos["wait_start"]   = datetime.combine(date.today(), trading_time)
                gpos["wait_counter"] = 0

    # ------------------------- 2. æ›´æ–°è¿½è¹¤æ¸…å–® --------------------------- #
    for grp, gstat in group_positions.items():
        if not (isinstance(gstat, dict) and gstat["status"] == "è§€å¯Ÿä¸­"):
            continue

        # ç¢ºä¿ tracking dict å­˜åœ¨
        track = gstat.setdefault("tracking", {})

        for sym in consolidated_symbols[grp]:
            df = stock_df[sym]
            if df.empty:
                continue
            row_now = df[df["time"] == trading_time]
            if row_now.empty:
                continue
            row_now = row_now.iloc[0]

            # åŠ å…¥æ¢ä»¶ï¼š2min_pct_increase â‰¥ 2%
            if row_now["2min_pct_increase"] >= 2 and sym not in track:
                track[sym] = {
                    "join_time": datetime.combine(date.today(), trading_time),
                    "base_vol":  row_now["volume"],
                    "base_rise": row_now["rise"]
                }
                msg = f"{sym} åŠ å…¥ {grp} è¿½è¹¤æ¸…å–®ï¼ˆ2minâ†‘2%ï¼‰"
                print(msg)

    # ----------------------- 3. é ˜æ¼²è™•ç†ï¼ˆæ‹‰é«˜ï¼‰ ------------------------ #
    for grp, gstat in group_positions.items():
        if not (isinstance(gstat, dict) and gstat["status"] == "è§€å¯Ÿä¸­"):
            continue
        if gstat.get("trigger") != "æ‹‰é«˜é€²å ´":
            continue

        track = gstat.get("tracking", {})
        if not track:
            continue

        # ç›®å‰ rise æœ€å¤§è€… = é ˜æ¼²
        max_sym = None
        max_rise = None
        for sym in track:
            df = stock_df[sym]
            row_now = df[df["time"] == trading_time]
            if row_now.empty:
                continue
            rise_now = row_now.iloc[0]["rise"]
            if max_rise is None or rise_now > max_rise:
                max_rise = rise_now
                max_sym  = sym

        # è‹¥é¦–æ¬¡ç¢ºç«‹é ˜æ¼²
        if gstat.get("leader") is None:
            gstat["leader"] = max_sym
            msg = f"æ‹‰é«˜é€²å ´ {grp} ç¢ºç«‹é ˜æ¼²ï¼š{max_sym}"
            print(msg)
            message_log.append((trading_txt, msg))
        else:
            # è‹¥é ˜æ¼²æ›¿æ›
            if max_sym and max_sym != gstat["leader"]:
                print(f"é ˜æ¼²æ›¿æ›ï¼š{gstat['leader']} â†’ {max_sym}")
                gstat["leader"] = max_sym
                gstat["leader_peak"] = rise_now
                gstat["leader_peak_time"] = current_time_str
                gstat["leader_reversal_rise"] = rise_now

                # âœ… é ˜æ¼²æ›¿æ›å¾Œåªæ›´æ–°ï¼Œä¸é€²å…¥ç­‰å¾…
                gstat["status"] = "è§€å¯Ÿä¸­"
                gstat.pop("wait_start", None)
                gstat["wait_counter"] = 0
                print(f"ğŸš€ é ˜æ¼²æ›¿æ›è§¸ç™¼ï¼Œé‡æ–°ç›£æ§é ˜æ¼²")
        # ---- é ˜æ¼²åè½‰ â†’ é€²å…¥ç­‰å¾… ----
        lead_sym = gstat["leader"]
        if not lead_sym:
            continue
        df_lead = stock_df[lead_sym]
        idx_now = df_lead[df_lead["time"] == trading_time].index
        if idx_now.empty:
            continue
        idx_now = idx_now[0]
        if idx_now - 1 >= 0:
            high_now = df_lead.loc[idx_now, "high"]
            high_pre = df_lead.loc[idx_now - 1, "high"]
            if high_now <= high_pre:
                # é–‹å§‹ç­‰å¾…
                if "wait_start" not in gstat:
                    gstat["wait_start"] = now_full = datetime.combine(date.today(), trading_time)
                    gstat["wait_counter"] = 0
                    gstat["leader_reversal_rise"] = df_lead.loc[idx_now, "rise"]
                    msg = f"æ‹‰é«˜é€²å ´ {grp} é ˜æ¼² {lead_sym} åè½‰ï¼Œé–‹å§‹ç­‰å¾…"
                    print(msg)
                    message_log.append((trading_txt, msg))

    # --------- è‹¥è™•æ–¼ç­‰å¾…éšæ®µï¼Œæ¯åˆ†é˜ç´¯åŠ ä¸¦å°ç‹€æ…‹ ---------
    for grp, gstat in group_positions.items():
        if not (isinstance(gstat, dict) and gstat["status"] == "è§€å¯Ÿä¸­"):
            continue

        # æ¼²åœé€²å ´ç­‰å¾…
        if gstat.get("trigger") == "æ¼²åœé€²å ´":
            if "wait_start" not in gstat:
                gstat["wait_start"]   = datetime.combine(date.today(), trading_time)
                gstat["wait_counter"] = 0
            else:
                gstat["wait_counter"] += 1
                print(f"æ¼²åœé€²å ´ {grp} ç­‰å¾…ç¬¬ {gstat['wait_counter']} åˆ†é˜")
            continue

        # æ‹‰é«˜é€²å ´ç­‰å¾…ï¼ˆå«è‡ªæˆ‘æ›¿æ›æª¢æŸ¥ï¼‰
        if gstat.get("trigger") != "æ‹‰é«˜é€²å ´" or "wait_start" not in gstat:
            continue

        # è‡ªæˆ‘æ›¿æ›æª¢æŸ¥
        lead = gstat.get("leader")
        if lead and gstat.get("leader_reversal_rise") is not None:
            df_lead = stock_df.get(lead, pd.DataFrame())
            row_now = df_lead[df_lead["time"] == trading_time]
            if not row_now.empty:
                rise_now = row_now.iloc[0]["rise"]
                if rise_now > gstat["leader_reversal_rise"]:
                    print(f"ğŸš€ é ˜æ¼²è‚¡ {lead} å†å‰µæ–°é«˜ {rise_now:.2f}% > {gstat['leader_reversal_rise']:.2f}% ï¼Œè§¸ç™¼è‡ªæˆ‘æ›¿æ›")
                    gstat["leader_reversal_rise"] = rise_now
                    # å›åˆ°è§€å¯Ÿä¸­ï¼Œé‡ç½®ç­‰å¾…
                    gstat["status"]         = "è§€å¯Ÿä¸­"
                    gstat.pop("wait_start", None)
                    gstat["wait_counter"]   = 0
                    print("ğŸš€ è‡ªæˆ‘æ›¿æ›è§¸ç™¼ï¼Œçµ‚æ­¢ç­‰å¾…ï¼Œé‡æ–°è§€å¯Ÿé ˜æ¼²")
                    continue

        # æ­£å¸¸ç´¯åŠ ç­‰å¾…åˆ†é˜
        gstat["wait_counter"] += 1
        print(f"æ‹‰é«˜é€²å ´ {grp} ç­‰å¾…ç¬¬ {gstat['wait_counter']} åˆ†é˜")

    # ---------------- 4. ç­‰å¾…å®Œæˆ â†’ ç¯©é¸è‚¡ç¥¨é€²å ´ ---------------- #
    def _vol_break(sym: str, join_time: datetime) -> bool:
        df = stock_df[sym]
        if df.empty:
            return False
        avgv = FIRST3_AVG_VOL[sym]
        if avgv == 0:
            return False
        later = df[df["time"] >= join_time.time()]
        return (later["volume"] >= 1.5 * avgv).any()

    def _rise_peak_flat(sym: str, join_time: datetime) -> bool:
        df = stock_df[sym]
        if df.empty:
            return False
        sub = df[df["time"] >= join_time.time()]
        if sub.empty:
            return False
        peak_idx = sub["rise"].idxmax()
        peak_val = sub.loc[peak_idx, "rise"]
        later = sub[sub.index > peak_idx]
        return (later["rise"] <= peak_val).all()

    groups_ready = []
    now_full = datetime.combine(date.today(), trading_time)
    for grp, gstat in group_positions.items():
        if not (isinstance(gstat, dict) and gstat["status"] == "è§€å¯Ÿä¸­"):
            continue
        elapsed = (now_full - gstat["start_time"]).total_seconds() / 60
        if elapsed >= wait_minutes:
            groups_ready.append(grp)

    for grp in groups_ready:
        gstat      = group_positions[grp]
        track      = gstat.get("tracking", {})   # åŸå§‹è¿½è¹¤æ¸…å–®ï¼Œdict[sym] = info
        leader_sym = gstat.get("leader")         # é ˜æ¼²è‚¡ç¥¨

        # â€”â€” 1. æ’é™¤ leader è‡ªå·± â€”â€” 
        candidates = [s for s in track.keys() if s != leader_sym]

        # â€”â€” 2. ç›¤ä¸­ç›¸ä¼¼åº¦ç¯©é¸ â€”â€” 
        sim_ok = calculate_realtime_kline_data(
            leader=leader_sym,
            candidates=candidates,
            intraday_file="auto_intraday.json",
            wait_end_time=now_full,
            similarity_threshold=0.4,
            close_weight=2.0
        )
        print(f"[RT-SIM] ç›¸ä¼¼åº¦åˆæ ¼ï¼š{sim_ok}")
        message_log.append((trading_txt, f"[RT-SIM] ç›¸ä¼¼åº¦åˆæ ¼ï¼š{sim_ok}"))

        # â€”â€” 3. æ¿¾é™¤æœªé€šéç›¸ä¼¼åº¦çš„è‚¡ç¥¨ â€”â€” 
        filtered_track = {s: track[s] for s in sim_ok if s in track}
        if not filtered_track:
            msg = f"{grp} ç›¸ä¼¼åº¦ç¯©é¸å¾Œç„¡å€™é¸ â†’ å–æ¶ˆè§€å¯Ÿ"
            print(msg)
            message_log.append((trading_txt, msg))
            group_positions[grp] = False
            continue

        # â€”â€” 4. æ›´æ–°è¿½è¹¤æ¸…å–® â€”â€” 
        gstat['tracking'] = filtered_track

        # 5. DEBUGï¼šåˆ—å‡ºæˆäº¤é‡çªç ´é–€æª»çš„è‚¡ç¥¨
        passed_vol = []
        for s, info in filtered_track.items():
            df   = stock_df[s]
            join = info["join_time"]
            avgv = FIRST3_AVG_VOL.get(s, 0)
            later = df[df["time"] >= join.time()]
            ok = avgv > 0 and (later["volume"] >= 1.5 * avgv).any()
            passed_vol.append(s) if ok else None
            message_log.append(
                (trading_txt,
                 f"[DEBUG] {s} é–‹ç›¤å‰ä¸‰åˆ†é˜å‡é‡={avgv:.2f}ï¼Œ"
                 f"1.5å€é–€æª»={1.5*avgv:.2f}ï¼Œ"
                 f"ç•¶å‰æˆäº¤é‡={(later.iloc[-1]['volume'] if not later.empty else 0):.2f}ï¼Œ"
                 f"è¶…è¶Šé–€æª»={ok}")
            )

        # 6. DEBUGï¼šåˆ—å‡ºåè½‰é€šéçš„è‚¡ç¥¨èˆ‡å³°é ‚æ™‚é–“
        passed_rev = []
        for s in passed_vol:
            df = stock_df[s]
            sub = df[df["time"] >= filtered_track[s]["join_time"].time()]
            if sub.empty: continue
            pkidx = sub["rise"].idxmax()
            pkval = sub.loc[pkidx, "rise"]
            pk_time = sub.loc[pkidx, "time"].strftime("%H:%M:%S")
            later = sub.loc[pkidx+1:]
            later_max = later["rise"].max() if not later.empty else None
            ok = (later_max is None) or (later_max <= pkval)
            passed_rev.append((s, pk_time))
            message_log.append(
                (trading_txt,
                 f"[DEBUG] {s} å³°é ‚={pkval:.2f} at {pk_time}ï¼Œ"
                 f"å¾ŒçºŒæœ€å¤§={later_max}ï¼Œpass={ok}")
            )

        # â€”â€” 7. åŸæœ¬çš„ eligible ç¯©é¸é‚è¼¯ â€”â€” 
        eligible = []

        for sym, info in track.items():
            if sym == leader_sym:
                continue
            if not _vol_break(sym, info["join_time"]):
                continue
            if not _rise_peak_flat(sym, info["join_time"]):
                continue
            df = stock_df[sym]
            row_now = df[df["time"] == trading_time]
            if row_now.empty:
                continue
            rise_now = row_now.iloc[0]["rise"]
            if not (-2 <= rise_now <= 6):
                continue
            entry_price = row_now.iloc[0]["close"]
            if entry_price > capital_per_stock * 1.5:
                msg = f"âš ï¸ æ’é™¤ {sym}ï¼Œè‚¡åƒ¹ {entry_price:.2f} è¶…éè³‡é‡‘ä¸Šé™ {capital_per_stock*1.5:.2f}"
                print(msg)
                message_log.append((trading_txt, msg))
                continue

            # âœ… æª¢æŸ¥æ˜¯å¦å¯ç•¶æ²–
            try:
                stock_code_int = int(sym)
                contract = api.Contracts.Stocks[sym]  # Shioaji å…§å»ºåˆç´„æŸ¥è©¢
                can_daytrade = contract.day_trade.value == "Yes"
                print(f"ğŸ§¾ æª¢æŸ¥ {sym} æ˜¯å¦å¯ç•¶æ²–ï¼š{contract.day_trade}")
                if not can_daytrade:
                    msg = f"âš ï¸ æ’é™¤ {sym}ï¼Œä»Šæ—¥ä¸å¯ç•¶æ²–"
                    print(msg)
                    message_log.append((trading_txt, msg))
                    continue
            except Exception as e:
                msg = f"âš ï¸ æ’é™¤ {sym}ï¼ŒæŸ¥è©¢ day_trade æ¬„ä½ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"
                print(msg)
                message_log.append((trading_txt, msg))
                continue

            eligible.append({
                "symbol": sym,
                "rise": rise_now,
                "row": row_now.iloc[0]
            })

        if not eligible:
            msg = f"{grp} ç­‰å¾…å®Œæˆï¼Œä½†ç„¡ç¬¦åˆæ¢ä»¶è‚¡ç¥¨ â†’ å–æ¶ˆè§€å¯Ÿ"
            print(msg)
            message_log.append((trading_txt, msg))
            group_positions[grp] = False
            continue

        eligible.sort(key=lambda x: x["rise"], reverse=True)
        chosen = eligible[len(eligible)//2]

        # ------------------- ä¸‹å–® -------------------
        
        row      = chosen["row"]
        entry_px = row["close"]
        shares   = round((capital_per_stock * 10000) / (entry_px * 1000))
        sell_amt = shares * entry_px * 1000
        fee      = int(sell_amt * (transaction_fee * 0.01) * (transaction_discount * 0.01))
        tax      = int(sell_amt * (trading_tax * 0.01))

        # --- è¨ˆç®— gap & tickï¼ˆä¾æ“š entry_priceï¼‰ ---
        if entry_px < 10:
            gap, tick = price_gap_below_50, 0.01
        elif entry_px < 50:
            gap, tick = price_gap_50_to_100, 0.05
        elif entry_px < 100:
            gap, tick = price_gap_50_to_100, 0.1
        elif entry_px < 500:
            gap, tick = price_gap_100_to_500, 0.5
        elif entry_px < 1000:
            gap, tick = price_gap_500_to_1000, 1
        else:
            gap, tick = price_gap_above_1000, 5

        # --- åŸå§‹åœæåƒ¹è¨ˆç®— ---
        highest_on_entry = row["highest"] or entry_px
        if (highest_on_entry - entry_px) * 1000 < gap:
            stop_type = "price_difference"
            stop_thr  = entry_px + gap / 1000
        else:
            stop_type = "over_high"
            stop_thr  = highest_on_entry + tick

        # âœ… åœæå¤©èŠ±æ¿é™åˆ¶ï¼šä¸å¾—é«˜æ–¼ã€Œæ¼²åœåƒ¹ - 2 tickã€
        limit_up = row["æ¼²åœåƒ¹"]
        if limit_up < 10:
            tick_for_limit = 0.01
        elif limit_up < 50:
            tick_for_limit = 0.05
        elif limit_up < 100:
            tick_for_limit = 0.1
        elif limit_up < 500:
            tick_for_limit = 0.5
        elif limit_up < 1000:
            tick_for_limit = 1
        else:
            tick_for_limit = 5

        ceiling = limit_up - 2 * tick_for_limit
        if stop_thr > ceiling:
            stop_thr = ceiling
            stop_type = "ceiling_limit"
            print(f"ğŸš« åœæåƒ¹éé«˜ï¼Œå•Ÿç”¨ ceiling é™åˆ¶ï¼š{ceiling:.2f}ï¼ˆæ¼²åœ {limit_up} - 2 tickï¼‰")

        current_position = {
            "symbol": chosen["symbol"],
            "shares": shares,
            "entry_price": entry_px,
            "sell_cost": sell_amt,
            "entry_fee": fee,
            "tax": tax,
            "entry_time": trading_txt,
            "current_price_gap": gap,
            "tick_unit": tick,
            "highest_on_entry": highest_on_entry,
            "stop_loss_type": stop_type,
            "stop_loss_threshold": stop_thr
        }

        open_positions[chosen['symbol']] = {'entry_price': entry_px, 'shares': shares} # ï¼å°‡æœ‰çœŸæ­£é€å‡ºå–®çš„è‚¡ç¥¨åŠ å…¥åˆ°è¡¨ä¸­

        # --- ä¸‹å¸‚åƒ¹ IOC è³£å‡ºå–®ï¼ˆåˆ¸å…ˆè³£ï¼‰ ---
        stock_code_int = int(chosen["symbol"])

        # è¼‰å…¥å¸‚å ´åˆ¥æ˜ å°„è¡¨
        if not os.path.exists("twse_stocks_by_market.json"):
            print(f"âš ï¸ æ‰¾ä¸åˆ° twse_stocks_by_market.jsonï¼Œç„¡æ³•åˆ¤åˆ¥è‚¡ç¥¨å¸‚å ´ï¼å–æ¶ˆä¸‹å–®ã€‚")
            return

        with open("twse_stocks_by_market.json", "r", encoding="utf-8") as f:
            stock_market_map = json.load(f)

        if chosen["symbol"] in stock_market_map.get("TSE", {}):
            contract = getattr(api.Contracts.Stocks.TSE, "TSE" + str(stock_code_int))
            market_label = "TSE"
        elif chosen["symbol"] in stock_market_map.get("OTC", {}):
            contract = getattr(api.Contracts.Stocks.OTC, "OTC" + str(stock_code_int))
            market_label = "OTC"
        else:
            print(f'âš ï¸ æ‰¾ä¸åˆ°è‚¡ç¥¨ {chosen["symbol"]} çš„å¸‚å ´è³‡æ–™ï¼å–æ¶ˆä¸‹å–®ã€‚')
            return

        order = api.Order(
            price=0,
            quantity=shares,
            action=sj.constant.Action.Sell,
            price_type=sj.constant.StockPriceType.MKT,
            order_type=sj.constant.OrderType.IOC,
            order_lot=sj.constant.StockOrderLot.Common,
            daytrade_short=True,
            account=api.stock_account
        )
        trade = api.place_order(contract, order)

        # --- TouchPrice åœæè²·å› ---
        t_cmd = tp.TouchCmd(
            code=f"{stock_code_int}",
            close=tp.Price(price=stop_thr, trend="Equal")
        )
        o_cmd = tp.OrderCmd(
            code=f"{stock_code_int}",
            order=sj.Order(
                price=0,
                quantity=shares,
                action="Buy",
                order_type="ROD",
                price_type="MKT"
            )
        )
        tcond = tp.TouchOrderCond(t_cmd, o_cmd)
        to.add_condition(tcond)

        msg = (
            f"{GREEN}é€²å ´ï¼{chosen['symbol']}  {shares}å¼µ  "
            f"æˆäº¤åƒ¹ {entry_px:.2f}  åœæåƒ¹ {stop_thr:.2f}{RESET}"
        )
        print(msg)
        message_log.append((trading_txt, msg))

        in_position            = True
        group_positions[grp]   = "å·²é€²å ´"
        leader                 = None
        tracking_stocks.clear()
        previous_rise_values.clear()

    # ------------------ 5. ä¾æ™‚é–“æ’åºåˆ—å°è¨Šæ¯ ------------------- #
    message_log.sort(key=lambda x: x[0])
    for t, m in message_log:
        print(f"[{t}] {m}")
    message_log.clear()

#ç›¤ä¸­13:30å‡ºå ´
def exit_trade_live():
    """
    æ­¤å‡½æ•¸ä¾æ“šè¨­å®šï¼Œæ–¼ 13:26 æ™‚é€²è¡Œå‡ºå ´å‹•ä½œï¼š
      1. å¾å…¨åŸŸè®Šæ•¸ to ä¸­å–å¾—æ‰€æœ‰å°šå­˜çš„è§¸åƒ¹å§”è¨—å–®ï¼ˆto.conditionsï¼‰
      2. ä¾æ“šæ¯å€‹è‚¡ç¥¨ä»£è™Ÿçš„æ‰€æœ‰å§”è¨—å–®ï¼Œç´¯åŠ å–å‡ºé€²å ´å¼µæ•¸ï¼ˆquantityï¼‰ï¼Œå½¢æˆ exit_data å­—å…¸
      3. å°‡ exit_data å¯«å…¥æœ¬åœ°æª”æ¡ˆ "enter_exit.json"
      4. é‡æ–°è®€å– "enter_exit.json" çš„è³‡æ–™
      5. å° exit_data ä¸­æ¯ä¸€ç­†è³‡æ–™ï¼Œåˆ©ç”¨è‚¡ç¥¨ä»£è™Ÿèˆ‡é€²å ´å¼µæ•¸å»ºç«‹å‡ºå ´å§”è¨—å–®ä¸¦ä¸‹å–®
      6. åˆªé™¤æ‰€æœ‰å°šå­˜çš„è§¸åƒ¹å§”è¨—å–®
      7. åŒæ­¥å¾ open_positions ä¸­ç§»é™¤å·²å¹³å€‰çš„è‚¡ç¥¨
    """
    global open_positions

    # 1. å–å¾—æ‰€æœ‰å°šå­˜çš„è§¸åƒ¹å§”è¨—å–®
    conditions_dict = to.conditions
    exit_data = {}

    # 2. éæ­·æ¯å€‹è‚¡ç¥¨ä»£è™ŸåŠå…¶å§”è¨—å–®åˆ—è¡¨ï¼Œç´¯åŠ é€²å ´å¼µæ•¸
    for stock_code, cond_list in conditions_dict.items():
        total_quantity = 0
        for cond in cond_list:
            try:
                qty = getattr(cond.order, 'quantity', 0)
                total_quantity += int(qty)
            except Exception as e:
                print(f"è®€å–è‚¡ç¥¨ {stock_code} çš„æ•¸é‡æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        if total_quantity > 0:
            exit_data[stock_code] = total_quantity

    # 3. å°‡ exit_data å¯«å…¥ "enter_exit.json"
    try:
        with open("enter_exit.json", "w", encoding="utf-8") as f:
            json.dump(exit_data, f, ensure_ascii=False, indent=4)
        print("å·²å°‡ç•¶å‰è§¸åƒ¹å§”è¨—å–®çš„è‚¡ç¥¨ä»£è™Ÿå’Œé€²å ´å¼µæ•¸å„²å­˜è‡³ enter_exit.json:")
        print(exit_data)
    except Exception as e:
        print(f"å¯«å…¥ enter_exit.json æª”æ¡ˆå¤±æ•—ï¼š{e}")
        return

    # 4. è®€å–æœ€æ–°çš„ exit data
    try:
        with open("enter_exit.json", "r", encoding="utf-8") as f:
            exit_info = json.load(f)
    except Exception as e:
        print(f"è®€å– enter_exit.json æª”æ¡ˆå¤±æ•—ï¼š{e}")
        return

    if not exit_info:
        print("enter_exit.json ä¸­æ²’æœ‰è§¸åƒ¹å§”è¨—å–®è³‡æ–™ï¼Œçµ‚æ­¢å‡ºå ´ç¨‹åºã€‚")
        return

    # 5. å°æ¯ç­† exit_info ä¸­çš„è³‡æ–™ï¼Œå»ºç«‹å‡ºå ´å§”è¨—å–®ä¸¦ä¸‹å–®
    for stock_code, shares in exit_info.items():
        try:
            # å–å¾— contract ç‰©ä»¶ï¼Œä¾‹å¦‚ "TSE2330"
            contract = getattr(api.Contracts.Stocks.TSE, "TSE" + str(stock_code))
            limit_up_price = contract.limit_up

            # å»ºç«‹é™åƒ¹è²·é€²çš„å§”è¨—å–® (ROC æ¢ä»¶)
            order = api.Order(
                action=sj.constant.Action.Buy,
                price=limit_up_price,
                quantity=shares,
                price_type=sj.constant.StockPriceType.LMT,
                order_type=sj.constant.OrderType.ROC,
                order_lot=sj.constant.StockOrderLot.Common,
                account=api.stock_account
            )
            trade = api.place_order(contract, order)
            print(f"{RED}ä¸‹å–®å‡ºå ´ï¼šè‚¡ç¥¨ {stock_code}ï¼Œæ•¸é‡ {shares} å¼µï¼›åƒ¹æ ¼è¨­å®šç‚ºæ¼²åœåƒ¹ {limit_up_price}{RESET}")

            # 7. åŒæ­¥å¾ open_positions ç§»é™¤å·²å¹³å€‰çš„è‚¡ç¥¨
            open_positions.pop(stock_code, None)

        except Exception as e:
            print(f"è™•ç†è‚¡ç¥¨ {stock_code} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    # 6. åˆªé™¤æ‰€æœ‰å°šå­˜çš„è§¸åƒ¹å§”è¨—å–®
    for stock_code, cond_list in list(conditions_dict.items()):
        for cond in cond_list:
            try:
                to.delete_condition(cond)
            except Exception as e:
                print(f"åˆªé™¤è‚¡ç¥¨ {stock_code} çš„è§¸åƒ¹å§”è¨—å–®æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    print(f"{RED}å‡ºå ´å§”è¨—å–®å·²å…¨éƒ¨ä¸‹å–®ï¼Œä¸¦åˆªé™¤æ‰€æœ‰è§¸åƒ¹å§”è¨—å–®ã€‚{RESET}")

def list_open_positions():
    if not open_positions:
        print(f"{YELLOW}ç›®å‰æ²’æœ‰ä»»ä½•æŒå€‰{RESET}")
        return
    print("\n========== ç›®å‰æŒå€‰ ==========")
    for i, (c, info) in enumerate(open_positions.items(), 1):
        print(f"{i}. {c:<6} {get_stock_name(c):<8} é€²å ´åƒ¹={info['entry_price']}  å¼µæ•¸={info['shares']}")
    print("=" * 29)

def close_one_stock(code: str):
    """åˆªè©²è‚¡æ‰€æœ‰è§¸åƒ¹å–® + ä»¥æ¼²åœåƒ¹ ROC å¸‚åƒ¹è²·å›"""
    conds = to.conditions.get(code, [])
    qty   = sum(getattr(c.order, 'quantity', 0) for c in conds)
    if qty == 0:
        print(f"âš ï¸  {code} å·²ç„¡å§”è¨— / æŒå€‰")
        return
    try:
        contract = getattr(api.Contracts.Stocks.TSE, f"TSE{code}")
        api.place_order(contract, api.Order(
            action=sj.constant.Action.Buy,
            price=contract.limit_up,
            quantity=qty,
            price_type=sj.constant.StockPriceType.LMT,
            order_type=sj.constant.OrderType.ROC,
            order_lot=sj.constant.StockOrderLot.Common,
            account=api.stock_account
        ))
        print(f"{GREEN}å·²å¹³å€‰ {code}  å…± {qty} å¼µ{RESET}")
    except Exception as e:
        print(f"å¹³å€‰ {code} æ™‚éŒ¯èª¤ï¼š{e}")
    for c in conds:
        to.delete_condition(c)
    to.conditions.pop(code, None)
    open_positions.pop(code, None)

def main():
    load_settings()
    config = load_config("config.yaml")
    client = RestClient(api_key=config['api_key'])
    matrix_dict_analysis = load_matrix_dict_analysis()
    main_menu()

if __name__ == "__main__":
    '''
    #æ¸¬è©¦ä¸­æ–‡è‚¡ç¥¨åç¨±
    data = fetch_twse_stock_codes(save_json="twse_stocks.json",
                                  save_csv="twse_stocks.csv")
    for code, name in data[:20]:
        print(code, name)
    '''
    ensure_packages(REQUIRED)
    print("é–‹å§‹åŸ·è¡Œç¨‹å¼...")
    main()